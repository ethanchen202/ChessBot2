Begin: Initializing Dataloader                 Current time: Sat Oct 25 21:31:44 2025      
  End: Initializing Dataloader                 Current time: Sat Oct 25 21:31:44 2025      Time elapsed: 0.00158s
Begin: Initializing Model                      Current time: Sat Oct 25 21:31:44 2025      
Running on cuda
  End: Initializing Model                      Current time: Sat Oct 25 21:31:44 2025      Time elapsed: 0.22307s
Begin: Initializing training process           Current time: Sat Oct 25 21:31:44 2025      
  End: Initializing training process           Current time: Sat Oct 25 21:31:46 2025      Time elapsed: 2.15711s
Begin: Training for 3907 batches               Current time: Sat Oct 25 21:31:46 2025      
Begin: Training epoch 1                        Current time: Sat Oct 25 21:31:46 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:32:07 2025      Time elapsed: 21.08873        ETA: 802.84853s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:32:27 2025      Time elapsed: 40.76098        ETA: 755.50483s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:32:47 2025      Time elapsed: 60.50440        ETA: 727.46471s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:33:07 2025      Time elapsed: 80.33309        ETA: 704.32046s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:33:27 2025      Time elapsed: 100.35327       ETA: 683.80725s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:33:47 2025      Time elapsed: 120.36157       ETA: 663.39291s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:34:07 2025      Time elapsed: 140.29895       ETA: 642.76967s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:34:27 2025      Time elapsed: 160.29281       ETA: 622.53724s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:34:47 2025      Time elapsed: 180.31355       ETA: 602.44763s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:35:07 2025      Time elapsed: 200.35163       ETA: 582.42220s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:35:27 2025      Time elapsed: 220.34385       ETA: 562.27746s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:35:47 2025      Time elapsed: 240.33853       ETA: 542.16367s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:36:07 2025      Time elapsed: 260.32977       ETA: 522.06133s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:36:27 2025      Time elapsed: 280.31549       ETA: 501.96497s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:36:47 2025      Time elapsed: 300.31191       ETA: 481.90053s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:37:07 2025      Time elapsed: 320.30420       ETA: 461.83862s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:37:27 2025      Time elapsed: 340.35166       ETA: 441.85655s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:37:47 2025      Time elapsed: 360.63627       ETA: 422.14480s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:38:07 2025      Time elapsed: 380.92203       ETA: 402.37397s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:38:27 2025      Time elapsed: 401.07193       ETA: 382.42209s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:38:48 2025      Time elapsed: 421.22002       ETA: 362.44980s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:39:08 2025      Time elapsed: 441.50980       ETA: 342.57147s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:39:28 2025      Time elapsed: 461.99107       ETA: 322.79116s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:39:49 2025      Time elapsed: 482.53481       ETA: 302.99166s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:40:09 2025      Time elapsed: 503.01890       ETA: 283.09904s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:40:30 2025      Time elapsed: 523.42434       ETA: 263.12139s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:40:50 2025      Time elapsed: 543.76764       ETA: 243.08428s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:41:11 2025      Time elapsed: 564.18201       ETA: 223.05339s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:41:31 2025      Time elapsed: 584.71917       ETA: 203.03869s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:41:52 2025      Time elapsed: 605.24652       ETA: 182.98620s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:42:12 2025      Time elapsed: 625.77101       ETA: 162.90232s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:42:33 2025      Time elapsed: 646.26225       ETA: 142.78357s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:42:53 2025      Time elapsed: 666.77139       ETA: 122.64553s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:43:14 2025      Time elapsed: 687.17345       ETA: 102.46969s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:43:34 2025      Time elapsed: 707.45171       ETA: 82.26653s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:43:54 2025      Time elapsed: 727.64005       ETA: 62.05153s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:44:14 2025      Time elapsed: 747.82368       ETA: 41.83770s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:44:34 2025      Time elapsed: 768.10221       ETA: 21.62814s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:44:55 2025      Time elapsed: 788.49041       ETA: 1.41524s
Epoch 1: Avg Policy Loss=3.0868, Avg Value Loss=0.5524
  End: Training epoch 1                        Current time: Sat Oct 25 21:44:56 2025      Time elapsed: 789.81436s
Begin: Validating epoch 1                      Current time: Sat Oct 25 21:44:56 2025      
Validation: Policy Loss=3.0461, Value Loss=0.5404, Top-1 Acc=0.1283, Top-5 Acc=0.3868
  End: Validating epoch 1                      Current time: Sat Oct 25 21:45:20 2025      Time elapsed: 24.14117s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_1.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 21:45:20 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss      xmax      xmin
0          3  Conv2d  0.125477   19    32  1.684211   5.329351       -1.234305  0.947069     True    0.586671     conv2d       -0.240548  1.506109          -0.231605     conv_stem.net.0          171   32.070760        171             38          0   9  0.702314       0.586671    54.665637  success  0.765945  0.127873                              0  0.586671  0.330133
1          6  Conv2d  0.126294   32    64  2.000000   8.304378       -1.473939  0.969655     True    0.664524     conv2d       -0.513052  1.812850          -0.177489     conv_stem.net.3          288   64.990527        288             33          0   9  1.271529       0.664524    97.800125  success  0.815183  0.175948  under-trained               0  0.664524  0.472161
2          9  Conv2d  0.165710   64   256  4.000000   3.477686        3.225649  0.973765     True    8.463063     conv2d        4.291279  2.424478           0.927528                proj           64  265.752587         64             34          0   1  0.424920       8.463063    31.401465  success  2.909134  1.059922                              0  8.463063  3.726597
3         14  Linear  0.071163  256   768  3.000000   5.951950        1.340810  0.978338     True    1.679857      dense        1.478656  1.913217           0.225272        blocks.0.qkv          256   81.887313        256             38          0   1  0.803312       1.679857    48.746597  success  1.296093  0.234746                              0  1.679857  0.540893
4         15  Linear  0.055166  256   256  1.000000   5.895871       -0.825938  0.919069     True    0.724290      dense       -0.642156  1.432091          -0.140088   blocks.0.out_proj          256   27.045268        256             21          0   1  1.068367       0.724290    37.340392  success  0.851052  0.001077                              0  0.724290  0.290222
5         22  Linear  0.086062  256  1024  4.000000   4.196007        2.719068  0.973954     True    4.446448      dense        2.824809  2.060884           0.648013  blocks.0.ffn.net.0          256  115.049221        256             78          0   1  0.361877       4.446448    25.874411  success  2.108660  0.328321                              0  4.446448  0.528722
6         25  Linear  0.085641  256  1024  4.000000   4.796968        2.559143  0.981011     True    3.415796      dense        2.606886  2.048159           0.533492  blocks.0.ffn.net.3          256  111.727290        256             68          0   1  0.460450       3.415796    32.709010  success  1.848187  0.318537                              0  3.415796  0.567264
7         29  Linear  0.070058  256   768  3.000000   6.135830        1.092825  0.978652     True    1.506973      dense        1.315432  1.912037           0.178105        blocks.1.qkv          256   81.665152        256             33          0   1  0.894033       1.506973    54.191524  success  1.227588  0.237731  under-trained               0  1.506973  0.561592
8         30  Linear  0.069907  256   256  1.000000   5.765613       -0.935849  0.920118     True    0.688152      dense       -0.673595  1.431987          -0.162316   blocks.1.out_proj          256   27.038780        256             26          0   1  0.934614       0.688152    39.291865  success  0.829549  0.001291                              0  0.688152  0.274533
9         37  Linear  0.088486  256  1024  4.000000   4.092281        2.753966  0.972550     True    4.709405      dense        2.858708  2.062912           0.672966  blocks.1.ffn.net.0          256  115.587890        256             84          0   1  0.337396       4.709405    24.544052  success  2.170116  0.322302                              0  4.709405  0.512409
10        40  Linear  0.081474  256  1024  4.000000   4.829818        2.643112  0.981071     True    3.525728      dense        2.683355  2.045686           0.547249  blocks.1.ffn.net.3          256  111.092788        256             65          0   1  0.475030       3.525728    31.509177  success  1.877692  0.328903                              0  3.525728  0.567878
11        44  Linear  0.088178  256   768  3.000000   4.446110        2.888747  0.963658     True    4.464003      dense        2.906471  1.936829           0.649724        blocks.2.qkv          256   86.462716        256             58          0   1  0.452496       4.464003    19.368875  success  2.112819  0.240090                              0  4.464003  0.469430
12        45  Linear  0.087826  256   256  1.000000   5.835045       -0.538040  0.919560     True    0.808708      dense       -0.439140  1.435174          -0.092208   blocks.2.out_proj          256   27.237900        256             20          0   1  1.081149       0.808708    33.680767  success  0.899282  0.000708                              1  0.808708  0.295238
13        52  Linear  0.083265  256  1024  4.000000   4.034991        2.650267  0.973382     True    4.537546      dense        2.759323  2.063038           0.656821  blocks.2.ffn.net.0          256  115.621428        256             87          0   1  0.325385       4.537546    25.481050  success  2.130152  0.324787                              0  4.537546  0.502840
14        55  Linear  0.084157  256  1024  4.000000   4.735081        2.549806  0.980915     True    3.455354      dense        2.599259  2.048094           0.538493  blocks.2.ffn.net.3          256  111.710523        256             67          0   1  0.456313       3.455354    32.329686  success  1.858858  0.325533                              0  3.455354  0.565622
15        59  Linear  0.076814  256   768  3.000000   5.920372        1.421030  0.978337     True    1.737896      dense        1.498829  1.912272           0.240024        blocks.3.qkv          256   81.709370        256             40          0   1  0.777979       1.737896    47.016267  success  1.318293  0.242704                              0  1.737896  0.533569
16        60  Linear  0.058813  256   256  1.000000   5.913302       -0.900240  0.919940     True    0.704304      dense       -0.698581  1.430628          -0.152240   blocks.3.out_proj          256   26.954326        256             18          0   1  1.158076       0.704304    38.270873  success  0.839228  0.000898                              1  0.704304  0.300018
17        67  Linear  0.083803  256  1024  4.000000   4.194062        2.744107  0.973965     True    4.511115      dense        2.831889  2.058608           0.654284  blocks.3.ffn.net.0          256  114.447890        256             80          0   1  0.357107       4.511115    25.370200  success  2.123939  0.325856                              0  4.511115  0.522651
18        70  Linear  0.071333  256  1024  4.000000   4.937900        2.608080  0.981563     True    3.374239      dense        2.646153  2.047502           0.528176  blocks.3.ffn.net.3          256  111.558279        256             57          0   1  0.521588       3.374239    33.061758  success  1.836910  0.316240                              0  3.374239  0.598558
19        74  Linear  0.054738  256   768  3.000000   6.475340        1.402520  0.979044     True    1.646622      dense        1.479043  1.911048           0.216594        blocks.4.qkv          256   81.479376        256             33          0   1  0.953134       1.646622    49.482739  success  1.283208  0.245696  under-trained               0  1.646622  0.561437
20        75  Linear  0.058481  256   256  1.000000   6.011250       -1.032845  0.920160     True    0.673258      dense       -0.805448  1.434622          -0.171819   blocks.4.out_proj          256   27.203296        256             20          0   1  1.120550       0.673258    40.405469  success  0.820523  0.001675  under-trained               0  0.673258  0.296727
21        82  Linear  0.090080  256  1024  4.000000   4.098687        2.769624  0.973192     True    4.739519      dense        2.856710  2.061184           0.675734  blocks.4.ffn.net.0          256  115.128772        256             85          0   1  0.336100       4.739519    24.291235  success  2.177044  0.328616                              0  4.739519  0.508924
22        85  Linear  0.083109  256  1024  4.000000   4.787542        2.617178  0.981109     True    3.520986      dense        2.656450  2.048186           0.546664  blocks.4.ffn.net.3          256  111.734156        256             69          0   1  0.455966       3.520986    31.733768  success  1.876429  0.321649                              0  3.520986  0.562954
23        89  Linear  0.064158  256   768  3.000000   5.549259        1.431544  0.977799     True    1.811217      dense        1.556104  1.916713           0.257970        blocks.5.qkv          256   82.549196        256             41          0   1  0.710475       1.811217    45.576656  success  1.345814  0.242804                              0  1.811217  0.527705
24        90  Linear  0.065180  256   256  1.000000   5.864303       -0.692788  0.919417     True    0.761840      dense       -0.548691  1.435115          -0.118136   blocks.5.out_proj          256   27.234246        256             18          0   1  1.146527       0.761840    35.748007  success  0.872834  0.000083                              1  0.761840  0.301727
25        97  Linear  0.088166  256  1024  4.000000   4.282285        2.764479  0.975056     True    4.421417      dense        2.847120  2.058734           0.645561  blocks.5.ffn.net.0          256  114.481045        256             78          0   1  0.371646       4.421417    25.892387  success  2.102717  0.330967                              0  4.421417  0.530792
26       100  Linear  0.083190  256  1024  4.000000   4.857337        2.642869  0.981325     True    3.500244      dense        2.677381  2.045960           0.544098  blocks.5.ffn.net.3          256  111.162861        256             63          0   1  0.485979       3.500244    31.758606  success  1.870894  0.323621                              0  3.500244  0.577765
27       104  Linear  0.076898  256   768  3.000000   5.800949        1.879445  0.977531     True    2.108576      dense        1.909389  1.913970           0.323989        blocks.6.qkv          256   82.029582        256             38          0   1  0.778817       2.108576    38.902833  success  1.452094  0.234222                              0  2.108576  0.537726
28       105  Linear  0.061304  256   256  1.000000   6.371877       -0.753311  0.919483     True    0.761686      dense       -0.673003  1.430423          -0.118224   blocks.6.out_proj          256   26.941563        256             15          0   1  1.387013       0.761686    35.370978  success  0.872746  0.000746  under-trained               1  0.761686  0.315807
29       112  Linear  0.092668  256  1024  4.000000   4.066819        2.679600  0.973931     True    4.559248      dense        2.773938  2.060766           0.658893  blocks.6.ffn.net.0          256  115.018042        256             85          0   1  0.332643       4.559248    25.227415  success  2.135240  0.327593                              0  4.559248  0.506198
30       115  Linear  0.088208  256  1024  4.000000   5.103583        2.768058  0.981293     True    3.486385      dense        2.795494  2.046757           0.542375  blocks.6.ffn.net.3          256  111.367194        256             58          0   1  0.538827       3.486385    31.943457  success  1.867186  0.330202                              0  3.486385  0.600674
31       119  Linear  0.066862  256   768  3.000000   5.743292        1.471898  0.978278     True    1.804186      dense        1.558385  1.912376           0.256281        blocks.7.qkv          256   81.728990        256             41          0   1  0.740778       1.804186    45.299660  success  1.343200  0.245332                              0  1.804186  0.526503
32       120  Linear  0.049583  256   256  1.000000   6.071341       -0.901675  0.920178     True    0.710373      dense       -0.726139  1.435751          -0.148513   blocks.7.out_proj          256   27.274114        256             21          0   1  1.106657       0.710373    38.394059  success  0.842836  0.000404  under-trained               1  0.710373  0.294575
33       127  Linear  0.081953  256  1024  4.000000   4.354057        2.849739  0.973971     True    4.513381      dense        2.939299  2.059749           0.654502  blocks.7.ffn.net.0          256  114.749087        256             70          0   1  0.400886       4.513381    25.424197  success  2.124472  0.321653                              0  4.513381  0.553025
34       130  Linear  0.079141  256  1024  4.000000   5.104053        2.631408  0.981992     True    3.277576      dense        2.669918  2.046534           0.515553  blocks.7.ffn.net.3          256  111.309851        256             57          0   1  0.543595       3.277576    33.961031  success  1.810408  0.324499                              0  3.277576  0.602187
35       134  Linear  0.058848  256   768  3.000000   6.514214        1.362486  0.978644     True    1.618661      dense        1.464048  1.913608           0.209156        blocks.8.qkv          256   81.961207        256             34          0   1  0.945680       1.618661    50.635203  success  1.272266  0.238460  under-trained               0  1.618661  0.566011
36       135  Linear  0.055900  256   256  1.000000   6.040442       -0.978501  0.920649     True    0.688666      dense       -0.796711  1.426788          -0.161992   blocks.8.out_proj          256   26.717026        256             23          0   1  1.051005       0.688666    38.795356  success  0.829859  0.001852  under-trained               0  0.688666  0.281627
37       142  Linear  0.083655  256  1024  4.000000   4.030752        2.644086  0.974414     True    4.528750      dense        2.728058  2.060943           0.655978  blocks.8.ffn.net.0          256  115.064901        256             88          0   1  0.323079       4.528750    25.407649  success  2.128086  0.325076                              0  4.528750  0.500402
38       145  Linear  0.074309  256  1024  4.000000   5.111952        2.770189  0.981473     True    3.482606      dense        2.795462  2.045567           0.541904  blocks.8.ffn.net.3          256  111.062456        256             57          0   1  0.544641       3.482606    31.890616  success  1.866174  0.332077                              0  3.482606  0.600752
39       149  Linear  0.061581  256   768  3.000000   5.862840        1.548846  0.978006     True    1.837300      dense        1.629983  1.912445           0.264180        blocks.9.qkv          256   81.741982        256             40          0   1  0.768882       1.837300    44.490265  success  1.355471  0.240058                              0  1.837300  0.533057
40       150  Linear  0.052366  256   256  1.000000   6.404397       -0.785152  0.919918     True    0.754057      dense       -0.691117  1.433616          -0.122596   blocks.9.out_proj          256   27.140401        256             17          0   1  1.310759       0.754057    35.992500  success  0.868365  0.000898  under-trained               1  0.754057  0.307949
41       157  Linear  0.085716  256  1024  4.000000   4.186331        2.764978  0.973762     True    4.575912      dense        2.857043  2.061748           0.660478  blocks.9.ffn.net.0          256  115.278465        256             81          0   1  0.354037       4.575912    25.192459  success  2.139138  0.323935                              0  4.575912  0.522672
42       160  Linear  0.083286  256  1024  4.000000   4.783340        2.480959  0.982027     True    3.301160      dense        2.532821  2.047394           0.518667  blocks.9.ffn.net.3          256  111.530631        256             66          0   1  0.465697       3.301160    33.785281  success  1.816910  0.332128                              0  3.301160  0.567053
43       165  Linear  0.070631  128   256  2.000000   5.087086       -0.722024  0.945485     True    0.721219      dense       -0.669674  1.149165          -0.141933          src_head.0          128   14.098235        128             22          0   1  0.871370       0.721219    19.547778  success  0.849246  0.095980                              0  0.721219  0.192678
44       167  Linear  0.075864   64   128  2.000000   4.830258       -2.932378  0.929901     True    0.247124      dense       -2.747679  0.553682          -0.607085          src_head.2           64    3.578346         64             13          0   1  1.062322       0.247124    14.479964  success  0.497116  0.068284                              0  0.247124  0.095338
45       169  Linear  0.056672  256   256  1.000000   4.859144       -0.290381  0.916891     True    0.871445      dense       -0.077190  1.455503          -0.059760         dest_head.0          256   28.543195        256             28          0   1  0.729310       0.871445    32.753850  success  0.933512  0.000950                              1  0.871445  0.277512
46       171  Linear  0.105162   73   256  3.506849   4.037900       -1.830024  0.963434     True    0.352199      dense       -1.294714  0.909463          -0.453212         dest_head.2           73    8.118266         73             26          0   1  0.595781       0.352199    23.050225  success  0.593464  0.155009                              0  0.352199  0.128514
47       173  Conv2d  0.105978  256   256  1.000000  27.822690       -9.854612  1.065142     True    0.442391     conv2d       -8.846718  2.405769          -0.354193        value_conv.0         2304  254.547421       2304             29          0   9  4.980849       0.442391   575.389668  success  0.665125  0.002423  under-trained               7  0.442391  0.404158
48       177  Linear  0.144872  128   256  2.000000   3.634400       -1.964603  0.954531     True    0.288033      dense       -0.870092  1.111958          -0.540558         value_mlp.0          128   12.940698        128             44          0   1  0.397151       0.288033    44.927821  success  0.536687  0.096257                              0  0.288033  0.123881
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0  0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 21:46:55 2025      Time elapsed: 94.65400s
Begin: Training epoch 2                        Current time: Sat Oct 25 21:46:55 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:47:15 2025      Time elapsed: 928.25849       ETA: 35338.80089s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:47:34 2025      Time elapsed: 947.86297       ETA: 17568.64033s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:47:54 2025      Time elapsed: 967.54017       ETA: 11633.05808s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:48:14 2025      Time elapsed: 987.33423       ETA: 8656.45290s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:48:34 2025      Time elapsed: 1007.25174      ETA: 6863.41343s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:48:54 2025      Time elapsed: 1027.27738      ETA: 5662.01051s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:49:14 2025      Time elapsed: 1047.37590      ETA: 4798.47789s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:49:34 2025      Time elapsed: 1067.44316      ETA: 4145.68239s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:49:54 2025      Time elapsed: 1087.52938      ETA: 3633.55652s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:50:14 2025      Time elapsed: 1107.73243      ETA: 3220.17820s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:50:34 2025      Time elapsed: 1128.02671      ETA: 2878.51909s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:50:55 2025      Time elapsed: 1148.29788      ETA: 2590.36864s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:51:15 2025      Time elapsed: 1168.60274      ETA: 2343.49796s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:51:35 2025      Time elapsed: 1188.99270      ETA: 2129.14621s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:51:56 2025      Time elapsed: 1209.25250      ETA: 1940.44719s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:52:16 2025      Time elapsed: 1229.37344      ETA: 1772.60284s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:52:36 2025      Time elapsed: 1249.48270      ETA: 1622.12254s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:52:56 2025      Time elapsed: 1269.62583      ETA: 1486.16757s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:53:16 2025      Time elapsed: 1289.85451      ETA: 1362.49369s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:53:36 2025      Time elapsed: 1310.07453      ETA: 1249.15607s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:53:57 2025      Time elapsed: 1330.20120      ETA: 1144.60646s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:54:17 2025      Time elapsed: 1350.34648      ETA: 1047.74611s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:54:37 2025      Time elapsed: 1370.70680      ETA: 957.70688s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:54:58 2025      Time elapsed: 1391.22587      ETA: 873.57391s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:55:18 2025      Time elapsed: 1411.48962      ETA: 794.38636s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:55:38 2025      Time elapsed: 1431.61254      ETA: 719.66061s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:55:58 2025      Time elapsed: 1451.86018      ETA: 649.03527s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:56:19 2025      Time elapsed: 1472.37187      ETA: 582.11274s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:56:39 2025      Time elapsed: 1492.87718      ETA: 518.38873s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:57:00 2025      Time elapsed: 1513.19598      ETA: 457.48959s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:57:20 2025      Time elapsed: 1533.54881      ETA: 399.21739s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:57:41 2025      Time elapsed: 1554.13123      ETA: 343.36587s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:58:01 2025      Time elapsed: 1574.64062      ETA: 289.63844s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:58:21 2025      Time elapsed: 1595.00202      ETA: 237.84295s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:58:42 2025      Time elapsed: 1615.29905      ETA: 187.83620s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:59:02 2025      Time elapsed: 1635.59116      ETA: 139.47958s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:59:22 2025      Time elapsed: 1655.99660      ETA: 92.64630s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 21:59:43 2025      Time elapsed: 1676.42424      ETA: 47.20458s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:00:03 2025      Time elapsed: 1696.74628      ETA: 3.04544s
Epoch 2: Avg Policy Loss=3.0060, Avg Value Loss=0.5518
  End: Training epoch 2                        Current time: Sat Oct 25 22:00:04 2025      Time elapsed: 789.32922s
Begin: Validating epoch 2                      Current time: Sat Oct 25 22:00:04 2025      
Validation: Policy Loss=2.9864, Value Loss=0.5393, Top-1 Acc=0.1451, Top-5 Acc=0.4231
  End: Validating epoch 2                      Current time: Sat Oct 25 22:00:28 2025      Time elapsed: 23.52450s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_2.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 22:00:28 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss      xmax      xmin
0          3  Conv2d  0.115659   19    32  1.684211   7.148309       -1.538224  0.946233     True    0.609274     conv2d       -0.823092  1.499650          -0.215187     conv_stem.net.0          171   31.597289        171             24          0   9  1.255018       0.609274    51.860529  success  0.780560  0.128998  under-trained               0  0.609274  0.385309
1          6  Conv2d  0.121773   32    64  2.000000  23.368554       -4.227183  0.969556     True    0.659338     conv2d       -3.796906  1.808278          -0.180892     conv_stem.net.3          288   64.309987        288             10          0   9  7.073558       0.659338    97.537216  success  0.811996  0.176120  under-trained               0  0.659338  0.579779
2          9  Conv2d  0.167756   64   256  4.000000   3.481158        3.207525  0.973745     True    8.344419     conv2d        4.275194  2.419016           0.921396                proj           64  262.431676         64             34          0   1  0.425515       8.344419    31.449966  success  2.888671  1.062566                              0  8.344419  3.681415
3         14  Linear  0.092515  256   768  3.000000   3.298157        2.323674  0.949668     True    5.064507      dense        2.505424  1.966806           0.704537        blocks.0.qkv          256   92.641601        256             97          0   1  0.233342       5.064507    18.292325  success  2.250446  0.235484                              0  5.064507  0.356268
4         15  Linear  0.087083  256   256  1.000000   4.104603        0.629331  0.908268     True    1.423388      dense        0.700226  1.447298           0.153323   blocks.0.out_proj          256   28.009048        256             41          0   1  0.484858       1.423388    19.677736  success  1.193058  0.001505                              0  1.423388  0.225077
5         22  Linear  0.071740  256  1024  4.000000   2.672903        2.093265  0.958881     True    6.069357      dense        2.401238  2.097579           0.783143  blocks.0.ffn.net.0          256  125.192731        256             15          0   1  0.431942       6.069357    20.627016  success  2.463607  0.327631                              0  6.069357  0.866177
6         25  Linear  0.079975  256  1024  4.000000   3.772393        2.560695  0.968884     True    4.773079      dense        2.710694  2.075938           0.678799  blocks.0.ffn.net.3          256  119.107289        256             87          0   1  0.297232       4.773079    24.953974  success  2.184738  0.317234                              0  4.773079  0.505840
7         29  Linear  0.076195  256   768  3.000000   3.566033        2.109456  0.958029     True    3.904285      dense        2.333110  1.954943           0.591541        blocks.1.qkv          256   90.145178        256             86          0   1  0.276702       3.904285    23.088782  success  1.975926  0.238108                              0  3.904285  0.387414
8         30  Linear  0.088001  256   256  1.000000   4.249675        0.280411  0.911338     True    1.164084      dense        0.444460  1.444933           0.065984   blocks.1.out_proj          256   27.856940        256             38          0   1  0.527167       1.164084    23.930361  success  1.078927  0.001029                              0  1.164084  0.232425
9         37  Linear  0.071791  256  1024  4.000000   3.488537        2.682996  0.959249     True    5.876102      dense        2.907837  2.096671           0.769089  blocks.1.ffn.net.0          256  124.931131        256             95          0   1  0.255318       5.876102    21.260886  success  2.424067  0.324858                              0  5.876102  0.485194
10        40  Linear  0.073936  256  1024  4.000000   3.690065        2.422951  0.969623     True    4.535392      dense        2.627327  2.071922           0.656615  blocks.1.ffn.net.3          256  118.010994        256             94          0   1  0.277459       4.535392    26.020019  success  2.129646  0.328730                              0  4.535392  0.478960
11        44  Linear  0.074307  256   768  3.000000   3.166218        2.253126  0.941787     True    5.147712      dense        2.541651  1.985063           0.711614        blocks.2.qkv          256   96.619123        256            102          0   1  0.214488       5.147712    18.769333  success  2.268857  0.241099                              0  5.147712  0.348276
12        45  Linear  0.089774  256   256  1.000000   4.291913        0.796191  0.908400     True    1.532885      dense        0.839005  1.449866           0.185510   blocks.2.out_proj          256   28.175151        256             35          0   1  0.556435       1.532885    18.380470  success  1.238097  0.000508                              1  1.532885  0.241079
13        52  Linear  0.078304  256  1024  4.000000   3.397098        2.553500  0.959198     True    5.645089      dense        2.800756  2.098497           0.751671  blocks.2.ffn.net.0          256  125.457716        256             99          0   1  0.240917       5.645089    22.224222  success  2.375940  0.325935                              0  5.645089  0.470329
14        55  Linear  0.073472  256  1024  4.000000   3.741640        2.439012  0.969653     True    4.485970      dense        2.630512  2.075015           0.651856  blocks.2.ffn.net.3          256  118.854357        256             87          0   1  0.293935       4.485970    26.494681  success  2.118011  0.324579                              0  4.485970  0.502325
15        59  Linear  0.077694  256   768  3.000000   3.634882        2.451651  0.954759     True    4.725840      dense        2.560368  1.960014           0.674479        blocks.3.qkv          256   91.203981        256             78          0   1  0.298342       4.725840    19.299000  success  2.173900  0.245680                              0  4.725840  0.410924
16        60  Linear  0.086981  256   256  1.000000   4.181780        0.551128  0.910266     True    1.354542      dense        0.622027  1.443544           0.131793   blocks.3.out_proj          256   27.767953        256             38          0   1  0.516153       1.354542    20.499876  success  1.163848  0.001351                              0  1.354542  0.229779
17        67  Linear  0.077737  256  1024  4.000000   3.434547        2.608391  0.958883     True    5.747211      dense        2.840333  2.095946           0.759457  blocks.3.ffn.net.0          256  124.722841        256             95          0   1  0.249779       5.747211    21.701455  success  2.397334  0.326928                              0  5.747211  0.480297
18        70  Linear  0.073130  256  1024  4.000000   3.747386        2.422672  0.969858     True    4.430946      dense        2.624528  2.075540           0.646496  blocks.3.ffn.net.3          256  118.998141        256             89          0   1  0.291222       4.430946    26.856149  success  2.104981  0.319933                              0  4.430946  0.499820
19        74  Linear  0.082494  256   768  3.000000   3.693805        2.299809  0.956763     True    4.193847      dense        2.462355  1.958395           0.622613        blocks.4.qkv          256   90.864607        256             78          0   1  0.305013       4.193847    21.666170  success  2.047889  0.248645                              0  4.193847  0.414181
20        75  Linear  0.080436  256   256  1.000000   4.230798        0.435881  0.910269     True    1.267727      dense        0.551509  1.449564           0.103026   blocks.4.out_proj          256   28.155558        256             37          1   1  0.531140       1.267727    22.209478  success  1.125934  0.000034                              1  1.267727  0.237488
21        82  Linear  0.073349  256  1024  4.000000   3.531812        2.697579  0.958870     True    5.804899      dense        2.937650  2.096792           0.763795  blocks.4.ffn.net.0          256  124.966087        256             91          0   1  0.265406       5.804899    21.527693  success  2.409336  0.330063                              0  5.804899  0.496624
22        85  Linear  0.076739  256  1024  4.000000   3.830736        2.507943  0.969660     True    4.515332      dense        2.701018  2.074875           0.654690  blocks.4.ffn.net.3          256  118.815913        256             84          0   1  0.308859       4.515332    26.313881  success  2.124931  0.322134                              0  4.515332  0.514926
23        89  Linear  0.073194  256   768  3.000000   3.469322        2.438331  0.947424     True    5.044598      dense        2.647723  1.975248           0.702827        blocks.5.qkv          256   94.460073        256             83          0   1  0.271043       5.044598    18.724997  success  2.246018  0.239596                              0  5.044598  0.398311
24        90  Linear  0.085053  256   256  1.000000   3.956427        0.704199  0.907837     True    1.506568      dense        0.774120  1.450734           0.177989   blocks.5.out_proj          256   28.231478        256             46          0   1  0.435901       1.506568    18.738934  success  1.227423  0.001402                              0  1.506568  0.212922
25        97  Linear  0.072574  256  1024  4.000000   3.475496        2.505407  0.962746     True    5.258687      dense        2.740936  2.092752           0.720877  blocks.5.ffn.net.0          256  123.808913        256             98          0   1  0.250063       5.258687    23.543691  success  2.293183  0.329938                              0  5.258687  0.476079
26       100  Linear  0.075833  256  1024  4.000000   3.791237        2.410306  0.970950     True    4.322720      dense        2.595945  2.072228           0.635757  blocks.5.ffn.net.3          256  118.094082        256             82          0   1  0.308241       4.322720    27.319392  success  2.079115  0.322431                              0  4.322720  0.514664
27       104  Linear  0.071596  256   768  3.000000   3.548261        2.431803  0.952502     True    4.845635      dense        2.566071  1.963568           0.685351        blocks.6.qkv          256   91.953432        256             81          0   1  0.283140       4.845635    18.976548  success  2.201280  0.236149                              0  4.845635  0.399381
28       105  Linear  0.071217  256   256  1.000000   4.066900        0.569286  0.909577     True    1.380322      dense        0.643393  1.444239           0.139980   blocks.6.out_proj          256   27.812466        256             41          0   1  0.478969       1.380322    20.149267  success  1.174871  0.000820                              1  1.380322  0.222277
29       112  Linear  0.066806  256  1024  4.000000   3.448881        2.638120  0.959817     True    5.819968      dense        2.840411  2.096791           0.764921  blocks.6.ffn.net.0          256  124.965878        256             98          0   1  0.247374       5.819968    21.471918  success  2.412461  0.326622                              0  5.819968  0.475376
30       115  Linear  0.072895  256  1024  4.000000   3.810855        2.528099  0.969742     True    4.606745      dense        2.683408  2.074200           0.663394  blocks.6.ffn.net.3          256  118.631614        256             83          0   1  0.308531       4.606745    25.751720  success  2.146333  0.332200                              0  4.606745  0.515128
31       119  Linear  0.077352  256   768  3.000000   3.410621        2.081367  0.956616     True    4.076245      dense        2.301568  1.958914           0.610260        blocks.7.qkv          256   90.973376        256             91          0   1  0.252702       4.076245    22.317937  success  2.018971  0.242497                              0  4.076245  0.371649
32       120  Linear  0.077673  256   256  1.000000   4.334784        0.446719  0.911071     True    1.267811      dense        0.542784  1.448153           0.103055   blocks.7.out_proj          256   28.064220        256             37          0   1  0.548235       1.267811    22.135962  success  1.125971  0.001115                              0  1.267811  0.238039
33       127  Linear  0.074325  256  1024  4.000000   3.365627        2.580605  0.958955     True    5.844576      dense        2.814485  2.097067           0.766753  blocks.7.ffn.net.0          256  125.045115        256            103          0   1  0.233092       5.844576    21.395071  success  2.417556  0.325281                              0  5.844576  0.459165
34       130  Linear  0.061584  256  1024  4.000000   3.805355        2.359879  0.970968     True    4.170104      dense        2.597365  2.073124           0.620147  blocks.7.ffn.net.3          256  118.337861        256             84          0   1  0.306089       4.170104    28.377676  success  2.042083  0.322727                              0  4.170104  0.511501
35       134  Linear  0.073407  256   768  3.000000   3.698095        1.785602  0.963674     True    3.039791      dense        2.081425  1.950788           0.482844        blocks.8.qkv          256   89.286979        256             78          0   1  0.305499       3.039791    29.372733  success  1.743500  0.235482                              0  3.039791  0.412596
36       135  Linear  0.085806  256   256  1.000000   4.428445        0.227339  0.912874     True    1.125476      dense        0.349448  1.438732           0.051336   blocks.8.out_proj          256   27.461992        256             34          0   1  0.587974       1.125476    24.400344  success  1.060884  0.000396                              2  1.125476  0.241998
37       142  Linear  0.068624  256  1024  4.000000   3.473751        2.540168  0.961085     True    5.385752      dense        2.780656  2.096198           0.731246  blocks.8.ffn.net.0          256  124.795262        256             96          0   1  0.252476       5.385752    23.171371  success  2.320722  0.327510                              0  5.385752  0.483353
38       145  Linear  0.074918  256  1024  4.000000   3.816277        2.443408  0.970723     True    4.367770      dense        2.615399  2.072292           0.640260  blocks.8.ffn.net.3          256  118.111367        256             87          0   1  0.301937       4.367770    27.041574  success  2.089921  0.330381                              0  4.367770  0.504909
39       149  Linear  0.070028  256   768  3.000000   3.430903        2.059654  0.956183     True    3.984045      dense        2.295199  1.959876           0.600324        blocks.9.qkv          256   91.174979        256             90          0   1  0.256240       3.984045    22.885026  success  1.996007  0.240780                              0  3.984045  0.374727
40       150  Linear  0.079910  256   256  1.000000   4.194666        0.576816  0.909938     True    1.372498      dense        0.652395  1.447620           0.137512   blocks.9.out_proj          256   28.029813        256             41          0   1  0.498923       1.372498    20.422481  success  1.171537  0.000449                              1  1.372498  0.226258
41       157  Linear  0.073233  256  1024  4.000000   3.396134        2.438751  0.959310     True    5.225118      dense        2.796720  2.098586           0.718096  blocks.9.ffn.net.0          256  125.483334        256             99          0   1  0.240821       5.225118    24.015406  success  2.285852  0.325751                              0  5.225118  0.471714
42       160  Linear  0.082077  256  1024  4.000000   3.728086        2.221901  0.971178     True    3.944481      dense        2.528752  2.074441           0.595990  blocks.9.ffn.net.3          256  118.697415        256             88          0   1  0.290815       3.944481    30.092024  success  1.986072  0.331914                              0  3.944481  0.498197
43       165  Linear  0.074929  128   256  2.000000   3.675529        0.608208  0.920982     True    1.463778      dense        0.641389  1.188386           0.165475          src_head.0          128   15.430708        128             32          0   1  0.472971       1.463778    10.541703  success  1.209867  0.099255                              0  1.463778  0.162670
44       167  Linear  0.074886   64   128  2.000000   4.055121       -1.674786  0.914142     True    0.386362      dense       -1.581590  0.587233          -0.413005          src_head.2           64    3.865740         64             14          0   1  0.816515       0.386362    10.005482  success  0.621580  0.069889                              0  0.386362  0.095332
45       169  Linear  0.039873  256   256  1.000000   3.195137        0.552342  0.896424     True    1.488914      dense        0.933053  1.518406           0.172870         dest_head.0          256   32.991832        256             43          0   1  0.334755       1.488914    22.158317  success  1.220211  0.000244                              2  1.488914  0.236868
46       171  Linear  0.074755   73   256  3.506849   3.240743       -0.505953  0.943118     True    0.698036      dense       -0.209513  0.983336          -0.156122         dest_head.2           73    9.623573         73             26          0   1  0.439446       0.698036    13.786649  success  0.835485  0.159485                              0  0.698036  0.137379
47       173  Conv2d  0.109778  256   256  1.000000  26.945045       -9.683407  1.065095     True    0.437143     conv2d       -8.598554  2.402866          -0.359376        value_conv.0         2304  252.851635       2304             30          0   9  4.736895       0.437143   578.418154  success  0.661168  0.003458  under-trained               6  0.437143  0.400553
48       177  Linear  0.144487  128   256  2.000000   3.615318       -1.971623  0.954474     True    0.284871      dense       -0.867748  1.108622          -0.545352         value_mlp.0          128   12.841682        128             44          0   1  0.394274       0.284871    45.079002  success  0.533733  0.095910                              0  0.284871  0.122627
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0  0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 22:01:58 2025      Time elapsed: 90.44549s
Begin: Training epoch 3                        Current time: Sat Oct 25 22:01:58 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:02:18 2025      Time elapsed: 1831.71937      ETA: 69733.55664s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:02:38 2025      Time elapsed: 1851.41463      ETA: 34315.97022s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:02:57 2025      Time elapsed: 1871.09685      ETA: 22496.82119s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:03:17 2025      Time elapsed: 1890.82222      ETA: 16577.78404s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:03:37 2025      Time elapsed: 1910.66784      ETA: 13019.29081s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:03:57 2025      Time elapsed: 1930.57481      ETA: 10640.68484s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:04:17 2025      Time elapsed: 1950.50069      ETA: 8936.07963s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:04:37 2025      Time elapsed: 1970.44097      ETA: 7652.70015s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:04:57 2025      Time elapsed: 1990.37572      ETA: 6650.06646s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:05:17 2025      Time elapsed: 2010.38078      ETA: 5844.17695s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:05:37 2025      Time elapsed: 2030.55977      ETA: 5181.61937s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:05:57 2025      Time elapsed: 2050.76965      ETA: 4626.19456s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:06:17 2025      Time elapsed: 2070.90871      ETA: 4152.96848s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:06:38 2025      Time elapsed: 2091.12545      ETA: 3744.60823s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:06:58 2025      Time elapsed: 2111.50910      ETA: 3388.26828s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:07:18 2025      Time elapsed: 2131.81507      ETA: 3073.81087s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:07:38 2025      Time elapsed: 2152.10619      ETA: 2793.94022s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:07:59 2025      Time elapsed: 2172.44483      ETA: 2542.96737s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:08:19 2025      Time elapsed: 2192.75562      ETA: 2316.24239s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:08:39 2025      Time elapsed: 2213.01802      ETA: 2110.11269s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:09:00 2025      Time elapsed: 2233.32979      ETA: 1921.72712s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:09:20 2025      Time elapsed: 2253.63802      ETA: 1748.61823s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:09:40 2025      Time elapsed: 2273.92839      ETA: 1588.78388s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:10:01 2025      Time elapsed: 2294.16311      ETA: 1440.54326s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:10:21 2025      Time elapsed: 2314.44887      ETA: 1302.57183s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:10:41 2025      Time elapsed: 2334.86375      ETA: 1173.71805s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:11:02 2025      Time elapsed: 2355.25289      ETA: 1052.88527s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:11:22 2025      Time elapsed: 2375.54011      ETA: 939.18675s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:11:42 2025      Time elapsed: 2395.83089      ETA: 831.93162s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:12:03 2025      Time elapsed: 2416.27462      ETA: 730.52036s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:12:23 2025      Time elapsed: 2436.83164      ETA: 634.36230s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:12:44 2025      Time elapsed: 2457.15444      ETA: 542.87756s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:13:04 2025      Time elapsed: 2477.66005      ETA: 455.73929s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:13:25 2025      Time elapsed: 2498.45541      ETA: 372.56379s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:13:46 2025      Time elapsed: 2519.15052      ETA: 292.94122s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:14:06 2025      Time elapsed: 2539.66022      ETA: 216.57658s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:14:27 2025      Time elapsed: 2560.19786      ETA: 143.23269s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:14:47 2025      Time elapsed: 2580.74853      ETA: 72.66844s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:15:08 2025      Time elapsed: 2601.18243      ETA: 4.66879s
Epoch 3: Avg Policy Loss=2.9580, Avg Value Loss=0.5476
  End: Training epoch 3                        Current time: Sat Oct 25 22:15:09 2025      Time elapsed: 790.40801s
Begin: Validating epoch 3                      Current time: Sat Oct 25 22:15:09 2025      
Validation: Policy Loss=2.9426, Value Loss=0.5220, Top-1 Acc=0.1563, Top-5 Acc=0.4430
  End: Validating epoch 3                      Current time: Sat Oct 25 22:15:33 2025      Time elapsed: 23.84565s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_3.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 22:15:33 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.100336   19    32  1.684211   8.449086       -1.340973  0.944548     True    0.693886     conv2d       -1.045493  1.496016          -0.158712     conv_stem.net.0          171   31.333989        171             17          0   9  1.806669       0.693886    45.157290  success  0.832998  0.127986  under-trained               0   0.693886  0.422990
1          6  Conv2d  0.117802   32    64  2.000000  19.507448       -3.394567  0.969342     True    0.669863     conv2d       -3.009123  1.800847          -0.174014     conv_stem.net.3          288   63.218967        288             10          0   9  5.852569       0.669863    94.375942  success  0.818452  0.176752  under-trained               0   0.669863  0.570042
2          9  Conv2d  0.152595   64   256  4.000000   8.827330        8.034580  0.973566     True    8.131929     conv2d        8.726823  2.409515           0.910194                proj           64  256.752620         64             14          0   1  2.091942       8.131929    31.573395  success  2.851654  1.025010  under-trained               0   8.131929  6.093653
3         14  Linear  0.086787  256   768  3.000000   2.632968        2.597549  0.895220     True    9.694994      dense        2.913614  2.056535           0.986548        blocks.0.qkv          256  113.902911        256            130          0   1  0.143221       9.694994    11.748631  success  3.113678  0.239634                              0   9.694994  0.280559
4         15  Linear  0.096728  256   256  1.000000   3.470492        1.895396  0.873525     True    3.516787      dense        1.908174  1.484793           0.546146   blocks.0.out_proj          256   30.534641        256             50          0   1  0.349380       3.516787     8.682539  success  1.875310  0.000807                              1   3.516787  0.199262
5         22  Linear  0.064174  256  1024  4.000000   3.063924        2.550775  0.947092     True    6.800157      dense        2.827211  2.129326           0.832519  blocks.0.ffn.net.0          256  134.687175        256            104          0   1  0.202384       6.800157    19.806480  success  2.607711  0.332208                              0   6.800157  0.457474
6         25  Linear  0.073504  256  1024  4.000000   3.318701        2.757831  0.955339     True    6.776370      dense        2.888854  2.101770           0.830997  blocks.0.ffn.net.3          256  126.406636        256             98          0   1  0.234224       6.776370    18.654035  success  2.603146  0.316822                              0   6.776370  0.469875
7         29  Linear  0.068963  256   768  3.000000   2.839369        2.795323  0.906579     True    9.649113      dense        2.977515  2.045112           0.984487        blocks.1.qkv          256  110.945979        256            109          0   1  0.176180       9.649113    11.498050  success  3.106302  0.241745                              0   9.649113  0.333308
8         30  Linear  0.092578  256   256  1.000000   3.454669        1.183857  0.891980     True    2.201320      dense        1.268190  1.469482           0.342683   blocks.1.out_proj          256   29.476929        256             54          1   1  0.334038       2.201320    13.390572  success  1.483685  0.000002                              1   2.201320  0.190590
9         37  Linear  0.067357  256  1024  4.000000   3.090284        2.545356  0.947995     True    6.662911      dense        2.843936  2.127740           0.823664  blocks.1.ffn.net.0          256  134.196261        256            108          0   1  0.201138       6.662911    20.140784  success  2.581262  0.326267                              0   6.662911  0.451545
10        40  Linear  0.075142  256  1024  4.000000   3.203759        2.523727  0.956638     True    6.133934      dense        2.729271  2.097781           0.787739  blocks.1.ffn.net.3          256  125.250800        256            113          0   1  0.207312       6.133934    20.419325  success  2.476678  0.329225                              0   6.133934  0.426436
11        44  Linear  0.075077  256   768  3.000000   2.566263        2.666535  0.883471     True   10.941400      dense        2.949727  2.089271           1.039073        blocks.2.qkv          256  122.820410        256            129          0   1  0.137902      10.941400    11.225292  success  3.307779  0.243486                              0  10.941400  0.285787
12        45  Linear  0.084440  256   256  1.000000   3.261474        2.007643  0.865313     True    4.126321      dense        2.020486  1.497148           0.615563   blocks.2.out_proj          256   31.415810        256             58          0   1  0.296946       4.126321     7.613515  success  2.031335  0.001135                              0   4.126321  0.181020
13        52  Linear  0.063944  256  1024  4.000000   2.982831        2.367384  0.946865     True    6.218278      dense        2.746956  2.132088           0.793670  blocks.2.ffn.net.0          256  135.546487        256            116          0   1  0.184101       6.218278    21.798073  success  2.493648  0.326609                              0   6.218278  0.426472
14        55  Linear  0.071754  256  1024  4.000000   3.218899        2.469340  0.956739     True    5.849762      dense        2.708704  2.102000           0.767138  blocks.2.ffn.net.3          256  126.473613        256            108          0   1  0.213514       5.849762    21.620299  success  2.418628  0.324982                              0   5.849762  0.442387
15        59  Linear  0.068509  256   768  3.000000   2.757807        2.837290  0.895396     True   10.686148      dense        3.041182  2.060298           1.028821        blocks.3.qkv          256  114.894189        256            115          0   1  0.163916      10.686148    10.751694  success  3.268967  0.240557                              0  10.686148  0.319479
16        60  Linear  0.085777  256   256  1.000000   3.454852        1.665124  0.882049     True    3.033660      dense        1.686525  1.477245           0.481967   blocks.3.out_proj          256   30.008579        256             52          0   1  0.340427       3.033660     9.891872  success  1.741741  0.000734                              1   3.033660  0.193880
17        67  Linear  0.063243  256  1024  4.000000   3.026549        2.440998  0.947045     True    6.405140      dense        2.771950  2.129907           0.806529  blocks.3.ffn.net.0          256  134.867406        256            108          0   1  0.195005       6.405140    21.056122  success  2.530838  0.331973                              0   6.405140  0.446197
18        70  Linear  0.067691  256  1024  4.000000   3.263264        2.441279  0.957615     True    5.598989      dense        2.693648  2.102210           0.748110  blocks.3.ffn.net.3          256  126.534761        256            100          0   1  0.226326       5.598989    22.599573  success  2.366218  0.321196                              0   5.598989  0.463023
19        74  Linear  0.080434  256   768  3.000000   2.741033        2.548240  0.903834     True    8.504801      dense        2.867795  2.052343           0.929664        blocks.4.qkv          256  112.808914        256            112          0   1  0.164512       8.504801    13.264145  success  2.916299  0.249070                              0   8.504801  0.321616
20        75  Linear  0.087212  256   256  1.000000   3.408062        1.494159  0.884610     True    2.744220      dense        1.535704  1.479771           0.438419   blocks.4.out_proj          256   30.183598        256             53          0   1  0.330773       2.744220    10.998972  success  1.656569  0.001355                              0   2.744220  0.193997
21        82  Linear  0.063025  256  1024  4.000000   3.008620        2.427528  0.948080     True    6.409995      dense        2.757333  2.128723           0.806858  blocks.4.ffn.net.0          256  134.500190        256            114          0   1  0.188125       6.409995    20.982887  success  2.531797  0.329213                              0   6.409995  0.431434
22        85  Linear  0.069183  256  1024  4.000000   3.249610        2.467512  0.958031     True    5.745471      dense        2.696351  2.100528           0.759326  blocks.4.ffn.net.3          256  126.045587        256            103          0   1  0.221661       5.745471    21.938251  success  2.396971  0.322404                              0   5.745471  0.455409
23        89  Linear  0.072801  256   768  3.000000   2.627169        2.745076  0.879508     True   11.088678      dense        3.093132  2.088058           1.044880        blocks.5.qkv          256  122.477908        256            128          0   1  0.143823      11.088678    11.045312  success  3.329967  0.246717                              0  11.088678  0.292644
24        90  Linear  0.095404  256   256  1.000000   3.242656        2.149089  0.858018     True    4.599977      dense        2.157655  1.505242           0.662756   blocks.5.out_proj          256   32.006810        256             57          0   1  0.297047       4.599977     6.958036  success  2.144756  0.000191                              1   4.599977  0.183165
25        97  Linear  0.066293  256  1024  4.000000   3.057036        2.428565  0.949396     True    6.228995      dense        2.747587  2.129027           0.794418  blocks.5.ffn.net.0          256  134.594375        256            109          0   1  0.197028       6.228995    21.607718  success  2.495795  0.330993                              0   6.228995  0.447624
26       100  Linear  0.071916  256  1024  4.000000   3.175916        2.335828  0.957895     True    5.438530      dense        2.614454  2.101181           0.735482  blocks.5.ffn.net.3          256  126.235459        256            107          0   1  0.210354       5.438530    23.211320  success  2.332066  0.324727                              0   5.438530  0.440799
27       104  Linear  0.080501  256   768  3.000000   2.712872        2.626521  0.894315     True    9.293299      dense        2.976937  2.056320           0.968170        blocks.6.qkv          256  113.846634        256            123          0   1  0.154444       9.293299    12.250401  success  3.048491  0.234419                              0   9.293299  0.296996
28       105  Linear  0.083704  256   256  1.000000   3.510481        1.739015  0.880120     True    3.128802      dense        1.757223  1.478060           0.495378   blocks.6.out_proj          256   30.064900        256             48          0   1  0.362357       3.128802     9.609079  success  1.768842  0.000776                              1   3.128802  0.202480
29       112  Linear  0.054748  256  1024  4.000000   3.056733        2.428734  0.946816     True    6.230921      dense        2.789876  2.133998           0.794552  blocks.6.ffn.net.0          256  136.143992        256            108          0   1  0.197909       6.230921    21.849739  success  2.496181  0.327480                              0   6.230921  0.453018
30       115  Linear  0.076460  256  1024  4.000000   3.213709        2.381197  0.956561     True    5.507437      dense        2.676394  2.103948           0.740950  blocks.6.ffn.net.3          256  127.042240        256            106          0   1  0.215014       5.507437    23.067397  success  2.346793  0.331466                              0   5.507437  0.447927
31       119  Linear  0.078571  256   768  3.000000   2.631681        2.497750  0.895887     True    8.894232      dense        2.880331  2.064587           0.949108        blocks.7.qkv          256  116.034481        256            129          0   1  0.143661       8.894232    13.046037  success  2.982320  0.242822                              0   8.894232  0.286098
32       120  Linear  0.086451  256   256  1.000000   3.372120        1.819399  0.875109     True    3.463710      dense        1.839181  1.491108           0.539542   blocks.7.out_proj          256   30.981900        256             52          1   1  0.328954       3.463710     8.944716  success  1.861104  0.000005                              1   3.463710  0.195035
33       127  Linear  0.063874  256  1024  4.000000   2.991549        2.417154  0.945864     True    6.426789      dense        2.774958  2.134543           0.807994  blocks.7.ffn.net.0          256  136.314788        256            112          0   1  0.188184       6.426789    21.210404  success  2.535111  0.327251                              0   6.426789  0.437764
34       130  Linear  0.066230  256  1024  4.000000   3.207980        2.291092  0.957970     True    5.178276      dense        2.623430  2.102661           0.714185  blocks.7.ffn.net.3          256  126.666417        256            104          0   1  0.216510       5.178276    24.461117  success  2.275583  0.321842                              0   5.178276  0.450659
35       134  Linear  0.073168  256   768  3.000000   2.798127        2.225824  0.913916     True    6.244094      dense        2.727470  2.045920           0.795469        blocks.8.qkv          256  111.152639        256            106          0   1  0.174649       6.244094    17.801243  success  2.498819  0.240338                              0   6.244094  0.339985
36       135  Linear  0.090630  256   256  1.000000   3.338592        1.280674  0.887042     True    2.418784      dense        1.364465  1.473073           0.383597   blocks.8.out_proj          256   29.721685        256             55          0   1  0.315336       2.418784    12.287863  success  1.555244  0.001473                              0   2.418784  0.186355
37       142  Linear  0.059362  256  1024  4.000000   3.061077        2.375257  0.947667     True    5.969728      dense        2.759850  2.134091           0.775955  blocks.8.ffn.net.0          256  136.172975        256            105          0   1  0.201141       5.969728    22.810585  success  2.443303  0.333225                              0   5.969728  0.462014
38       145  Linear  0.069219  256  1024  4.000000   3.290137        2.370214  0.958105     True    5.252908      dense        2.655143  2.101737           0.720400  blocks.8.ffn.net.3          256  126.397209        256             97          0   1  0.232528       5.252908    24.062332  success  2.291922  0.327286                              0   5.252908  0.472502
39       149  Linear  0.075134  256   768  3.000000   2.740731        2.650796  0.894052     True    9.272261      dense        2.981931  2.067372           0.967186        blocks.9.qkv          256  116.780974        256            113          0   1  0.163754       9.272261    12.594660  success  3.045039  0.242434                              0   9.272261  0.321987
40       150  Linear  0.086914  256   256  1.000000   3.441111        1.997928  0.869783     True    3.807199      dense        2.010387  1.492806           0.580606   blocks.9.out_proj          256   31.103264        256             49          0   1  0.348730       3.807199     8.169592  success  1.951205  0.001276                              0   3.807199  0.201142
41       157  Linear  0.060984  256  1024  4.000000   2.967014        2.378967  0.944072     True    6.335855      dense        2.787548  2.139453           0.801805  blocks.9.ffn.net.0          256  137.864517        256            114          0   1  0.184228       6.335855    21.759416  success  2.517112  0.326812                              0   6.335855  0.434198
42       160  Linear  0.067348  256  1024  4.000000   3.217798        2.248438  0.957419     True    4.997472      dense        2.641191  2.105940           0.698750  blocks.9.ffn.net.3          256  127.626364        256            107          0   1  0.214403       4.997472    25.538183  success  2.235503  0.331455                              0   4.997472  0.447699
43       165  Linear  0.085242  128   256  2.000000   2.869106        0.891365  0.895151     True    2.044923      dense        0.974109  1.233623           0.310677          src_head.0          128   17.124703        128             47          0   1  0.272637       2.044923     8.374252  success  1.430008  0.101085                              0   2.044923  0.124929
44       167  Linear  0.083469   64   128  2.000000   3.624157       -1.270763  0.902248     True    0.446029      dense       -1.126959  0.615139          -0.350637          src_head.2           64    4.122292         64             14          0   1  0.701336       0.446029     9.242201  success  0.667854  0.071414                              0   0.446029  0.098479
45       169  Linear  0.043721  256   256  1.000000   2.655484        0.893199  0.874091     True    2.169503      dense        1.341194  1.586782           0.336360         dest_head.0          256   38.617291        256             57          0   1  0.219274       2.169503    17.800064  success  1.472923  0.001975                              0   2.169503  0.207345
46       171  Linear  0.073091   73   256  3.506849   3.139631        0.203376  0.919757     True    1.160852      dense        0.369418  1.058447           0.064777         dest_head.2           73   11.440540         73             16          0   1  0.534908       1.160852     9.855295  success  1.077428  0.159719                              0   1.160852  0.210523
47       173  Conv2d  0.061873  256   256  1.000000   9.417949       -1.956032  1.063914     True    0.619881     conv2d       -1.196849  2.405058          -0.207692        value_conv.0         2304  254.131289       2304             84          0   9  0.918474       0.619881   409.968078  success  0.787325  0.002013  under-trained               6   0.619881  0.365765
48       177  Linear  0.135437  128   256  2.000000   6.348428       -3.079227  0.952699     True    0.327312      dense       -2.499263  1.111223          -0.485038         value_mlp.0          128   12.918825        128             18          0   1  1.260636       0.327312    39.469416  success  0.572112  0.096486  under-trained               0   0.327312  0.196673
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 22:17:04 2025      Time elapsed: 91.02886s
Begin: Training epoch 4                        Current time: Sat Oct 25 22:17:04 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:17:23 2025      Time elapsed: 2737.07101      ETA: 104200.29357s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:17:43 2025      Time elapsed: 2756.75518      ETA: 51096.45735s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:18:03 2025      Time elapsed: 2776.50704      ETA: 33382.86971s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:18:23 2025      Time elapsed: 2796.42363      ETA: 24517.64421s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:18:43 2025      Time elapsed: 2816.54737      ETA: 19191.95385s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:19:03 2025      Time elapsed: 2836.62659      ETA: 15634.54027s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:19:23 2025      Time elapsed: 2856.79526      ETA: 13088.20345s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:19:43 2025      Time elapsed: 2877.06387      ETA: 11173.79682s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:20:04 2025      Time elapsed: 2897.31246      ETA: 9680.24287s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:20:24 2025      Time elapsed: 2917.43217      ETA: 8480.97533s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:20:44 2025      Time elapsed: 2937.50560      ETA: 7495.98022s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:21:04 2025      Time elapsed: 2957.63177      ETA: 6671.92434s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:21:24 2025      Time elapsed: 2977.81803      ETA: 5971.67048s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:21:44 2025      Time elapsed: 2998.05993      ETA: 5368.66876s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:22:05 2025      Time elapsed: 3018.39543      ETA: 4843.51855s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:22:25 2025      Time elapsed: 3038.97065      ETA: 4381.81581s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:22:46 2025      Time elapsed: 3059.59684      ETA: 3972.07662s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:23:07 2025      Time elapsed: 3080.17108      ETA: 3605.51138s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:23:27 2025      Time elapsed: 3100.68144      ETA: 3275.29877s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:23:48 2025      Time elapsed: 3121.17946      ETA: 2976.04462s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:24:08 2025      Time elapsed: 3141.64337      ETA: 2703.30932s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:24:29 2025      Time elapsed: 3162.13651      ETA: 2453.53047s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:24:49 2025      Time elapsed: 3182.47142      ETA: 2223.57895s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:25:09 2025      Time elapsed: 3202.77319      ETA: 2011.07467s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:25:29 2025      Time elapsed: 3223.11253      ETA: 1813.96773s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:25:50 2025      Time elapsed: 3243.41997      ETA: 1630.44227s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:26:10 2025      Time elapsed: 3263.65564      ETA: 1458.97495s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:26:30 2025      Time elapsed: 3283.85069      ETA: 1298.29383s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:26:50 2025      Time elapsed: 3304.07441      ETA: 1147.31136s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:27:11 2025      Time elapsed: 3324.40995      ETA: 1005.07994s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:27:31 2025      Time elapsed: 3344.77561      ETA: 870.72062s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:27:51 2025      Time elapsed: 3365.06756      ETA: 743.46961s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:28:12 2025      Time elapsed: 3385.31399      ETA: 622.69260s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:28:32 2025      Time elapsed: 3405.60347      ETA: 507.83558s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:28:52 2025      Time elapsed: 3425.90307      ETA: 398.38359s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:29:13 2025      Time elapsed: 3446.17564      ETA: 293.88220s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:29:33 2025      Time elapsed: 3466.40418      ETA: 193.93126s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:29:53 2025      Time elapsed: 3486.59343      ETA: 98.17513s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:30:13 2025      Time elapsed: 3506.76976      ETA: 6.29420s
Epoch 4: Avg Policy Loss=2.9170, Avg Value Loss=0.5303
  End: Training epoch 4                        Current time: Sat Oct 25 22:30:14 2025      Time elapsed: 790.62711s
Begin: Validating epoch 4                      Current time: Sat Oct 25 22:30:14 2025      
Validation: Policy Loss=2.9059, Value Loss=0.5023, Top-1 Acc=0.1671, Top-5 Acc=0.4593
  End: Validating epoch 4                      Current time: Sat Oct 25 22:30:38 2025      Time elapsed: 23.62179s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_4.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 22:30:38 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max        sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.127678   19    32  1.684211   4.956140       -0.399927  0.941647     True    0.830437     conv2d        0.037323  1.496207          -0.080693     conv_stem.net.0          171   31.347819        171             33          0   9  0.688676       0.830437    37.748579  success  0.911283  1.331548e-01                              0   0.830437  0.335421
1          6  Conv2d  0.131746   32    64  2.000000   5.110929       -0.882671  0.969168     True    0.671889     conv2d        0.228911  1.791238          -0.172703     conv_stem.net.3          288   61.835525        288             61          0   9  0.526351       0.671889    92.032384  success  0.819688  1.803653e-01                              0   0.671889  0.355696
2          9  Conv2d  0.153292   64   256  4.000000   8.989585        8.066657  0.973216     True    7.894663     conv2d        8.759238  2.396953           0.897334                proj           64  249.432456         64             14          0   1  2.135306       7.894663    31.595072  success  2.809744  8.883660e-01  under-trained               0   7.894663  5.934799
3         14  Linear  0.068077  256   768  3.000000   2.487081        2.811205  0.863001     True   13.499667      dense        3.106091  2.119894           1.130323        blocks.0.qkv          256  131.793456        256            131          0   1  0.129927      13.499667     9.762719  success  3.674189  2.412244e-01                              0  13.499667  0.280502
4         15  Linear  0.093468  256   256  1.000000   2.934776        2.025915  0.845292     True    4.901324      dense        2.050954  1.521010           0.690313   blocks.0.out_proj          256   33.190226        256             64          0   1  0.241847       4.901324     6.771685  success  2.213893  7.563442e-04                              2   4.901324  0.165151
5         22  Linear  0.050989  256  1024  4.000000   2.883385        2.327866  0.942202     True    6.417088      dense        2.732459  2.147388           0.807338  blocks.0.ffn.net.0          256  140.406876        256            108          0   1  0.181229       6.417088    21.880154  success  2.533197  3.332090e-01                              0   6.417088  0.447140
6         25  Linear  0.056730  256  1024  4.000000   3.131091        2.869757  0.946040     True    8.251551      dense        2.977623  2.116098           0.916536  blocks.0.ffn.net.3          256  130.646689        256            102          0   1  0.211009       8.251551    15.832986  success  2.872551  3.151055e-01                              0   8.251551  0.454026
7         29  Linear  0.048056  256   768  3.000000   2.200009        2.622736  0.867816     True   15.564962      dense        2.832803  2.117058           1.192148        blocks.1.qkv          256  130.935697        256             27          0   1  0.230942      15.564962     8.412208  success  3.945246  2.396579e-01                              0  15.564962  0.683356
8         30  Linear  0.065027  256   256  1.000000   3.153649        1.560778  0.867853     True    3.125444      dense        1.665583  1.508216           0.494912   blocks.1.out_proj          256   32.226746        256             56          0   1  0.287793       3.125444    10.311094  success  1.767892  1.391914e-04                              1   3.125444  0.187984
9         37  Linear  0.046240  256  1024  4.000000   2.945247        2.433063  0.942090     True    6.700359      dense        2.802371  2.147826           0.826098  blocks.1.ffn.net.0          256  140.548269        256            101          0   1  0.193559       6.700359    20.976229  success  2.588505  3.244887e-01                              0   6.700359  0.471676
10        40  Linear  0.058348  256  1024  4.000000   3.100132        2.716632  0.946520     True    7.521346      dense        2.881473  2.114018           0.876296  blocks.1.ffn.net.3          256  130.022476        256            110          0   1  0.200240       7.521346    17.287130  success  2.742507  3.269912e-01                              0   7.521346  0.431359
11        44  Linear  0.064539  256   768  3.000000   2.388483        2.755256  0.856047     True   14.241607      dense        3.057414  2.150663           1.153559        blocks.2.qkv          256  141.469527        256            136          0   1  0.119061      14.241607     9.933537  success  3.773805  2.361091e-01                              0  14.241607  0.271424
12        45  Linear  0.077640  256   256  1.000000   2.916630        2.263063  0.827738     True    5.969213      dense        2.288135  1.552196           0.775917   blocks.2.out_proj          256   35.661167        256             59          1   1  0.249524       5.969213     5.974182  success  2.443197  2.244483e-07                              1   5.969213  0.177973
13        52  Linear  0.049450  256  1024  4.000000   2.821514        2.199591  0.940110     True    6.019747      dense        2.717359  2.155161           0.779578  blocks.2.ffn.net.0          256  142.942320        256            115          0   1  0.169857       6.019747    23.745570  success  2.453517  3.268155e-01                              0   6.019747  0.429462
14        55  Linear  0.071010  256  1024  4.000000   3.018332        2.515788  0.947388     True    6.815577      dense        2.762486  2.119140           0.833503  blocks.2.ffn.net.3          256  131.564964        256            112          0   1  0.190714       6.815577    19.303569  success  2.610666  3.216033e-01                              0   6.815577  0.426806
15        59  Linear  0.065835  256   768  3.000000   2.506838        2.962161  0.862091     True   15.192615      dense        3.162045  2.127677           1.181633        blocks.3.qkv          256  134.176806        256            124          0   1  0.135318      15.192615     8.831713  success  3.897770  2.392093e-01                              0  15.192615  0.299507
16        60  Linear  0.071040  256   256  1.000000   3.050782        2.018848  0.847264     True    4.589313      dense        2.055440  1.529615           0.661748   blocks.3.out_proj          256   33.854426        256             56          0   1  0.274047       4.589313     7.376796  success  2.142268  1.174735e-03                              0   4.589313  0.186038
17        67  Linear  0.046917  256  1024  4.000000   2.890822        2.294387  0.939828     True    6.218420      dense        2.762436  2.154045           0.793680  blocks.3.ffn.net.0          256  142.575375        256            106          0   1  0.183653       6.218420    22.927912  success  2.493676  3.330609e-01                              0   6.218420  0.458281
18        70  Linear  0.068004  256  1024  4.000000   2.972203        2.424045  0.948070     True    6.539908      dense        2.695970  2.120397           0.815572  blocks.3.ffn.net.3          256  131.946311        256            115          0   1  0.183909       6.539908    20.175561  success  2.557324  3.182723e-01                              0   6.539908  0.417332
19        74  Linear  0.063133  256   768  3.000000   2.497281        2.718897  0.870646     True   12.267129      dense        3.027152  2.118885           1.088743        blocks.4.qkv          256  131.487768        256            125          0   1  0.133921      12.267129    10.718708  success  3.502446  2.427733e-01                              0  12.267129  0.295115
20        75  Linear  0.074051  256   256  1.000000   3.036721        1.635824  0.861454     True    3.456854      dense        1.741176  1.514952           0.538681   blocks.4.out_proj          256   32.730428        256             58          0   1  0.267435       3.456854     9.468269  success  1.859262  7.513780e-04                              1   3.456854  0.180949
21        82  Linear  0.047773  256  1024  4.000000   2.842287        2.227689  0.941313     True    6.078081      dense        2.714237  2.152513           0.783766  blocks.4.ffn.net.0          256  142.073312        256            114          0   1  0.172546       6.078081    23.374700  success  2.465376  3.270688e-01                              0   6.078081  0.433478
22        85  Linear  0.059175  256  1024  4.000000   3.071382        2.498433  0.949889     True    6.508122      dense        2.734084  2.117711           0.813456  blocks.4.ffn.net.3          256  131.132806        256            104          0   1  0.203116       6.508122    20.149099  success  2.551102  3.203528e-01                              0   6.508122  0.449995
23        89  Linear  0.068152  256   768  3.000000   2.400821        2.784051  0.850094     True   14.441916      dense        3.135446  2.155516           1.159625        blocks.5.qkv          256  143.059348        256            137          0   1  0.119680      14.441916     9.905842  success  3.800252  2.495231e-01                              0  14.441916  0.271590
24        90  Linear  0.086944  256   256  1.000000   2.648706        2.168072  0.813459     True    6.584758      dense        2.212450  1.574097           0.818540   blocks.5.out_proj          256   37.505702        256             80          1   1  0.184331       6.584758     5.695836  success  2.566078  4.865650e-05                              2   6.584758  0.139973
25        97  Linear  0.047547  256  1024  4.000000   2.835722        2.233559  0.939219     True    6.132689      dense        2.760740  2.158483           0.787651  blocks.5.ffn.net.0          256  144.040037        256            111          0   1  0.174239       6.132689    23.487258  success  2.476427  3.326943e-01                              0   6.132689  0.442991
26       100  Linear  0.064103  256  1024  4.000000   2.973674        2.373389  0.947008     True    6.282514      dense        2.694494  2.123363           0.798133  blocks.5.ffn.net.3          256  132.850377        256            111          0   1  0.187333       6.282514    21.146055  success  2.506494  3.228497e-01                              0   6.282514  0.427815
27       104  Linear  0.066901  256   768  3.000000   2.573001        2.756144  0.868281     True   11.780902      dense        3.120381  2.106714           1.071179        blocks.6.qkv          256  127.853881        256            123          0   1  0.141833      11.780902    10.852639  success  3.432332  2.375206e-01                              0  11.780902  0.297861
28       105  Linear  0.071124  256   256  1.000000   3.018850        1.880722  0.856002     True    4.197522      dense        1.915820  1.515982           0.622993   blocks.6.out_proj          256   32.808187        256             59          0   1  0.262832       4.197522     7.816085  success  2.048785  6.350399e-04                              1   4.197522  0.177413
29       112  Linear  0.053580  256  1024  4.000000   2.745103        2.215135  0.936152     True    6.411220      dense        2.746498  2.165105           0.806941  blocks.6.ffn.net.0          256  146.253207        256            124          0   1  0.156715       6.411220    22.812071  success  2.532039  3.268946e-01                              0   6.411220  0.408541
30       115  Linear  0.073096  256  1024  4.000000   2.897760        2.385194  0.945050     True    6.654519      dense        2.701724  2.127832           0.823117  blocks.6.ffn.net.3          256  134.224536        256            118          0   1  0.174703       6.654519    20.170435  success  2.579635  3.280188e-01                              0   6.654519  0.408632
31       119  Linear  0.068662  256   768  3.000000   2.426010        2.567284  0.868729     True   11.434923      dense        2.972312  2.127048           1.058233        blocks.7.qkv          256  133.982588        256            135          0   1  0.122731      11.434923    11.716964  success  3.381556  2.410041e-01                              0  11.434923  0.272936
32       120  Linear  0.082512  256   256  1.000000   2.964164        1.909867  0.845484     True    4.408787      dense        1.986469  1.542565           0.644319   blocks.7.out_proj          256   34.879088        256             59          0   1  0.255712       4.408787     7.911266  success  2.099711  6.946612e-04                              1   4.408787  0.181839
33       127  Linear  0.046271  256  1024  4.000000   2.757136        2.351400  0.933685     True    7.125926      dense        2.809508  2.169088           0.852841  blocks.7.ffn.net.0          256  147.600491        256            114          0   1  0.164571       7.125926    20.713165  success  2.669443  3.245574e-01                              0   7.125926  0.432344
34       130  Linear  0.066735  256  1024  4.000000   2.926322        2.402455  0.945030     True    6.621876      dense        2.721580  2.128584           0.820981  blocks.7.ffn.net.3          256  134.457169        256            116          0   1  0.178854       6.621876    20.304997  success  2.573301  3.215762e-01                              0   6.621876  0.415545
35       134  Linear  0.066240  256   768  3.000000   2.480193        2.392878  0.878803     True    9.221357      dense        2.894638  2.119933           0.964795        blocks.8.qkv          256  131.805194        256            128          0   1  0.130832       9.221357    14.293470  success  3.036669  2.436245e-01                              0   9.221357  0.292849
36       135  Linear  0.081945  256   256  1.000000   2.804313        1.750564  0.845517     True    4.209589      dense        1.850313  1.535636           0.624240   blocks.8.out_proj          256   34.327006        256             68          1   1  0.218805       4.209589     8.154479  success  2.051728  5.444831e-05                              1   4.209589  0.158782
37       142  Linear  0.047157  256  1024  4.000000   2.773326        2.268663  0.935396     True    6.577028      dense        2.780831  2.167500           0.818030  blocks.8.ffn.net.0          256  147.061767        256            116          0   1  0.164649       6.577028    22.359913  success  2.564572  3.321483e-01                              0   6.577028  0.431027
38       145  Linear  0.062010  256  1024  4.000000   2.919879        2.379121  0.946264     True    6.528318      dense        2.684892  2.125949           0.814801  blocks.8.ffn.net.3          256  133.643836        256            120          0   1  0.175260       6.528318    20.471404  success  2.555057  3.247463e-01                              0   6.528318  0.407136
39       149  Linear  0.065628  256   768  3.000000   2.459937        2.503953  0.874220     True   10.420609      dense        2.928651  2.114303           1.017893        blocks.9.qkv          256  130.107700        256            135          0   1  0.125651      10.420609    12.485614  success  3.228097  2.421784e-01                              0  10.420609  0.272768
40       150  Linear  0.071562  256   256  1.000000   3.163778        1.949549  0.856435     True    4.132465      dense        1.989012  1.516078           0.616209   blocks.9.out_proj          256   32.815435        256             53          0   1  0.297218       4.132465     7.940887  success  2.032846  5.680333e-04                              1   4.132465  0.192818
41       157  Linear  0.046467  256  1024  4.000000   2.727907        2.461761  0.928974     True    7.987960      dense        2.873815  2.178144           0.902436  blocks.9.ffn.net.0          256  150.710559        256            116          0   1  0.160432       7.987960    18.867214  success  2.826298  3.227217e-01                              0   7.987960  0.428444
42       160  Linear  0.064006  256  1024  4.000000   2.925225        2.471091  0.943690     True    6.994433      dense        2.762844  2.133599           0.844753  blocks.9.ffn.net.3          256  136.018849        256            120          0   1  0.175748       6.994433    19.446729  success  2.644699  3.282875e-01                              0   6.994433  0.411428
43       165  Linear  0.075091  128   256  2.000000   2.539550        1.063380  0.867007     True    2.622573      dense        1.199586  1.285552           0.418728          src_head.0          128   19.299780        128             58          0   1  0.202153       2.622573     7.359101  success  1.619436  1.007972e-01                              0   2.622573  0.104410
44       167  Linear  0.070262   64   128  2.000000   3.021601       -0.893710  0.888072     True    0.506088      dense       -0.661920  0.642764          -0.295774          src_head.2           64    4.393024         64             17          0   1  0.490310       0.506088     8.680351  success  0.711399  6.994657e-02                              0   0.506088  0.086411
45       169  Linear  0.042845  256   256  1.000000   2.320745        1.107340  0.852304     True    3.000188      dense        1.604184  1.661620           0.477148         dest_head.0          256   45.879613        256             68          0   1  0.160164       3.000188    15.292245  success  1.732105  1.299083e-03                              0   3.000188  0.185950
46       171  Linear  0.084924   73   256  3.506849   2.339107        0.510027  0.900827     True    1.652127      dense        0.770742  1.134603           0.218043         dest_head.2           73   13.633358         73             40          0   1  0.211731       1.652127     8.252002  success  1.285351  1.646926e-01                              0   1.652127  0.108538
47       173  Conv2d  0.047800  256   256  1.000000   4.935529        0.020848  1.060268     True    1.009774     conv2d        0.903792  2.412228           0.004224        value_conv.0         2304  258.361495       2304            223          0   9  0.263543       1.009774   255.860750  success  1.004875  1.487816e-03                              7   1.009774  0.287526
48       177  Linear  0.064480  128   256  2.000000   5.072752       -1.305457  0.945407     True    0.552908      dense       -1.132201  1.121264          -0.257347         value_mlp.0          128   13.220991        128             16          0   1  1.018188       0.552908    23.911721  success  0.743578  9.387632e-02                              0   0.552908  0.202767
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  1.007277e-01  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 22:32:09 2025      Time elapsed: 90.92311s
Begin: Training epoch 5                        Current time: Sat Oct 25 22:32:09 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:32:29 2025      Time elapsed: 3642.36789      ETA: 138664.94588s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:32:48 2025      Time elapsed: 3661.89686      ETA: 67873.25843s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:33:08 2025      Time elapsed: 3681.54188      ETA: 44264.40530s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:33:28 2025      Time elapsed: 3701.26323      ETA: 32450.82545s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:33:47 2025      Time elapsed: 3721.08074      ETA: 25355.44419s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:34:07 2025      Time elapsed: 3740.96591      ETA: 20618.95717s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:34:27 2025      Time elapsed: 3760.94656      ETA: 17230.50804s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:34:47 2025      Time elapsed: 3781.04382      ETA: 14684.62895s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:35:08 2025      Time elapsed: 3801.18122      ETA: 12700.16883s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:35:28 2025      Time elapsed: 3821.34132      ETA: 11108.63924s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:35:48 2025      Time elapsed: 3841.48066      ETA: 9802.76021s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:36:08 2025      Time elapsed: 3861.72495      ETA: 8711.40787s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:36:28 2025      Time elapsed: 3882.02278      ETA: 7784.94878s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:36:49 2025      Time elapsed: 3902.33892      ETA: 6987.97406s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:37:09 2025      Time elapsed: 3922.66613      ETA: 6294.57159s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:37:29 2025      Time elapsed: 3942.92630      ETA: 5685.20689s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:37:50 2025      Time elapsed: 3963.12663      ETA: 5145.07087s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:38:10 2025      Time elapsed: 3983.41960      ETA: 4662.81395s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:38:30 2025      Time elapsed: 4003.77421      ETA: 4229.24992s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:38:51 2025      Time elapsed: 4024.35136      ETA: 3837.21903s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:39:11 2025      Time elapsed: 4045.10340      ETA: 3480.71517s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:39:32 2025      Time elapsed: 4065.73396      ETA: 3154.63994s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:39:53 2025      Time elapsed: 4086.18539      ETA: 2854.99997s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:40:13 2025      Time elapsed: 4106.64954      ETA: 2578.63369s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:40:33 2025      Time elapsed: 4127.11856      ETA: 2322.74233s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:40:54 2025      Time elapsed: 4147.55027      ETA: 2084.94162s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:41:14 2025      Time elapsed: 4167.91517      ETA: 1863.21245s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:41:35 2025      Time elapsed: 4188.32676      ETA: 1655.88490s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:41:55 2025      Time elapsed: 4208.67912      ETA: 1461.42754s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:42:15 2025      Time elapsed: 4228.97182      ETA: 1278.55915s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:42:36 2025      Time elapsed: 4249.29908      ETA: 1106.18850s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:42:56 2025      Time elapsed: 4269.82878      ETA: 943.36530s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:43:17 2025      Time elapsed: 4290.36851      ETA: 789.16778s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:43:37 2025      Time elapsed: 4310.81866      ETA: 642.81914s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:43:58 2025      Time elapsed: 4331.32337      ETA: 503.67103s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:44:18 2025      Time elapsed: 4351.91322      ETA: 371.12149s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:44:39 2025      Time elapsed: 4372.45498      ETA: 244.62113s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:44:59 2025      Time elapsed: 4392.87442      ETA: 123.69410s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:45:20 2025      Time elapsed: 4413.38146      ETA: 7.92145s
Epoch 5: Avg Policy Loss=2.8811, Avg Value Loss=0.5156
  End: Training epoch 5                        Current time: Sat Oct 25 22:45:21 2025      Time elapsed: 791.82956s
Begin: Validating epoch 5                      Current time: Sat Oct 25 22:45:21 2025      
Validation: Policy Loss=2.8713, Value Loss=0.4958, Top-1 Acc=0.1758, Top-5 Acc=0.4726
  End: Validating epoch 5                      Current time: Sat Oct 25 22:45:45 2025      Time elapsed: 24.18547s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_5.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 22:45:45 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.071079   19    32  1.684211   5.799487       -0.073140  0.937668     True    0.971379     conv2d        0.130969  1.493815          -0.012611     conv_stem.net.0          171   31.175615        171             10          0   9  1.517731       0.971379    32.094197  success  0.985585  0.131147                              0   0.971379  0.471855
1          6  Conv2d  0.127722   32    64  2.000000   5.284294       -0.946643  0.969006     True    0.661999     conv2d        0.126497  1.779490          -0.179143     conv_stem.net.3          288   60.185284        288             56          0   9  0.572513       0.661999    90.914481  success  0.813633  0.174009                              0   0.661999  0.357737
2          9  Conv2d  0.158529   64   256  4.000000   8.869298        7.810138  0.972873     True    7.595937     conv2d        8.519947  2.381432           0.880581                proj           64  240.675695         64             14          0   1  2.103158       7.595937    31.684792  success  2.756073  0.740758  under-trained               0   7.595937  5.711096
3         14  Linear  0.060748  256   768  3.000000   2.328084        2.818192  0.842569     True   16.237516      dense        3.128177  2.173439           1.210520        blocks.0.qkv          256  149.086598        256            136          0   1  0.113882      16.237516     9.181613  success  4.029580  0.240819                              0  16.237516  0.268317
4         15  Linear  0.067281  256   256  1.000000   2.683482        2.039213  0.821790     True    5.753249      dense        2.096509  1.561353           0.759913   blocks.0.out_proj          256   36.421110        256             70          1   1  0.201215       5.753249     6.330529  success  2.398593  0.000058                              1   5.753249  0.152629
5         22  Linear  0.041442  256  1024  4.000000   2.705480        2.109313  0.938027     True    6.020669      dense        2.649832  2.165170           0.779645  blocks.0.ffn.net.0          256  146.274835        256            110          0   1  0.162611       6.020669    24.295447  success  2.453705  0.331893                              0   6.020669  0.437773
6         25  Linear  0.056779  256  1024  4.000000   2.967451        2.856251  0.938449     True    9.173322      dense        2.975072  2.125977           0.962527  blocks.0.ffn.net.3          256  133.652554        256            108          0   1  0.189318       9.173322    14.569701  success  3.028749  0.313822                              0   9.173322  0.430468
7         29  Linear  0.056671  256   768  3.000000   2.302014        2.996940  0.839586     True   20.039070      dense        3.187843  2.191402           1.301878        blocks.1.qkv          256  155.382522        256            138          0   1  0.110835      20.039070     7.753979  success  4.476502  0.244162                              0  20.039070  0.270745
8         30  Linear  0.066387  256   256  1.000000   2.576574        1.638238  0.827604     True    4.323348      dense        1.871784  1.579252           0.635820   blocks.1.out_proj          256   37.953544        256             72          0   1  0.185801       4.323348     8.778740  success  2.079266  0.000548                              1   4.323348  0.150784
9         37  Linear  0.032628  256  1024  4.000000   2.748731        2.247126  0.937058     True    6.569218      dense        2.716637  2.167714           0.817514  blocks.1.ffn.net.0          256  147.134413        256            107          0   1  0.169056       6.569218    22.397553  success  2.563049  0.322733                              0   6.569218  0.453884
10        40  Linear  0.056183  256  1024  4.000000   2.950205        2.725755  0.937939     True    8.393065      dense        2.908865  2.126119           0.923921  blocks.1.ffn.net.3          256  133.696260        256            110          0   1  0.185945       8.393065    15.929372  success  2.897079  0.323337                              0   8.393065  0.422237
11        44  Linear  0.056268  256   768  3.000000   2.238767        2.710975  0.841715     True   16.252611      dense        3.045776  2.196183           1.210923        blocks.2.qkv          256  157.102365        256            149          0   1  0.101484      16.252611     9.666285  success  4.031453  0.237860                              0  16.252611  0.245157
12        45  Linear  0.071047  256   256  1.000000   2.528457        2.099698  0.799910     True    6.767472      dense        2.191105  1.605853           0.830426   blocks.2.out_proj          256   40.350882        256             75          0   1  0.176491       6.767472     5.962475  success  2.601437  0.000859                              1   6.767472  0.144410
13        52  Linear  0.038250  256  1024  4.000000   2.623056        2.074503  0.933184     True    6.178349      dense        2.685283  2.179560           0.790872  blocks.2.ffn.net.0          256  151.202741        256            120          0   1  0.148164       6.178349    24.473003  success  2.485628  0.326437                              0   6.178349  0.412276
14        55  Linear  0.063962  256  1024  4.000000   2.871204        2.522956  0.938423     True    7.563282      dense        2.801676  2.134151           0.878710  blocks.2.ffn.net.3          256  136.191665        256            112          0   1  0.176812       7.563282    18.006954  success  2.750142  0.316269                              0   7.563282  0.418875
15        59  Linear  0.057116  256   768  3.000000   2.275208        2.793763  0.841362     True   16.901117      dense        3.092518  2.190428           1.227915        blocks.3.qkv          256  155.034501        256            142          0   1  0.107013      16.901117     9.173033  success  4.111097  0.236144                              0  16.901117  0.259550
16        60  Linear  0.071296  256   256  1.000000   2.497848        1.945382  0.799629     True    6.009291      dense        2.112984  1.608906           0.778823   blocks.3.out_proj          256   40.635552        256             79          0   1  0.168521       6.009291     6.762121  success  2.451385  0.000676                              1   6.009291  0.137556
17        67  Linear  0.033199  256  1024  4.000000   2.643813        2.036714  0.933513     True    5.893456      dense        2.683825  2.178863           0.770370  blocks.3.ffn.net.0          256  150.960461        256            111          0   1  0.156024       5.893456    25.614932  success  2.427644  0.329270                              0   5.893456  0.437331
18        70  Linear  0.057197  256  1024  4.000000   2.848636        2.435153  0.939553     True    7.158943      dense        2.741759  2.135229           0.854849  blocks.3.ffn.net.3          256  136.530391        256            116          0   1  0.171641       7.158943    19.071307  success  2.675620  0.316650                              0   7.158943  0.410303
19        74  Linear  0.056121  256   768  3.000000   2.290821        2.693760  0.845603     True   14.993134      dense        3.060457  2.186645           1.175892        blocks.4.qkv          256  153.689880        256            135          0   1  0.111096      14.993134    10.250684  success  3.872097  0.243523                              0  14.993134  0.272410
20        75  Linear  0.062723  256   256  1.000000   2.576966        1.710457  0.820889     True    4.610505      dense        1.965521  1.585259           0.663749   blocks.4.out_proj          256   38.482106        256             74          0   1  0.183319       4.610505     8.346614  success  2.147209  0.000485                              1   4.610505  0.148964
21        82  Linear  0.036582  256  1024  4.000000   2.663722        2.075366  0.933458     True    6.013435      dense        2.704788  2.180366           0.779123  blocks.4.ffn.net.0          256  151.483726        256            107          0   1  0.160838       6.013435    25.190880  success  2.452231  0.325462                              0   6.013435  0.451290
22        85  Linear  0.054781  256  1024  4.000000   2.886384        2.512497  0.940437     True    7.421046      dense        2.771352  2.134681           0.870465  blocks.4.ffn.net.3          256  136.358262        256            108          0   1  0.181517       7.421046    18.374533  success  2.724160  0.317244                              0   7.421046  0.432339
23        89  Linear  0.057465  256   768  3.000000   2.267541        2.689220  0.838386     True   15.344862      dense        3.090235  2.195744           1.185963        blocks.5.qkv          256  156.943627        256            144          0   1  0.105628      15.344862    10.227764  success  3.917252  0.244306                              0  15.344862  0.254749
24        90  Linear  0.067594  256   256  1.000000   2.451166        2.028601  0.792424     True    6.723675      dense        2.166379  1.622183           0.827607   blocks.5.out_proj          256   41.896973        256             84          1   1  0.158335       6.723675     6.231261  success  2.593005  0.000057                              1   6.723675  0.131436
25        97  Linear  0.027089  256  1024  4.000000   2.605931        2.297654  0.928625     True    7.615556      dense        2.764973  2.192901           0.881702  blocks.5.ffn.net.0          256  155.919845        256            118          0   1  0.147838       7.615556    20.473862  success  2.759630  0.332425                              0   7.615556  0.423624
26       100  Linear  0.066303  256  1024  4.000000   2.757972        2.407661  0.934858     True    7.464187      dense        2.754333  2.146168           0.872982  blocks.5.ffn.net.3          256  140.013030        256            126          0   1  0.156613       7.464187    18.757975  success  2.732066  0.319351                              0   7.464187  0.386684
27       104  Linear  0.060940  256   768  3.000000   2.399332        2.731891  0.850130     True   13.759566      dense        3.114657  2.156651           1.138605        blocks.6.qkv          256  143.433553        256            129          0   1  0.123204      13.759566    10.424279  success  3.709389  0.238208                              0  13.759566  0.284332
28       105  Linear  0.068377  256   256  1.000000   2.636097        1.957211  0.823391     True    5.526696      dense        2.032059  1.570664           0.742466   blocks.6.out_proj          256   37.210413        256             70          0   1  0.195551       5.526696     6.732850  success  2.350893  0.000257                              1   5.526696  0.153533
29       112  Linear  0.036331  256  1024  4.000000   2.584010        2.343881  0.924728     True    8.073672      dense        2.804767  2.200840           0.907071  blocks.6.ffn.net.0          256  158.796227        256            123          0   1  0.142825       8.073672    19.668401  success  2.841421  0.322450                              0   8.073672  0.413278
30       115  Linear  0.061416  256  1024  4.000000   2.756556        2.499245  0.932283     True    8.065939      dense        2.809403  2.152128           0.906655  blocks.6.ffn.net.3          256  141.947522        256            122          0   1  0.159031       8.065939    17.598388  success  2.840060  0.325622                              0   8.065939  0.396711
31       119  Linear  0.056263  256   768  3.000000   2.269893        2.492840  0.851112     True   12.537742      dense        2.980733  2.180814           1.098219        blocks.7.qkv          256  151.639986        256            142          0   1  0.106567      12.537742    12.094681  success  3.540867  0.242349                              0  12.537742  0.257538
32       120  Linear  0.073648  256   256  1.000000   2.465839        1.810326  0.808891     True    5.422036      dense        2.003387  1.611481           0.734162   blocks.7.out_proj          256   40.877215        256             81          0   1  0.162871       5.422036     7.539090  success  2.328526  0.000153                              1   5.422036  0.136396
33       127  Linear  0.032997  256  1024  4.000000   2.538473        2.480751  0.920313     True    9.489889      dense        2.860447  2.207350           0.977261  blocks.7.ffn.net.0          256  161.194572        256            123          0   1  0.138719       9.489889    16.985928  success  3.080566  0.319602                              0   9.489889  0.407908
34       130  Linear  0.054232  256  1024  4.000000   2.788235        2.596024  0.931131     True    8.532249      dense        2.867076  2.154237           0.931064  blocks.7.ffn.net.3          256  142.638513        256            117          0   1  0.165322       8.532249    16.717574  success  2.921001  0.319526                              0   8.532249  0.410820
35       134  Linear  0.059101  256   768  3.000000   2.300228        2.462651  0.854901     True   11.765535      dense        2.973464  2.179871           1.070612        blocks.8.qkv          256  151.311311        256            136          0   1  0.111494      11.765535    12.860555  success  3.430093  0.242563                              0  11.765535  0.273648
36       135  Linear  0.068518  256   256  1.000000   2.539920        2.164435  0.797597     True    7.114864      dense        2.233199  1.607546           0.852167   blocks.8.out_proj          256   40.508484        256             76          0   1  0.176641       7.114864     5.693501  success  2.667370  0.001088                              0   7.114864  0.144060
37       142  Linear  0.033553  256  1024  4.000000   2.550857        2.460375  0.921237     True    9.215711      dense        2.851786  2.207424           0.964529  blocks.8.ffn.net.0          256  161.221992        256            120          0   1  0.141573       9.215711    17.494255  success  3.035739  0.330325                              0   9.215711  0.417900
38       145  Linear  0.058999  256  1024  4.000000   2.759590        2.478005  0.933022     True    7.906084      dense        2.792778  2.152056           0.897961  blocks.8.ffn.net.3          256  141.923891        256            121          0   1  0.159963       7.906084    17.951225  success  2.811776  0.324537                              0   7.906084  0.399839
39       149  Linear  0.056012  256   768  3.000000   2.332226        2.468364  0.858287     True   11.438588      dense        2.953814  2.159504           1.058372        blocks.9.qkv          256  144.378879        256            137          0   1  0.113820      11.438588    12.622089  success  3.382098  0.241574                              0  11.438588  0.266741
40       150  Linear  0.069755  256   256  1.000000   2.785394        1.899605  0.836153     True    4.808262      dense        1.974838  1.551995           0.681988   blocks.9.out_proj          256   35.644727        256             65          0   1  0.221451       4.808262     7.413224  success  2.192775  0.000803                              1   4.808262  0.166326
41       157  Linear  0.030020  256  1024  4.000000   2.496167        2.600423  0.913123     True   11.009464      dense        2.936886  2.220442           1.041766  blocks.9.ffn.net.0          256  166.127852        256            124          0   1  0.134360      11.009464    15.089549  success  3.318051  0.321253                              0  11.009464  0.403687
42       160  Linear  0.060936  256  1024  4.000000   2.697375        2.542469  0.928538     True    8.761359      dense        2.845350  2.161874           0.942571  blocks.9.ffn.net.3          256  145.169079        256            132          0   1  0.147738       8.761359    16.569242  success  2.959959  0.324092                              0   8.761359  0.376037
43       165  Linear  0.055786  128   256  2.000000   2.454691        1.248258  0.839662     True    3.224925      dense        1.421018  1.341731           0.508520          src_head.0          128   21.964978        128             51          0   1  0.203697       3.224925     6.811005  success  1.795807  0.100173                              0   3.224925  0.118258
44       167  Linear  0.077390   64   128  2.000000   2.681756       -0.656633  0.872942     True    0.569047      dense       -0.354059  0.671679          -0.244852          src_head.2           64    4.695470         64             18          0   1  0.396394       0.569047     8.251463  success  0.754352  0.068446                              0   0.569047  0.081140
45       169  Linear  0.046361  256   256  1.000000   2.085581        1.249769  0.833328     True    3.974134      dense        1.785266  1.736053           0.599243         dest_head.0          256   54.456942        256             85          1   1  0.117748       3.974134    13.702844  success  1.993523  0.000009                              1   3.974134  0.151212
46       171  Linear  0.060360   73   256  3.506849   3.049881        0.952644  0.889443     True    2.052837      dense        1.087242  1.211811           0.312354         dest_head.2           73   16.285875         73             16          0   1  0.512470       2.052837     7.933352  success  1.432772  0.170772                              0   2.052837  0.314685
47       173  Conv2d  0.058903  256   256  1.000000   4.111128        0.518216  1.055764     True    1.336755     conv2d        1.439995  2.419207           0.126052        value_conv.0         2304  262.546968       2304            298          0   9  0.180223       1.336755   196.406158  success  1.156181  0.001619                              6   1.336755  0.256001
48       177  Linear  0.084227  128   256  2.000000   3.695077       -0.355317  0.932928     True    0.801384      dense       -0.144266  1.136070          -0.096160         value_mlp.0          128   13.679487        128             28          0   1  0.509322       0.801384    17.069836  success  0.895200  0.092584                              0   0.801384  0.158051
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 22:47:16 2025      Time elapsed: 90.56260s
Begin: Training epoch 6                        Current time: Sat Oct 25 22:47:16 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:47:36 2025      Time elapsed: 4549.22808      ETA: 173189.11321s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:47:55 2025      Time elapsed: 4568.92623      ETA: 84685.04780s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:48:15 2025      Time elapsed: 4588.68359      ETA: 55171.27243s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:48:35 2025      Time elapsed: 4608.53001      ETA: 40405.28694s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:48:55 2025      Time elapsed: 4628.52297      ETA: 31538.75558s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:49:15 2025      Time elapsed: 4648.58539      ETA: 25621.45318s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:49:35 2025      Time elapsed: 4668.69903      ETA: 21389.31117s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:49:55 2025      Time elapsed: 4688.84378      ETA: 18210.29704s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:50:15 2025      Time elapsed: 4708.93658      ETA: 15733.08035s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:50:35 2025      Time elapsed: 4729.03023      ETA: 13747.29090s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:50:56 2025      Time elapsed: 4749.16959      ETA: 12119.01732s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:51:16 2025      Time elapsed: 4769.48777      ETA: 10759.16952s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:51:36 2025      Time elapsed: 4789.84722      ETA: 9605.48594s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:51:56 2025      Time elapsed: 4810.09726      ETA: 8613.50990s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:52:17 2025      Time elapsed: 4830.25848      ETA: 7750.95478s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:52:37 2025      Time elapsed: 4850.57361      ETA: 6993.92084s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:52:57 2025      Time elapsed: 4871.06741      ETA: 6323.79164s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:53:18 2025      Time elapsed: 4891.47285      ETA: 5725.74073s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:53:38 2025      Time elapsed: 4911.79132      ETA: 5188.40273s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:53:59 2025      Time elapsed: 4932.25610      ETA: 4702.90620s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:54:19 2025      Time elapsed: 4952.91736      ETA: 4261.86746s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:54:40 2025      Time elapsed: 4973.46711      ETA: 3858.95834s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:55:00 2025      Time elapsed: 4993.83522      ETA: 3489.17096s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:55:20 2025      Time elapsed: 5014.12493      ETA: 3148.45262s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:55:41 2025      Time elapsed: 5034.43278      ETA: 2833.37877s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:56:01 2025      Time elapsed: 5054.97933      ETA: 2541.09923s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:56:22 2025      Time elapsed: 5075.60012      ETA: 2268.98124s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:56:43 2025      Time elapsed: 5096.16906      ETA: 2014.80684s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:57:03 2025      Time elapsed: 5116.66970      ETA: 1776.71945s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:57:24 2025      Time elapsed: 5137.16595      ETA: 1553.13651s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:57:44 2025      Time elapsed: 5157.72225      ETA: 1342.67157s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:58:05 2025      Time elapsed: 5178.33726      ETA: 1144.08889s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:58:25 2025      Time elapsed: 5198.98458      ETA: 956.29807s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:58:46 2025      Time elapsed: 5219.51024      ETA: 778.32109s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:59:06 2025      Time elapsed: 5239.94812      ETA: 609.33111s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:59:27 2025      Time elapsed: 5260.37476      ETA: 448.59307s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 22:59:47 2025      Time elapsed: 5280.85886      ETA: 295.44264s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:00:08 2025      Time elapsed: 5301.34486      ETA: 149.27471s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:00:28 2025      Time elapsed: 5321.86927      ETA: 9.55207s
Epoch 6: Avg Policy Loss=2.8460, Avg Value Loss=0.5061
  End: Training epoch 6                        Current time: Sat Oct 25 23:00:30 2025      Time elapsed: 793.66474s
Begin: Validating epoch 6                      Current time: Sat Oct 25 23:00:30 2025      
Validation: Policy Loss=2.8353, Value Loss=0.4906, Top-1 Acc=0.1849, Top-5 Acc=0.4863
  End: Validating epoch 6                      Current time: Sat Oct 25 23:00:53 2025      Time elapsed: 23.91878s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_6.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 23:00:54 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.066798   19    32  1.684211   4.698813        0.189276  0.933014     True    1.097189     conv2d        0.448428  1.489414           0.040282     conv_stem.net.0          171   30.861314        171             25          0   9  0.739763       1.097189    28.127611  success  1.047468  0.124639                              0   1.097189  0.364819
1          6  Conv2d  0.102884   32    64  2.000000  19.416594       -3.600804  0.968848     True    0.652454     conv2d       -3.369796  1.765861          -0.185450     conv_stem.net.3          288   58.325867        288              7          0   9  6.960818       0.652454    89.394544  success  0.807747  0.163815  under-trained               0   0.652454  0.552747
2          9  Conv2d  0.162818   64   256  4.000000   8.323281        7.160499  0.972609     True    7.249327     conv2d        7.906973  2.362720           0.860298                proj           64  230.525929         64             14          0   1  1.957229       7.249327    31.799631  success  2.692457  0.606214  under-trained               0   7.249327  5.409310
3         14  Linear  0.047172  256   768  3.000000   2.205828        2.811997  0.827753     True   18.827967      dense        3.136394  2.226275           1.274803        blocks.0.qkv          256  168.374177        256            138          0   1  0.102647      18.827967     8.942770  success  4.339120  0.239073                              0  18.827967  0.263173
4         15  Linear  0.063253  256   256  1.000000   2.455053        1.945301  0.801884     True    6.199635      dense        2.069997  1.606379           0.792366   blocks.0.out_proj          256   40.399809        256             78          0   1  0.164752       6.199635     6.516482  success  2.489907  0.001355                              0   6.199635  0.136962
5         22  Linear  0.032865  256  1024  4.000000   2.504702        1.969938  0.930726     True    6.116404      dense        2.620553  2.189251           0.786496  blocks.0.ffn.net.0          256  154.614873        256            121          0   1  0.136791       6.116404    25.278723  success  2.473136  0.326949                              0   6.116404  0.401176
6         25  Linear  0.052456  256  1024  4.000000   2.857874        2.852258  0.930972     True    9.954860      dense        2.984940  2.137375           0.998035  blocks.0.ffn.net.3          256  137.206487        256            110          0   1  0.177141       9.954860    13.782865  success  3.155132  0.313598                              0   9.954860  0.421236
7         29  Linear  0.048028  256   768  3.000000   2.127349        2.856065  0.825392     True   22.006264      dense        3.127435  2.255836           1.342546        blocks.1.qkv          256  180.233844        256            147          0   1  0.092982      22.006264     8.190116  success  4.691083  0.239930                              0  22.006264  0.249099
8         30  Linear  0.065881  256   256  1.000000   2.302695        1.691292  0.792384     True    5.426050      dense        2.024558  1.655878           0.734484   blocks.1.out_proj          256   45.277036        256             82          0   1  0.143859       5.426050     8.344382  success  2.329388  0.000440                              1   5.426050  0.131765
9         37  Linear  0.029759  256  1024  4.000000   2.528382        2.081820  0.929322     True    6.658563      dense        2.674532  2.193496           0.823380  blocks.1.ffn.net.0          256  156.133341        256            113          0   1  0.143778       6.658563    23.448505  success  2.580419  0.318062                              0   6.658563  0.428498
10        40  Linear  0.048783  256  1024  4.000000   2.792377        2.656014  0.930193     True    8.936469      dense        2.883055  2.138826           0.951166  blocks.1.ffn.net.3          256  137.665818        256            117          0   1  0.165705       8.936469    15.404945  success  2.989393  0.319311                              0   8.936469  0.397555
11        44  Linear  0.050080  256   768  3.000000   2.120094        2.700670  0.827801     True   18.786434      dense        3.060920  2.247327           1.273844        blocks.2.qkv          256  176.736879        256            152          0   1  0.090852      18.786434     9.407686  success  4.334332  0.237096                              0  18.786434  0.235331
12        45  Linear  0.065471  256   256  1.000000   2.355301        2.065900  0.774464     True    7.535767      dense        2.231122  1.658709           0.877127   blocks.2.out_proj          256   45.573155        256             79          0   1  0.152483       7.535767     6.047581  success  2.745135  0.000414                              1   7.535767  0.135291
13        52  Linear  0.029513  256  1024  4.000000   2.444406        2.116622  0.924025     True    7.343521      dense        2.694472  2.210734           0.865904  blocks.2.ffn.net.0          256  162.455440        256            120          0   1  0.131856       7.343521    22.122281  success  2.709893  0.322055                              0   7.343521  0.406511
14        55  Linear  0.055062  256  1024  4.000000   2.712133        2.486045  0.929537     True    8.253504      dense        2.804189  2.151616           0.916638  blocks.2.ffn.net.3          256  141.780410        256            122          0   1  0.155009       8.253504    17.178209  success  2.872891  0.317182                              0   8.253504  0.389906
15        59  Linear  0.044454  256   768  3.000000   2.163357        2.658768  0.830757     True   16.943405      dense        3.073208  2.241370           1.229001        blocks.3.qkv          256  174.328975        256            141          0   1  0.097972      16.943405    10.288898  success  4.116237  0.236818                              0  16.943405  0.260215
16        60  Linear  0.065742  256   256  1.000000   2.298246        1.909449  0.770199     True    6.773743      dense        2.189456  1.672389           0.830829   blocks.3.out_proj          256   47.031490        256             84          0   1  0.141650       6.773743     6.943205  success  2.602642  0.000521                              1   6.773743  0.126830
17        67  Linear  0.030510  256  1024  4.000000   2.423662        1.974817  0.924203     True    6.528408      dense        2.671990  2.211041           0.814807  blocks.3.ffn.net.0          256  162.570250        256            126          0   1  0.126830       6.528408    24.901974  success  2.555075  0.321407                              0   6.528408  0.390964
18        70  Linear  0.049661  256  1024  4.000000   2.678739        2.398636  0.930603     True    7.860216      dense        2.746787  2.153024           0.895434  blocks.3.ffn.net.3          256  142.240731        256            124          0   1  0.150755       7.860216    18.096287  success  2.803608  0.313745                              0   7.860216  0.384003
19        74  Linear  0.044608  256   768  3.000000   2.127892        2.590082  0.828460     True   16.489420      dense        3.057545  2.251269           1.217205        blocks.4.qkv          256  178.348189        256            147          0   1  0.093027      16.489420    10.815916  success  4.060717  0.239463                              0  16.489420  0.246165
20        75  Linear  0.062066  256   256  1.000000   2.279166        1.792660  0.780840     True    6.117049      dense        2.109699  1.672039           0.786542   blocks.4.out_proj          256   46.993625        256             86          0   1  0.137936       6.117049     7.682402  success  2.473267  0.000587                              1   6.117049  0.126455
21        82  Linear  0.033305  256  1024  4.000000   2.414762        2.101305  0.923148     True    7.416365      dense        2.691543  2.215343           0.870191  blocks.4.ffn.net.0          256  164.188476        256            130          0   1  0.124083       7.416365    22.138672  success  2.723300  0.320849                              0   7.416365  0.383443
22        85  Linear  0.049484  256  1024  4.000000   2.729062        2.531848  0.930292     True    8.467121      dense        2.811755  2.155324           0.927736  blocks.4.ffn.net.3          256  142.996185        256            114          0   1  0.161941       8.467121    16.888407  success  2.909832  0.311650                              0   8.467121  0.413296
23        89  Linear  0.049683  256   768  3.000000   2.162953        2.586415  0.828870     True   15.695660      dense        3.068416  2.237038           1.195780        blocks.5.qkv          256  172.599005        256            147          0   1  0.095919      15.695660    10.996607  success  3.961775  0.241869                              0  15.695660  0.245833
24        90  Linear  0.070856  256   256  1.000000   2.292217        1.876823  0.777173     True    6.588409      dense        2.130215  1.667490           0.818781   blocks.5.out_proj          256   46.503980        256             86          0   1  0.139343       6.588409     7.058454  success  2.566790  0.001041                              0   6.588409  0.124780
25        97  Linear  0.031940  256  1024  4.000000   2.362176        2.293467  0.916678     True    9.352181      dense        2.763281  2.234300           0.970913  blocks.5.ffn.net.0          256  171.513990        256            133          0   1  0.118116       9.352181    18.339463  success  3.058134  0.328087                              0   9.352181  0.377228
26       100  Linear  0.051810  256  1024  4.000000   2.615483        2.476126  0.922586     True    8.845425      dense        2.825960  2.172265           0.946719  blocks.5.ffn.net.3          256  148.684197        256            128          0   1  0.142790       8.845425    16.809164  success  2.974126  0.313112                              0   8.845425  0.377348
27       104  Linear  0.050417  256   768  3.000000   2.231558        2.676736  0.834988     True   15.830408      dense        3.086811  2.212370           1.199492        blocks.6.qkv          256  163.068396        256            135          0   1  0.105996      15.830408    10.300960  success  3.978745  0.239302                              0  15.830408  0.269370
28       105  Linear  0.062297  256   256  1.000000   2.334348        1.892613  0.791424     True    6.467962      dense        2.064757  1.633568           0.810767   blocks.6.out_proj          256   43.009867        256             84          0   1  0.145589       6.467962     6.649678  success  2.543219  0.001152                              0   6.467962  0.125863
29       112  Linear  0.032405  256  1024  4.000000   2.344863        2.340265  0.912819     True    9.954947      dense        2.795972  2.241570           0.998039  blocks.6.ffn.net.0          256  174.409467        256            137          0   1  0.114899       9.954947    17.519878  success  3.155146  0.316693                              0   9.954947  0.368301
30       115  Linear  0.054906  256  1024  4.000000   2.573786        2.478807  0.920378     True    9.185390      dense        2.832060  2.178226           0.963098  blocks.6.ffn.net.3          256  150.739123        256            135          0   1  0.135450       9.185390    16.410747  success  3.030741  0.323426                              0   9.185390  0.361486
31       119  Linear  0.048283  256   768  3.000000   2.157967        2.431825  0.838931     True   13.393847      dense        2.990881  2.228659           1.126905        blocks.7.qkv          256  169.300641        256            144          0   1  0.096497      13.393847    12.640181  success  3.659760  0.243178                              0  13.393847  0.251122
32       120  Linear  0.069148  256   256  1.000000   2.276954        1.812450  0.780908     True    6.251692      dense        2.088886  1.672713           0.795998   blocks.7.out_proj          256   47.066614        256             89          0   1  0.135357       6.251692     7.528620  success  2.500338  0.000799                              1   6.251692  0.121901
33       127  Linear  0.027781  256  1024  4.000000   2.325710        2.515299  0.906572     True   12.064772      dense        2.878835  2.251496           1.081519  blocks.7.ffn.net.0          256  178.441576        256            139          0   1  0.112445      12.064772    14.790299  success  3.473438  0.319728                              0  12.064772  0.363339
34       130  Linear  0.048057  256  1024  4.000000   2.567870        2.606524  0.916674     True   10.352685      dense        2.895531  2.184448           1.015053  blocks.7.ffn.net.3          256  152.914348        256            135          0   1  0.134941      10.352685    14.770501  success  3.217559  0.320900                              0  10.352685  0.362281
35       134  Linear  0.049453  256   768  3.000000   2.156899        2.458695  0.836706     True   13.801343      dense        3.015907  2.239561           1.139921        blocks.8.qkv          256  173.604660        256            143          0   1  0.096745      13.801343    12.578824  success  3.715016  0.240195                              0  13.801343  0.257262
36       135  Linear  0.069981  256   256  1.000000   2.290177        2.149558  0.763974     True    8.681593      dense        2.279795  1.678262           0.938599   blocks.8.out_proj          256   47.671808        256             86          0   1  0.139123       8.681593     5.491136  success  2.946454  0.000932                              1   8.681593  0.124857
37       142  Linear  0.031671  256  1024  4.000000   2.320917        2.551050  0.904476     True   12.564821      dense        2.903326  2.258944           1.099156  blocks.8.ffn.net.0          256  181.527950        256            133          0   1  0.114538      12.564821    14.447317  success  3.544689  0.329886                              0  12.564821  0.379140
38       145  Linear  0.055163  256  1024  4.000000   2.545508        2.509810  0.915759     True    9.682244      dense        2.863585  2.187791           0.985976  blocks.8.ffn.net.3          256  154.095984        256            134          0   1  0.133512       9.682244    15.915317  success  3.111630  0.321872                              0   9.682244  0.362624
39       149  Linear  0.054546  256   768  3.000000   2.164164        2.399103  0.841309     True   12.839808      dense        2.960007  2.219786           1.108559        blocks.9.qkv          256  165.876971        256            149          0   1  0.095372      12.839808    12.918961  success  3.583268  0.240677                              0  12.839808  0.241180
40       150  Linear  0.059696  256   256  1.000000   2.418758        1.808058  0.803523     True    5.591328      dense        2.008781  1.615645           0.747515   blocks.9.out_proj          256   41.271045        256             79          0   1  0.159623       5.591328     7.381260  success  2.364599  0.000180                              1   5.591328  0.136506
41       157  Linear  0.029344  256  1024  4.000000   2.293008        2.693720  0.895354     True   14.953871      dense        2.992504  2.271675           1.174754  blocks.9.ffn.net.0          256  186.928114        256            141          0   1  0.108891      14.953871    12.500316  success  3.867023  0.319733                              0  14.953871  0.358228
42       160  Linear  0.052038  256  1024  4.000000   2.570074        2.626805  0.911225     True   10.521399      dense        2.960136  2.198094           1.022073  blocks.9.ffn.net.3          256  157.795269        256            132          0   1  0.136657      10.521399    14.997556  success  3.243670  0.317958                              0  10.521399  0.374143
43       165  Linear  0.041006  128   256  2.000000   2.270514        1.361306  0.813280     True    3.977028      dense        1.588020  1.408310           0.599559          src_head.0          128   25.604140        128             53          0   1  0.174518       3.977028     6.438009  success  1.994249  0.101950                              0   3.977028  0.115232
44       167  Linear  0.079611   64   128  2.000000   2.489482       -0.489285  0.857613     True    0.636003      dense       -0.123957  0.708641          -0.196541          src_head.2           64    5.112585         64             19          0   1  0.341711       0.636003     8.038619  success  0.797498  0.070609                              0   0.636003  0.079527
45       169  Linear  0.058267  256   256  1.000000   1.915191        1.343779  0.818237     True    5.030861      dense        1.915300  1.805830           0.701642         dest_head.0          256   63.948504        256             98          0   1  0.092448       5.030861    12.711245  success  2.242958  0.001350   over-trained               0   5.030861  0.124973
46       171  Linear  0.053717   73   256  3.506849   2.994895        1.163458  0.882646     True    2.446134      dense        1.326787  1.291454           0.388480         dest_head.2           73   19.563834         73             17          0   1  0.483833       2.446134     7.997858  success  1.564012  0.177076                              0   2.446134  0.367895
47       173  Conv2d  0.054224  256   256  1.000000   3.537738        0.892145  1.049216     True    1.787226     conv2d        1.831725  2.429421           0.252180        value_conv.0         2304  268.794758       2304            374          0   9  0.131223       1.787226   150.397717  success  1.336872  0.002217                              6   1.787226  0.226232
48       177  Linear  0.069105  128   256  2.000000   3.052851        0.129541  0.911427     True    1.102638      dense        0.414997  1.160518           0.042433         value_mlp.0          128   14.471663        128             40          0   1  0.324584       1.102638    13.124584  success  1.050066  0.092209                              0   1.102638  0.124389
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 23:02:23 2025      Time elapsed: 89.76111s
Begin: Training epoch 7                        Current time: Sat Oct 25 23:02:23 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:02:43 2025      Time elapsed: 5456.51837      ETA: 207729.65453s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:03:03 2025      Time elapsed: 5476.13788      ETA: 101500.21574s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:03:22 2025      Time elapsed: 5495.91291      ETA: 66079.19299s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:03:42 2025      Time elapsed: 5515.80689      ETA: 48359.83696s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:04:02 2025      Time elapsed: 5535.73029      ETA: 37720.46626s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:04:22 2025      Time elapsed: 5555.70816      ETA: 30621.21151s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:04:42 2025      Time elapsed: 5575.85162      ETA: 25545.36593s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:05:03 2025      Time elapsed: 5596.14100      ETA: 21734.01263s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:05:23 2025      Time elapsed: 5616.46041      ETA: 18765.21831s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:05:43 2025      Time elapsed: 5636.75882      ETA: 16386.05792s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:06:03 2025      Time elapsed: 5656.95051      ETA: 14435.50917s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:06:23 2025      Time elapsed: 5677.09620      ETA: 12806.58286s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:06:44 2025      Time elapsed: 5697.27809      ETA: 11425.23385s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:07:04 2025      Time elapsed: 5717.47765      ETA: 10238.36892s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:07:24 2025      Time elapsed: 5737.77479      ETA: 9207.21595s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:07:44 2025      Time elapsed: 5758.00614      ETA: 8302.32512s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:08:05 2025      Time elapsed: 5778.23072      ETA: 7501.50306s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:08:25 2025      Time elapsed: 5798.44585      ETA: 6787.40301s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:08:45 2025      Time elapsed: 5818.68090      ETA: 6146.36451s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:09:05 2025      Time elapsed: 5838.87563      ETA: 5567.36792s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:09:25 2025      Time elapsed: 5859.04123      ETA: 5041.56548s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:09:46 2025      Time elapsed: 5879.22521      ETA: 4561.74429s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:10:06 2025      Time elapsed: 5899.36948      ETA: 4121.86381s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:10:26 2025      Time elapsed: 5919.50282      ETA: 3716.95448s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:10:46 2025      Time elapsed: 5939.63702      ETA: 3342.82772s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:11:06 2025      Time elapsed: 5959.77705      ETA: 2995.93408s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:11:26 2025      Time elapsed: 5979.90907      ETA: 2673.24083s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:11:46 2025      Time elapsed: 6000.03940      ETA: 2372.15843s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:12:07 2025      Time elapsed: 6020.15358      ETA: 2090.44643s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:12:27 2025      Time elapsed: 6040.25730      ETA: 1826.17112s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:12:47 2025      Time elapsed: 6060.46438      ETA: 1577.67573s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:13:07 2025      Time elapsed: 6080.82299      ETA: 1343.48183s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:13:28 2025      Time elapsed: 6101.27994      ETA: 1122.26573s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:13:48 2025      Time elapsed: 6121.57148      ETA: 912.83434s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:14:08 2025      Time elapsed: 6141.81799      ETA: 714.20569s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:14:28 2025      Time elapsed: 6162.08401      ETA: 525.48883s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:14:49 2025      Time elapsed: 6182.37305      ETA: 345.87871s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:15:09 2025      Time elapsed: 6202.61452      ETA: 174.65257s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:15:29 2025      Time elapsed: 6222.93538      ETA: 11.16937s
Epoch 7: Avg Policy Loss=2.8112, Avg Value Loss=0.4951
  End: Training epoch 7                        Current time: Sat Oct 25 23:15:31 2025      Time elapsed: 787.30843s
Begin: Validating epoch 7                      Current time: Sat Oct 25 23:15:31 2025      
Validation: Policy Loss=2.8033, Value Loss=0.4852, Top-1 Acc=0.1930, Top-5 Acc=0.4969
  End: Validating epoch 7                      Current time: Sat Oct 25 23:15:54 2025      Time elapsed: 23.84844s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_7.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 23:15:55 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.065821   19    32  1.684211   4.212215        0.264641  0.929693     True    1.155652     conv2d        0.564817  1.482939           0.062827     conv_stem.net.0          171   30.404564        171             23          0   9  0.669793       1.155652    26.309450  success  1.075012  0.121706                              0   1.155652  0.359210
1          6  Conv2d  0.137838   32    64  2.000000   8.501802       -1.631411  0.968735     True    0.642850     conv2d       -0.932568  1.753409          -0.191890     conv_stem.net.3          288   56.677324        288             26          0   9  1.471224       0.642850    88.165643  success  0.801780  0.155267  under-trained               0   0.642850  0.437466
2          9  Conv2d  0.165144   64   256  4.000000   3.556334        2.991319  0.972479     True    6.936242     conv2d        4.076341  2.345623           0.841124                proj           64  221.626925         64             34          0   1  0.438408       6.936242    31.952017  success  2.633675  0.521569                              0   6.936242  3.157260
3         14  Linear  0.037035  256   768  3.000000   2.102518        2.734995  0.819324     True   19.990273      dense        3.109790  2.267734           1.300819        blocks.0.qkv          256  185.239783        256            141          0   1  0.092849      19.990273     9.266496  success  4.471048  0.239391                              0  19.990273  0.253203
4         15  Linear  0.068566  256   256  1.000000   2.323137        1.926708  0.781790     True    6.750811      dense        2.119461  1.650726           0.829356   blocks.0.out_proj          256   44.743080        256             80          0   1  0.147931       6.750811     6.627808  success  2.598232  0.000247                              1   6.750811  0.131594
5         22  Linear  0.032834  256  1024  4.000000   2.361495        1.906784  0.922711     True    6.418710      dense        2.633654  2.212308           0.807448  blocks.0.ffn.net.0          256  163.045029        256            128          0   1  0.120340       6.418710    25.401525  success  2.533517  0.323310                              0   6.418710  0.374510
6         25  Linear  0.043427  256  1024  4.000000   2.746317        2.774649  0.925513     True   10.240383      dense        2.941690  2.148616           1.010316  blocks.0.ffn.net.3          256  140.804483        256            110          0   1  0.166505      10.240383    13.749923  success  3.200060  0.312439                              0  10.240383  0.415246
7         29  Linear  0.041346  256   768  3.000000   2.040595        2.761207  0.819073     True   22.549582      dense        3.098525  2.294955           1.353138        blocks.1.qkv          256  197.221944        256            151          0   1  0.084682      22.549582     8.746147  success  4.748640  0.238176                              0  22.549582  0.237894
8         30  Linear  0.059632  256   256  1.000000   2.154828        1.705903  0.771620     True    6.189637      dense        2.105321  1.711277           0.791665   blocks.1.out_proj          256   51.437128        256             90          0   1  0.121730       6.189637     8.310201  success  2.487898  0.000388                              1   6.189637  0.118170
9         37  Linear  0.032007  256  1024  4.000000   2.364760        2.012971  0.920919     True    7.099654      dense        2.674698  2.217833           0.851237  blocks.1.ffn.net.0          256  165.132717        256            135          0   1  0.117460       7.099654    23.259262  success  2.664518  0.313553                              0   7.099654  0.365509
10        40  Linear  0.045346  256  1024  4.000000   2.709178        2.620049  0.924654     True    9.270460      dense        2.876320  2.150959           0.967101  blocks.1.ffn.net.3          256  141.566111        256            114          0   1  0.160079       9.270460    15.270667  success  3.044743  0.314851                              0   9.270460  0.401153
11        44  Linear  0.046492  256   768  3.000000   2.042716        2.661651  0.819850     True   20.090755      dense        3.060525  2.283953           1.302996        blocks.2.qkv          256  192.288331        256            160          0   1  0.082434      20.090755     9.570986  success  4.482271  0.237462                              0  20.090755  0.219275
12        45  Linear  0.058732  256   256  1.000000   2.223821        2.034715  0.756302     True    8.221735      dense        2.256424  1.701444           0.914963   blocks.2.out_proj          256   50.285642        256             88          0   1  0.130460       8.221735     6.116184  success  2.867357  0.000152                              2   8.221735  0.119803
13        52  Linear  0.033414  256  1024  4.000000   2.286053        2.134063  0.915388     True    8.580536      dense        2.701832  2.237755           0.933514  blocks.2.ffn.net.0          256  172.884207        256            141          0   1  0.108305       8.580536    20.148416  success  2.929255  0.318808                              0   8.580536  0.347128
14        55  Linear  0.048025  256  1024  4.000000   2.624008        2.447258  0.923427     True    8.563302      dense        2.804718  2.166362           0.932641  blocks.2.ffn.net.3          256  146.676847        256            121          0   1  0.147637       8.563302    17.128538  success  2.926312  0.317826                              0   8.563302  0.389120
15        59  Linear  0.034683  256   768  3.000000   2.080206        2.537466  0.826326     True   16.588800      dense        3.039276  2.271600           1.219815        blocks.3.qkv          256  186.895886        256            144          0   1  0.090017      16.588800    11.266389  success  4.072935  0.234799                              0  16.588800  0.249980
16        60  Linear  0.064317  256   256  1.000000   2.186319        1.883592  0.757089     True    7.270025      dense        2.206709  1.709428           0.861536   blocks.3.out_proj          256   51.218660        256             88          0   1  0.126462       7.270025     7.045184  success  2.696298  0.000999                              1   7.270025  0.118271
17        67  Linear  0.037189  256  1024  4.000000   2.280612        2.020192  0.916707     True    7.687962      dense        2.673881  2.235750           0.885811  blocks.3.ffn.net.0          256  172.087895        256            136          0   1  0.109812       7.687962    22.384072  success  2.772717  0.316848                              0   7.687962  0.356351
18        70  Linear  0.037872  256  1024  4.000000   2.642176        2.367690  0.926003     True    7.872516      dense        2.763600  2.165407           0.896114  blocks.3.ffn.net.3          256  146.354825        256            110          0   1  0.156575       7.872516    18.590603  success  2.805800  0.312078                              0   7.872516  0.417708
19        74  Linear  0.040539  256   768  3.000000   2.041740        2.482598  0.822335     True   16.440804      dense        3.037336  2.285730           1.215923        blocks.4.qkv          256  193.076890        256            152          0   1  0.084496      16.440804    11.743762  success  4.054726  0.237809                              0  16.440804  0.232076
20        75  Linear  0.059875  256   256  1.000000   2.175148        1.806757  0.762648     True    6.770749      dense        2.169646  1.720448           0.830637   blocks.4.out_proj          256   52.534948        256             89          1   1  0.124565       6.770749     7.759104  success  2.602066  0.000054                              1   6.770749  0.120635
21        82  Linear  0.035762  256  1024  4.000000   2.259333        2.138908  0.914327     True    8.845019      dense        2.703930  2.244903           0.946699  blocks.4.ffn.net.0          256  175.753069        256            147          0   1  0.103868       8.845019    19.870287  success  2.974058  0.320923                              0   8.845019  0.335672
22        85  Linear  0.045046  256  1024  4.000000   2.601923        2.480258  0.923559     True    8.979259      dense        2.802465  2.171912           0.953241  blocks.4.ffn.net.3          256  148.563366        256            119          0   1  0.146848       8.979259    16.545169  success  2.996541  0.311508                              0   8.979259  0.395553
23        89  Linear  0.040898  256   768  3.000000   2.088244        2.502820  0.822994     True   15.795327      dense        3.051549  2.267673           1.198529        blocks.5.qkv          256  185.213832        256            146          0   1  0.090064      15.795327    11.725862  success  3.974334  0.236557                              0  15.795327  0.242689
24        90  Linear  0.065151  256   256  1.000000   2.180720        1.847413  0.762009     True    7.033267      dense        2.155558  1.704844           0.847157   blocks.5.out_proj          256   50.680894        256             94          0   1  0.121782       7.033267     7.205882  success  2.652031  0.000405                              1   7.033267  0.111374
25        97  Linear  0.037840  256  1024  4.000000   2.212039        2.292632  0.906618     True   10.875124      dense        2.779862  2.268683           1.036434  blocks.5.ffn.net.0          256  185.644747        256            145          0   1  0.100654      10.875124    17.070587  success  3.297745  0.321063                              0  10.875124  0.340175
26       100  Linear  0.041137  256  1024  4.000000   2.523130        2.475260  0.913481     True    9.572552      dense        2.860308  2.194537           0.981028  blocks.5.ffn.net.3          256  156.508211        256            128          0   1  0.134627       9.572552    16.349686  success  3.093954  0.313440                              0   9.572552  0.375412
27       104  Linear  0.043461  256   768  3.000000   2.133578        2.629997  0.826328     True   17.087168      dense        3.073188  2.250888           1.232670        blocks.6.qkv          256  178.191830        256            139          0   1  0.096149      17.087168    10.428401  success  4.133663  0.238717                              0  17.087168  0.258552
28       105  Linear  0.055000  256   256  1.000000   2.237257        1.956323  0.767526     True    7.489095      dense        2.169840  1.680560           0.874429   blocks.6.out_proj          256   47.924818        256             86          0   1  0.133417       7.489095     6.399280  success  2.736621  0.000594                              1   7.489095  0.121298
29       112  Linear  0.040027  256  1024  4.000000   2.202875        2.347300  0.903300     True   11.629525      dense        2.809594  2.274861           1.065562  blocks.6.ffn.net.0          256  188.304483        256            144          0   1  0.100240      11.629525    16.191932  success  3.410209  0.314760                              0  11.629525  0.341882
30       115  Linear  0.043786  256  1024  4.000000   2.505436        2.523664  0.911235     True   10.168930      dense        2.886733  2.200002           1.007275  blocks.6.ffn.net.3          256  158.490116        256            129          0   1  0.132546      10.168930    15.585722  success  3.188876  0.317185                              0  10.168930  0.373226
31       119  Linear  0.042395  256   768  3.000000   2.091390        2.406385  0.832139     True   14.145406      dense        2.993607  2.260633           1.150615        blocks.7.qkv          256  182.235363        256            148          0   1  0.089712      14.145406    12.883007  success  3.761038  0.240971                              0  14.145406  0.242248
32       120  Linear  0.068565  256   256  1.000000   2.163306        1.767168  0.763575     True    6.559685      dense        2.135545  1.715057           0.816883   blocks.7.out_proj          256   51.886806        256             94          0   1  0.119986       6.559685     7.909954  success  2.561188  0.002015                              0   6.559685  0.111942
33       127  Linear  0.036687  256  1024  4.000000   2.182085        2.493838  0.896508     True   13.895342      dense        2.880726  2.287077           1.142869  blocks.7.ffn.net.0          256  193.676609        256            154          0   1  0.095255      13.895342    13.938240  success  3.727646  0.316980                              0  13.895342  0.321616
34       130  Linear  0.040074  256  1024  4.000000   2.486218        2.613836  0.906183     True   11.254600      dense        2.941281  2.209275           1.051330  blocks.7.ffn.net.3          256  161.910679        256            133          0   1  0.128871      11.254600    14.386179  success  3.354788  0.319326                              0  11.254600  0.364877
35       134  Linear  0.041972  256   768  3.000000   2.077137        2.413717  0.830200     True   14.522455      dense        3.010975  2.273781           1.162040        blocks.8.qkv          256  187.837052        256            149          0   1  0.088243      14.522455    12.934249  success  3.810834  0.239477                              0  14.522455  0.243579
36       135  Linear  0.070646  256   256  1.000000   2.161717        2.112958  0.745322     True    9.493896      dense        2.298469  1.724855           0.977444   blocks.8.out_proj          256   53.070776        256             95          0   1  0.119190       9.493896     5.589989  success  3.081217  0.000480                              1   9.493896  0.110153
37       142  Linear  0.035377  256  1024  4.000000   2.163044        2.548228  0.893522     True   15.068670      dense        2.906880  2.297229           1.178075  blocks.8.ffn.net.0          256  198.257052        256            155          0   1  0.093418      15.068670    13.156904  success  3.881839  0.327543                              0  15.068670  0.320393
38       145  Linear  0.049185  256  1024  4.000000   2.443642        2.504039  0.903329     True   10.585621      dense        2.915611  2.216071           1.024716  blocks.8.ffn.net.3          256  164.464223        256            140          0   1  0.122010      10.585621    15.536568  success  3.253555  0.321322                              0  10.585621  0.347667
39       149  Linear  0.043792  256   768  3.000000   2.087166        2.385510  0.831508     True   13.897676      dense        2.988076  2.261821           1.142942        blocks.9.qkv          256  182.734877        256            146          0   1  0.089974      13.897676    13.148593  success  3.727959  0.240630                              0  13.897676  0.243876
40       150  Linear  0.054015  256   256  1.000000   2.279792        1.876893  0.776186     True    6.656925      dense        2.128494  1.670436           0.823274   blocks.9.out_proj          256   46.820450        256             78          0   1  0.144908       6.656925     7.033345  success  2.580102  0.001479                              0   6.656925  0.134866
41       157  Linear  0.034488  256  1024  4.000000   2.155494        2.718052  0.882822     True   18.238443      dense        3.013131  2.311561           1.260988  blocks.9.ffn.net.0          256  204.908964        256            153          0   1  0.093416      18.238443    11.235003  success  4.270649  0.317276                              0  18.238443  0.323279
42       160  Linear  0.046870  256  1024  4.000000   2.449105        2.619918  0.897562     True   11.742081      dense        3.006037  2.228426           1.069745  blocks.9.ffn.net.3          256  169.209994        256            134          0   1  0.125184      11.742081    14.410563  success  3.426672  0.317969                              0  11.742081  0.364334
43       165  Linear  0.031764  128   256  2.000000   2.135397        1.437072  0.794918     True    4.709520      dense        1.699205  1.466283           0.672977          src_head.0          128   29.260579        128             54          0   1  0.154508       4.709520     6.213070  success  2.170143  0.101537                              0   4.709520  0.113838
44       167  Linear  0.075200   64   128  2.000000   2.291526       -0.367568  0.848790     True    0.691189      dense        0.055286  0.743956          -0.160403          src_head.2           64    5.545694         64             26          0   1  0.253289       0.691189     8.023408  success  0.831378  0.072020                              0   0.691189  0.061722
45       169  Linear  0.064094  256   256  1.000000   1.800134        1.391733  0.809118     True    5.930991      dense        1.988340  1.855039           0.773127         dest_head.0          256   71.620838        256            114          1   1  0.074939       5.930991    12.075696  success  2.435363  0.000064   over-trained               1   5.930991  0.096765
46       171  Linear  0.061288   73   256  3.506849   3.037192        1.350937  0.879925     True    2.784825      dense        1.525295  1.353549           0.444798         dest_head.2           73   22.570909         73             17          0   1  0.494092       2.784825     8.104965  success  1.668779  0.181316                              0   2.784825  0.430801
47       173  Conv2d  0.051090  256   256  1.000000   3.223313        1.065549  1.043578     True    2.140798     conv2d        2.023727  2.437592           0.330576        value_conv.0         2304  273.899831       2304            437          1   9  0.106355       2.140798   127.942846  success  1.463147  0.001462                              7   2.140798  0.203831
48       177  Linear  0.070834  128   256  2.000000   2.775219        0.356870  0.892538     True    1.344596      dense        0.677850  1.179071           0.128592         value_mlp.0          128   15.103259        128             49          0   1  0.253603       1.344596    11.232564  success  1.159567  0.091063                              0   1.344596  0.104362
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 23:17:22 2025      Time elapsed: 87.33284s
Begin: Training epoch 8                        Current time: Sat Oct 25 23:17:22 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:17:41 2025      Time elapsed: 6355.07473      ETA: 241937.69514s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:18:01 2025      Time elapsed: 6374.70301      ETA: 118155.12049s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:18:21 2025      Time elapsed: 6394.51893      ETA: 76883.43267s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:18:41 2025      Time elapsed: 6414.57228      ETA: 56239.76253s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:19:01 2025      Time elapsed: 6434.71584      ETA: 43846.15375s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:19:21 2025      Time elapsed: 6454.83001      ETA: 35576.87145s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:19:41 2025      Time elapsed: 6475.09017      ETA: 29665.16311s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:20:02 2025      Time elapsed: 6495.43092      ETA: 25226.62988s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:20:22 2025      Time elapsed: 6515.71059      ETA: 21769.71306s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:20:42 2025      Time elapsed: 6535.97378      ETA: 19000.07579s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:21:03 2025      Time elapsed: 6556.30996      ETA: 16730.51098s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:21:23 2025      Time elapsed: 6576.63439      ETA: 14835.79109s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:21:43 2025      Time elapsed: 6596.86818      ETA: 13229.25797s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:22:03 2025      Time elapsed: 6617.05105      ETA: 11849.24786s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:22:24 2025      Time elapsed: 6637.31850      ETA: 10650.68377s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:22:44 2025      Time elapsed: 6657.62965      ETA: 9599.46976s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:23:04 2025      Time elapsed: 6678.04762      ETA: 8669.67712s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:23:25 2025      Time elapsed: 6698.42971      ETA: 7840.88411s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:23:45 2025      Time elapsed: 6718.78310      ETA: 7097.15668s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:24:05 2025      Time elapsed: 6739.08107      ETA: 6425.71381s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:24:26 2025      Time elapsed: 6759.46646      ETA: 5816.35996s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:24:46 2025      Time elapsed: 6780.00587      ETA: 5260.66820s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:25:07 2025      Time elapsed: 6800.57377      ETA: 4751.53133s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:25:27 2025      Time elapsed: 6821.08917      ETA: 4283.07558s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:25:48 2025      Time elapsed: 6841.49266      ETA: 3850.39207s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:26:08 2025      Time elapsed: 6861.79400      ETA: 3449.37106s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:26:28 2025      Time elapsed: 6882.09000      ETA: 3076.54912s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:26:49 2025      Time elapsed: 6902.44287      ETA: 2728.93009s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:27:09 2025      Time elapsed: 6922.83507      ETA: 2403.89480s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:27:30 2025      Time elapsed: 6943.12773      ETA: 2099.13895s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:27:50 2025      Time elapsed: 6963.31498      ETA: 1812.70813s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:28:10 2025      Time elapsed: 6983.55557      ETA: 1542.92931s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:28:30 2025      Time elapsed: 7004.07630      ETA: 1288.32555s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:28:51 2025      Time elapsed: 7024.67585      ETA: 1047.50313s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:29:12 2025      Time elapsed: 7045.23308      ETA: 819.25996s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:29:32 2025      Time elapsed: 7065.76664      ETA: 602.55288s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:29:53 2025      Time elapsed: 7086.41435      ETA: 396.45615s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:30:13 2025      Time elapsed: 7107.11838      ETA: 200.12149s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:30:34 2025      Time elapsed: 7127.75956      ETA: 12.79341s
Epoch 8: Avg Policy Loss=2.7821, Avg Value Loss=0.4838
  End: Training epoch 8                        Current time: Sat Oct 25 23:30:35 2025      Time elapsed: 793.58413s
Begin: Validating epoch 8                      Current time: Sat Oct 25 23:30:35 2025      
Validation: Policy Loss=2.7804, Value Loss=0.4811, Top-1 Acc=0.1993, Top-5 Acc=0.5060
  End: Validating epoch 8                      Current time: Sat Oct 25 23:30:59 2025      Time elapsed: 23.85964s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_8.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 23:30:59 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.063188   19    32  1.684211   4.004526        0.281513  0.927927     True    1.175706     conv2d        0.601927  1.476349           0.070299     conv_stem.net.0          171   29.946720        171             23          0   9  0.626487       1.175706    25.471265  success  1.084300  0.119778                              0   1.175706  0.349516
1          6  Conv2d  0.113017   32    64  2.000000  20.754892       -4.147626  0.968653     True    0.631192     conv2d       -3.978090  1.744009          -0.199838     conv_stem.net.3          288   55.463767        288              7          0   9  7.466647       0.631192    87.871454  success  0.794476  0.150336  under-trained               0   0.631192  0.533716
2          9  Conv2d  0.162106   64   256  4.000000   3.729567        3.085429  0.972436     True    6.718752     conv2d        4.156007  2.333027           0.827289                proj           64  215.291669         64             32          0   1  0.482524       6.718752    32.043402  success  2.592056  0.481642                              0   6.718752  3.219124
3         14  Linear  0.038172  256   768  3.000000   2.052759        2.672680  0.816633     True   20.044436      dense        3.087408  2.287858           1.301994        blocks.0.qkv          256  194.025080        256            142          0   1  0.088346      20.044436     9.679748  success  4.477101  0.238492                              0  20.044436  0.248020
4         15  Linear  0.059148  256   256  1.000000   2.201204        1.864852  0.772515     True    7.033904      dense        2.101502  1.675046           0.847196   blocks.0.out_proj          256   47.320122        256             91          0   1  0.125920       7.033904     6.727434  success  2.652151  0.000861                              1   7.033904  0.112651
5         22  Linear  0.035627  256  1024  4.000000   2.267094        1.924411  0.916606     True    7.060647      dense        2.646104  2.228210           0.848844  blocks.0.ffn.net.0          256  169.125853        256            141          0   1  0.106709       7.060647    23.953310  success  2.657188  0.319062                              0   7.060647  0.336824
6         25  Linear  0.040252  256  1024  4.000000   2.699737        2.756231  0.921799     True   10.493627      dense        2.939878  2.157537           1.020926  blocks.0.ffn.net.3          256  143.726561        256            107          0   1  0.164320      10.493627    13.696558  success  3.239387  0.309909                              0  10.493627  0.422376
7         29  Linear  0.040136  256   768  3.000000   1.991675        2.695625  0.816272     True   22.565544      dense        3.075212  2.313641           1.353446        blocks.1.qkv          256  205.892925        256            157          0   1  0.079144      22.565544     9.124217  success  4.750320  0.233941   over-trained               0  22.565544  0.223251
8         30  Linear  0.050071  256   256  1.000000   2.118569        1.731864  0.762396     True    6.568537      dense        2.157200  1.740748           0.817469   blocks.1.out_proj          256   55.048879        256             87          0   1  0.119923       6.568537     8.380691  success  2.562916  0.000412                              1   6.568537  0.122794
9         37  Linear  0.038343  256  1024  4.000000   2.253636        1.999393  0.914975     True    7.712328      dense        2.670987  2.234256           0.887186  blocks.1.ffn.net.0          256  171.496832        256            143          0   1  0.104834       7.712328    22.236713  success  2.777108  0.308632                              0   7.712328  0.335404
10        40  Linear  0.036512  256  1024  4.000000   2.650849        2.588951  0.921387     True    9.476543      dense        2.864114  2.159243           0.976650  blocks.1.ffn.net.3          256  144.292268        256            116          0   1  0.153277       9.476543    15.226255  success  3.078399  0.316013                              0   9.476543  0.395258
11        44  Linear  0.042720  256   768  3.000000   2.006826        2.617102  0.817090     True   20.141874      dense        3.052844  2.301628           1.304100        blocks.2.qkv          256  200.275510        256            160          0   1  0.079597      20.141874     9.943241  success  4.487970  0.235482                              0  20.141874  0.216194
12        45  Linear  0.058424  256   256  1.000000   2.141494        2.009234  0.746431     True    8.674393      dense        2.262568  1.727169           0.938239   blocks.2.out_proj          256   53.354286        256             96          0   1  0.116503       8.674393     6.150781  success  2.945232  0.000096                              2   8.674393  0.107294
13        52  Linear  0.036592  256  1024  4.000000   2.193359        2.122674  0.909746     True    9.284816      dense        2.704331  2.254707           0.967773  blocks.2.ffn.net.0          256  179.765590        256            158          0   1  0.094939       9.284816    19.361245  success  3.047100  0.315432                              0   9.284816  0.304683
14        55  Linear  0.038459  256  1024  4.000000   2.570431        2.423281  0.920079     True    8.765020      dense        2.800090  2.175789           0.942753  blocks.2.ffn.net.3          256  149.895559        256            124          0   1  0.141029       8.765020    17.101564  success  2.960578  0.316994                              0   8.765020  0.381509
15        59  Linear  0.035349  256   768  3.000000   2.036626        2.476883  0.823809     True   16.450155      dense        3.023672  2.287441           1.216170        blocks.3.qkv          256  193.838919        256            145          0   1  0.086087      16.450155    11.783410  success  4.055879  0.233852                              0  16.450155  0.244055
16        60  Linear  0.055867  256   256  1.000000   2.168625        1.910103  0.750001     True    7.599582      dense        2.246583  1.729513           0.880790   blocks.3.out_proj          256   53.642961        256             85          0   1  0.126755       7.599582     7.058673  success  2.756734  0.002882                              0   7.599582  0.123008
17        67  Linear  0.038871  256  1024  4.000000   2.196210        2.027874  0.911288     True    8.382078      dense        2.681516  2.252169           0.923352  blocks.3.ffn.net.0          256  178.718439        256            149          0   1  0.097997       8.382078    21.321495  success  2.895182  0.314399                              0   8.382078  0.320536
18        70  Linear  0.035939  256  1024  4.000000   2.570635        2.329298  0.922834     True    8.055970      dense        2.750140  2.174409           0.906118  blocks.3.ffn.net.3          256  149.420001        256            118          0   1  0.144589       8.055970    18.547735  success  2.838304  0.311964                              0   8.055970  0.395832
19        74  Linear  0.038952  256   768  3.000000   1.994521        2.425280  0.819949     True   16.442617      dense        3.019425  2.302268           1.215971        blocks.4.qkv          256  200.570938        256            156          0   1  0.079625      16.442617    12.198237  success  4.054950  0.237165   over-trained               0  16.442617  0.220704
20        75  Linear  0.061463  256   256  1.000000   2.107013        1.784083  0.754422     True    7.026449      dense        2.184855  1.744908           0.846736   blocks.4.out_proj          256   55.578695        256             93          0   1  0.114792       7.026449     7.909927  success  2.650745  0.001452                              0   7.026449  0.113005
21        82  Linear  0.039565  256  1024  4.000000   2.174185        2.149621  0.908499     True    9.743204      dense        2.715223  2.263599           0.988702  blocks.4.ffn.net.0          256  183.484514        256            151          0   1  0.095554       9.743204    18.832051  success  3.121411  0.319792                              0   9.743204  0.318026
22        85  Linear  0.036098  256  1024  4.000000   2.560968        2.494854  0.919304     True    9.422889      dense        2.824523  2.182777           0.974184  blocks.4.ffn.net.3          256  152.327119        256            114          0   1  0.146198       9.422889    16.165650  success  3.069672  0.314188                              0   9.422889  0.407513
23        89  Linear  0.041747  256   768  3.000000   2.045927        2.457875  0.820683     True   15.898291      dense        3.034407  2.282609           1.201350        blocks.5.qkv          256  191.694432        256            149          0   1  0.085686      15.898291    12.057550  success  3.987266  0.233367                              0  15.898291  0.233933
24        90  Linear  0.056417  256   256  1.000000   2.149188        1.846725  0.754663     True    7.232135      dense        2.180736  1.723794           0.859267   blocks.5.out_proj          256   52.941189        256             94          0   1  0.118530       7.232135     7.320271  success  2.689263  0.000611                              1   7.232135  0.110416
25        97  Linear  0.044954  256  1024  4.000000   2.113890        2.278384  0.900891     True   11.962327      dense        2.775296  2.287911           1.077816  blocks.5.ffn.net.0          256  194.048661        256            170          0   1  0.085431      11.962327    16.221648  success  3.458660  0.316758                              0  11.962327  0.282145
26       100  Linear  0.033968  256  1024  4.000000   2.463174        2.453293  0.908938     True    9.908056      dense        2.862326  2.206906           0.995988  blocks.5.ffn.net.3          256  161.029731        256            127          0   1  0.129836       9.908056    16.252404  success  3.147707  0.314922                              0   9.908056  0.374389
27       104  Linear  0.039494  256   768  3.000000   2.067453        2.577090  0.822697     True   17.640259      dense        3.044758  2.269849           1.246505        blocks.6.qkv          256  186.144046        256            149          0   1  0.087449      17.640259    10.552229  success  4.200031  0.235815                              0  17.640259  0.235735
28       105  Linear  0.058868  256   256  1.000000   2.179514        1.968881  0.755058     True    8.004934      dense        2.212872  1.707794           0.903358   blocks.6.out_proj          256   51.026273        256             87          0   1  0.126457       8.004934     6.374353  success  2.829299  0.000185                              1   8.004934  0.118220
29       112  Linear  0.043255  256  1024  4.000000   2.116596        2.327769  0.897809     True   12.582603      dense        2.807241  2.294307           1.099771  blocks.6.ffn.net.0          256  196.927755        256            161          0   1  0.088000      12.582603    15.650796  success  3.547197  0.312310                              0  12.582603  0.298873
30       115  Linear  0.037891  256  1024  4.000000   2.440722        2.506594  0.906030     True   10.641153      dense        2.891859  2.213039           1.026989  blocks.6.ffn.net.3          256  163.319764        256            134          0   1  0.124459      10.641153    15.347938  success  3.262078  0.314125                              0  10.641153  0.359681
31       119  Linear  0.038308  256   768  3.000000   2.050438        2.370065  0.829328     True   14.317999      dense        2.983095  2.276589           1.155882        blocks.7.qkv          256  189.055158        256            146          0   1  0.086935      14.317999    13.204021  success  3.783913  0.236398                              0  14.317999  0.241684
32       120  Linear  0.069961  256   256  1.000000   2.094020        1.695108  0.753812     True    6.449106      dense        2.157260  1.741225           0.809500   blocks.7.out_proj          256   55.109296        256             97          0   1  0.111081       6.449106     8.545261  success  2.539509  0.000575                              1   6.449106  0.105310
33       127  Linear  0.040955  256  1024  4.000000   2.094767        2.464624  0.891226     True   15.016275      dense        2.868699  2.306752           1.176562  blocks.7.ffn.net.0          256  202.652399        256            165          0   1  0.085227      15.016275    13.495517  success  3.875084  0.313325                              0  15.016275  0.290243
34       130  Linear  0.038882  256  1024  4.000000   2.426420        2.582558  0.900492     True   11.597092      dense        2.946092  2.223575           1.064349  blocks.7.ffn.net.3          256  167.330591        256            133          0   1  0.123686      11.597092    14.428668  success  3.405450  0.319051                              0  11.597092  0.361741
35       134  Linear  0.043655  256   768  3.000000   2.003896        2.350479  0.827161     True   14.892065      dense        2.975457  2.291214           1.172955        blocks.8.qkv          256  195.530126        256            162          0   1  0.078873      14.892065    13.129819  success  3.859024  0.240172                              0  14.892065  0.214292
36       135  Linear  0.062700  256   256  1.000000   2.117762        2.103212  0.736272     True    9.843048      dense        2.320242  1.749172           0.993130   blocks.8.out_proj          256   56.127073        256             94          0   1  0.115288       9.843048     5.702204  success  3.137363  0.000795                              1   9.843048  0.109706
37       142  Linear  0.043487  256  1024  4.000000   2.084706        2.533186  0.887441     True   16.410776      dense        2.908174  2.319737           1.215129  blocks.8.ffn.net.0          256  208.803191        256            162          0   1  0.085223      16.410776    12.723541  success  4.051022  0.323678                              0  16.410776  0.298048
38       145  Linear  0.042937  256  1024  4.000000   2.387454        2.514095  0.895323     True   11.299122      dense        2.951068  2.234404           1.053045  blocks.8.ffn.net.3          256  171.555314        256            139          0   1  0.117682      11.299122    15.183066  success  3.361417  0.320617                              0  11.299122  0.346972
39       149  Linear  0.040313  256   768  3.000000   2.041634        2.344812  0.828682     True   14.076591      dense        2.978249  2.279287           1.148497        blocks.9.qkv          256  190.233513        256            152          0   1  0.084488      14.076591    13.514175  success  3.751878  0.237996                              0  14.076591  0.230846
40       150  Linear  0.052066  256   256  1.000000   2.201860        1.873346  0.763790     True    7.092535      dense        2.162880  1.699625           0.850801   blocks.9.out_proj          256   50.075523        256             83          0   1  0.131921       7.092535     7.060314  success  2.663181  0.000676                              1   7.092535  0.125505
41       157  Linear  0.038042  256  1024  4.000000   2.074307        2.696724  0.876555     True   19.955368      dense        3.005170  2.334825           1.300060  blocks.9.ffn.net.0          256  216.184594        256            165          0   1  0.083635      19.955368    10.833405  success  4.467143  0.318007                              0  19.955368  0.291508
42       160  Linear  0.042357  256  1024  4.000000   2.370352        2.576354  0.889486     True   12.215403      dense        3.014340  2.247546           1.086908  blocks.9.ffn.net.3          256  176.825814        256            139          0   1  0.116232      12.215403    14.475644  success  3.495054  0.317593                              0  12.215403  0.348905
43       165  Linear  0.039520  128   256  2.000000   2.040204        1.463087  0.784431     True    5.213481      dense        1.754727  1.506398           0.717128          src_head.0          128   32.092083        128             62          0   1  0.132106       5.213481     6.155595  success  2.283305  0.101743                              0   5.213481  0.098341
44       167  Linear  0.089280   64   128  2.000000   2.118020       -0.296960  0.845654     True    0.724092      dense        0.176887  0.769409          -0.140206          src_head.2           64    5.880433         64             31          0   1  0.200802       0.724092     8.121116  success  0.850936  0.072382                              0   0.724092  0.049808
45       169  Linear  0.060596  256   256  1.000000   1.753625        1.427297  0.804397     True    6.514966      dense        2.032777  1.884580           0.813912         dest_head.0          256   76.661957        256            119          0   1  0.069085       6.514966    11.767055  success  2.552443  0.001142   over-trained               0   6.514966  0.088672
46       171  Linear  0.059908   73   256  3.506849   2.969526        1.440768  0.878894     True    3.056220      dense        1.627741  1.394257           0.485185         dest_head.2           73   24.788892         73             17          0   1  0.477680       3.056220     8.110964  success  1.748205  0.185414                              0   3.056220  0.464546
47       173  Conv2d  0.047612  256   256  1.000000   2.783227        1.010773  1.040471     True    2.307629     conv2d        2.051951  2.441473           0.363166        value_conv.0         2304  276.358821       2304             90          1   9  0.187969       2.307629   119.758781  success  1.519088  0.001228                              8   2.307629  0.384584
48       177  Linear  0.063515  128   256  2.000000   2.742541        0.491442  0.879567     True    1.510749      dense        0.812897  1.191694           0.179192         value_mlp.0          128   15.548707        128             49          0   1  0.248934       1.510749    10.292050  success  1.229125  0.089763                              0   1.510749  0.103705
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 23:32:26 2025      Time elapsed: 86.50396s
Begin: Training epoch 9                        Current time: Sat Oct 25 23:32:26 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:32:46 2025      Time elapsed: 7259.16648      ETA: 276356.46814s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:33:05 2025      Time elapsed: 7278.81733      ETA: 134912.87939s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:33:25 2025      Time elapsed: 7298.54874      ETA: 87752.88442s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:33:45 2025      Time elapsed: 7318.37193      ETA: 64163.82597s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:34:05 2025      Time elapsed: 7338.28066      ETA: 50003.04447s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:34:25 2025      Time elapsed: 7358.29205      ETA: 40556.45308s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:34:45 2025      Time elapsed: 7378.43330      ETA: 33803.76517s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:35:05 2025      Time elapsed: 7398.62501      ETA: 28734.40990s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:35:25 2025      Time elapsed: 7418.76256      ETA: 24786.91004s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:35:45 2025      Time elapsed: 7438.84725      ETA: 21624.72896s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:36:05 2025      Time elapsed: 7458.99776      ETA: 19034.00612s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:36:26 2025      Time elapsed: 7479.28959      ETA: 16872.03078s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:36:46 2025      Time elapsed: 7499.53852      ETA: 15039.45919s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:37:06 2025      Time elapsed: 7519.68915      ETA: 13465.61480s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:37:26 2025      Time elapsed: 7539.88289      ETA: 12098.99876s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:37:47 2025      Time elapsed: 7560.16371      ETA: 10900.81105s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:38:07 2025      Time elapsed: 7580.46677      ETA: 9841.22952s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:38:27 2025      Time elapsed: 7600.75732      ETA: 8897.10871s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:38:48 2025      Time elapsed: 7621.16623      ETA: 8050.35823s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:39:08 2025      Time elapsed: 7641.64995      ETA: 7286.31324s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:39:28 2025      Time elapsed: 7662.02726      ETA: 6592.99203s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:39:49 2025      Time elapsed: 7682.33673      ETA: 5960.79491s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:40:09 2025      Time elapsed: 7702.92323      ETA: 5381.99897s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:40:30 2025      Time elapsed: 7723.58242      ETA: 4849.76613s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:40:50 2025      Time elapsed: 7744.02098      ETA: 4358.33501s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:41:11 2025      Time elapsed: 7764.33273      ETA: 3903.07034s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:41:31 2025      Time elapsed: 7784.65285      ETA: 3480.02815s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:41:51 2025      Time elapsed: 7804.96503      ETA: 3085.74868s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:42:12 2025      Time elapsed: 7825.25702      ETA: 2717.25304s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:42:32 2025      Time elapsed: 7845.59895      ETA: 2371.98608s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:42:52 2025      Time elapsed: 7866.06421      ETA: 2047.71414s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:43:13 2025      Time elapsed: 7886.71601      ETA: 1742.47132s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:43:34 2025      Time elapsed: 7907.34503      ETA: 1454.47225s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:43:54 2025      Time elapsed: 7927.90026      ETA: 1182.18983s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:44:15 2025      Time elapsed: 7948.39621      ETA: 924.28493s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:44:35 2025      Time elapsed: 7968.85996      ETA: 679.56667s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:44:56 2025      Time elapsed: 7989.27690      ETA: 446.96765s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:45:16 2025      Time elapsed: 8009.77390      ETA: 225.53837s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:45:37 2025      Time elapsed: 8030.18540      ETA: 14.41315s
Epoch 9: Avg Policy Loss=2.7611, Avg Value Loss=0.4727
  End: Training epoch 9                        Current time: Sat Oct 25 23:45:38 2025      Time elapsed: 791.98488s
Begin: Validating epoch 9                      Current time: Sat Oct 25 23:45:38 2025      
Validation: Policy Loss=2.7655, Value Loss=0.4772, Top-1 Acc=0.2028, Top-5 Acc=0.5112
  End: Validating epoch 9                      Current time: Sat Oct 25 23:46:02 2025      Time elapsed: 23.68320s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_9.pt
Begin: Generating ww analysis                  Current time: Sat Oct 25 23:46:02 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.069916   19    32  1.684211   3.926991        0.281428  0.927159     True    1.179411     conv2d        0.609386  1.471850           0.071665     conv_stem.net.0          171   29.638057        171             25          0   9  0.585398       1.179411    25.129542  success  1.086007  0.120390                              0   1.179411  0.334318
1          6  Conv2d  0.108531   32    64  2.000000  21.123585       -4.325665  0.968608     True    0.624052     conv2d       -4.167592  1.738534          -0.204779     conv_stem.net.3          288   54.768852        288              7          0   9  7.606000       0.624052    87.763217  success  0.789970  0.149162  under-trained               0   0.624052  0.527779
2          9  Conv2d  0.160371   64   256  4.000000   3.739570        3.065616  0.972399     True    6.603553     conv2d        4.136537  2.325956           0.819778                proj           64  211.814831         64             32          0   1  0.484292       6.603553    32.075890  success  2.569738  0.455320                              0   6.603553  3.170713
3         14  Linear  0.036892  256   768  3.000000   2.034866        2.635631  0.816324     True   19.734940      dense        3.073646  2.294495           1.295236        blocks.0.qkv          256  197.012846        256            142          0   1  0.086844      19.734940     9.982946  success  4.442402  0.237040                              0  19.734940  0.246434
4         15  Linear  0.056437  256   256  1.000000   2.208376        1.875305  0.769121     True    7.066077      dense        2.125860  1.684782           0.849178   blocks.0.out_proj          256   48.392917        256             85          0   1  0.131067       7.066077     6.848626  success  2.658209  0.001363                              0   7.066077  0.121133
5         22  Linear  0.035766  256  1024  4.000000   2.216198        1.925659  0.913502     True    7.394388      dense        2.647918  2.235877           0.868902  blocks.0.ffn.net.0          256  172.138161        256            152          0   1  0.098647       7.394388    23.279569  success  2.719262  0.316756                              0   7.394388  0.309315
6         25  Linear  0.036102  256  1024  4.000000   2.645303        2.720910  0.919587     True   10.680263      dense        2.918043  2.161760           1.028582  blocks.0.ffn.net.3          256  145.130935        256            113          0   1  0.154777      10.680263    13.588705  success  3.268067  0.308545                              0  10.680263  0.403437
7         29  Linear  0.037574  256   768  3.000000   1.975449        2.673362  0.815318     True   22.557617      dense        3.067232  2.319911           1.353293        blocks.1.qkv          256  208.886893        256            157          0   1  0.077849      22.557617     9.260149  success  4.749486  0.232178   over-trained               0  22.557617  0.220935
8         30  Linear  0.043963  256   256  1.000000   2.081114        1.729735  0.759249     True    6.778883      dense        2.159487  1.751961           0.831158   blocks.1.out_proj          256   56.488638        256             93          0   1  0.112106       6.778883     8.333030  success  2.603629  0.000623                              1   6.778883  0.113435
9         37  Linear  0.037480  256  1024  4.000000   2.216357        1.990155  0.912154     True    7.905688      dense        2.675461  2.242056           0.897940  blocks.1.ffn.net.0          256  174.604596        256            149          0   1  0.099648       7.905688    22.085945  success  2.811706  0.307461                              0   7.905688  0.319561
10        40  Linear  0.032689  256  1024  4.000000   2.632095        2.592467  0.919566     True    9.659268      dense        2.870341  2.163442           0.984944  blocks.1.ffn.net.3          256  145.694240        256            113          0   1  0.153535       9.659268    15.083362  success  3.107936  0.314488                              0   9.659268  0.402111
11        44  Linear  0.040553  256   768  3.000000   1.987048        2.586028  0.816382     True   20.018988      dense        3.040247  2.307373           1.301442        blocks.2.qkv          256  202.942577        256            161          0   1  0.077790      20.018988    10.137504  success  4.474258  0.234714   over-trained               0  20.018988  0.211894
12        45  Linear  0.054957  256   256  1.000000   2.123000        2.020755  0.742835     True    8.950335      dense        2.274469  1.737028           0.951839   blocks.2.out_proj          256   54.579252        256             96          0   1  0.114616       8.950335     6.098013  success  2.991711  0.000511                              1   8.950335  0.106670
13        52  Linear  0.039220  256  1024  4.000000   2.156883        2.112836  0.907268     True    9.540662      dense        2.705106  2.262212           0.979579  blocks.2.ffn.net.0          256  182.899195        256            160          0   1  0.091460       9.540662    19.170493  success  3.088796  0.312632                              0   9.540662  0.296037
14        55  Linear  0.033599  256  1024  4.000000   2.549447        2.422938  0.918265     True    8.920262      dense        2.804837  2.180118           0.950378  blocks.2.ffn.net.3          256  151.397093        256            124          0   1  0.139144       8.920262    16.972269  success  2.986681  0.314632                              0   8.920262  0.380975
15        59  Linear  0.035760  256   768  3.000000   2.008338        2.437740  0.822883     True   16.361008      dense        3.005410  2.293010           1.213810        blocks.3.qkv          256  196.340555        256            148          0   1  0.082885      16.361008    12.000517  success  4.044874  0.233250                              0  16.361008  0.234326
16        60  Linear  0.050797  256   256  1.000000   2.149478        1.912145  0.746765     True    7.755069      dense        2.255822  1.738773           0.889586   blocks.3.out_proj          256   54.798987        256             85          0   1  0.124678       7.755069     7.066215  success  2.784792  0.003440                              0   7.755069  0.122496
17        67  Linear  0.040214  256  1024  4.000000   2.153905        2.017674  0.908733     True    8.644736      dense        2.680960  2.259856           0.936752  blocks.3.ffn.net.0          256  181.909952        256            155          0   1  0.092684       8.644736    21.042857  success  2.940193  0.312398                              0   8.644736  0.303454
18        70  Linear  0.033865  256  1024  4.000000   2.536095        2.305167  0.921289     True    8.108558      dense        2.741728  2.178628           0.908944  blocks.3.ffn.net.3          256  150.878628        256            117          0   1  0.142012       8.108558    18.607332  success  2.847553  0.311764                              0   8.108558  0.395798
19        74  Linear  0.036999  256   768  3.000000   1.984978        2.408347  0.819255     True   16.341282      dense        3.017833  2.307803           1.213286        blocks.4.qkv          256  203.143453        256            156          0   1  0.078861      16.341282    12.431305  success  4.042435  0.235793   over-trained               0  16.341282  0.219922
20        75  Linear  0.058546  256   256  1.000000   2.092044        1.770941  0.751235     True    7.022833      dense        2.196652  1.754855           0.846512   blocks.4.out_proj          256   56.866280        256             92          0   1  0.113853       7.022833     8.097342  success  2.650063  0.001008                              0   7.022833  0.113854
21        82  Linear  0.040257  256  1024  4.000000   2.133768        2.140868  0.905909     True   10.076921      dense        2.715559  2.271647           1.003328  blocks.4.ffn.net.0          256  186.916424        256            159          0   1  0.089914      10.076921    18.548961  success  3.174417  0.319611                              0  10.076921  0.297852
22        85  Linear  0.031345  256  1024  4.000000   2.545045        2.492194  0.917449     True    9.533087      dense        2.830869  2.187262           0.979234  blocks.4.ffn.net.3          256  153.908256        256            113          0   1  0.145346       9.533087    16.144640  success  3.087570  0.312811                              0   9.533087  0.410583
23        89  Linear  0.038031  256   768  3.000000   2.026095        2.433846  0.820074     True   15.894597      dense        3.022482  2.288142           1.201250        blocks.5.qkv          256  194.152142        256            149          0   1  0.084061      15.894597    12.214977  success  3.986803  0.232177                              0  15.894597  0.231315
24        90  Linear  0.054200  256   256  1.000000   2.129531        1.835820  0.751608     True    7.279089      dense        2.186713  1.732193           0.862077   blocks.5.out_proj          256   53.975028        256             93          0   1  0.117127       7.279089     7.415080  success  2.697979  0.000351                              2   7.279089  0.110509
25        97  Linear  0.044184  256  1024  4.000000   2.078252        2.269439  0.898335     True   12.359309      dense        2.775501  2.296306           1.091994  blocks.5.ffn.net.0          256  197.836314        256            171          0   1  0.082456      12.359309    16.007069  success  3.515581  0.315944                              0  12.359309  0.274778
26       100  Linear  0.032593  256  1024  4.000000   2.461880        2.466097  0.906621     True   10.039520      dense        2.883339  2.212505           1.001713  blocks.5.ffn.net.3          256  163.119133        256            123          0   1  0.131813      10.039520    16.247702  success  3.168520  0.315632                              0  10.039520  0.385797
27       104  Linear  0.036199  256   768  3.000000   2.051086        2.556893  0.821985     True   17.644312      dense        3.036307  2.276012           1.246605        blocks.6.qkv          256  188.804227        256            149          0   1  0.086108      17.644312    10.700572  success  4.200513  0.235454                              0  17.644312  0.234191
28       105  Linear  0.061720  256   256  1.000000   2.149603        1.963493  0.750291     True    8.192582      dense        2.221828  1.719343           0.913421   blocks.6.out_proj          256   52.401388        256             87          0   1  0.123250       8.192582     6.396199  success  2.862269  0.000886                              1   8.192582  0.116794
29       112  Linear  0.045197  256  1024  4.000000   2.084363        2.322698  0.895366     True   13.012003      dense        2.808855  2.302955           1.114344  blocks.6.ffn.net.0          256  200.888466        256            162          0   1  0.085196      13.012003    15.438704  success  3.607215  0.311243                              0  13.012003  0.292409
30       115  Linear  0.038062  256  1024  4.000000   2.416365        2.500832  0.903513     True   10.838178      dense        2.896653  2.218853           1.034956  blocks.6.ffn.net.3          256  165.521127        256            134          0   1  0.122355      10.838178    15.272044  success  3.292139  0.311703                              0  10.838178  0.358145
31       119  Linear  0.035548  256   768  3.000000   2.024820        2.345736  0.828093     True   14.404273      dense        2.970369  2.282886           1.158491        blocks.7.qkv          256  191.816316        256            153          0   1  0.082852      14.404273    13.316626  success  3.795296  0.235100                              0  14.404273  0.227081
32       120  Linear  0.065068  256   256  1.000000   2.100928        1.705675  0.748162     True    6.484368      dense        2.198935  1.754787           0.811868   blocks.7.out_proj          256   56.857392        256             95          0   1  0.112953       6.484368     8.768378  success  2.546442  0.000356                              1   6.484368  0.109021
33       127  Linear  0.043263  256  1024  4.000000   2.059404        2.446388  0.888971     True   15.413844      dense        2.862742  2.315202           1.187911  blocks.7.ffn.net.0          256  206.634193        256            170          0   1  0.081253      15.413844    13.405753  success  3.926047  0.311570                              0  15.413844  0.276423
34       130  Linear  0.039807  256  1024  4.000000   2.402102        2.575085  0.897797     True   11.803564      dense        2.950452  2.229669           1.072013  blocks.7.ffn.net.3          256  169.694948        256            132          0   1  0.122037      11.803564    14.376585  success  3.435632  0.318058                              0  11.803564  0.362238
35       134  Linear  0.039820  256   768  3.000000   1.993265        2.346965  0.826130     True   15.046912      dense        2.975778  2.297378           1.177447        blocks.8.qkv          256  198.325464        256            162          0   1  0.078038      15.046912    13.180476  success  3.879035  0.239227   over-trained               0  15.046912  0.213359
36       135  Linear  0.059616  256   256  1.000000   2.086901        2.088485  0.732063     True   10.017501      dense        2.321541  1.760065           1.000759   blocks.8.out_proj          256   57.552635        256             96          0   1  0.110931      10.017501     5.745209  success  3.165044  0.001221                              0  10.017501  0.105795
37       142  Linear  0.045514  256  1024  4.000000   2.047780        2.520130  0.884779     True   17.008427      dense        2.904845  2.329496           1.230664  blocks.8.ffn.net.0          256  213.548450        256            168          0   1  0.080838      17.008427    12.555450  success  4.124127  0.322781                              0  17.008427  0.281926
38       145  Linear  0.043744  256  1024  4.000000   2.345404        2.496280  0.891670     True   11.596543      dense        2.951149  2.242407           1.064329  blocks.8.ffn.net.3          256  174.746102        256            141          0   1  0.113303      11.596543    15.068809  success  3.405370  0.319901                              0  11.596543  0.338563
39       149  Linear  0.039756  256   768  3.000000   2.023354        2.331950  0.827687     True   14.207472      dense        2.971846  2.285133           1.152517        blocks.9.qkv          256  192.811398        256            153          0   1  0.082733      14.207472    13.571127  success  3.769280  0.236296                              0  14.207472  0.227071
40       150  Linear  0.055803  256   256  1.000000   2.163090        1.871662  0.758659     True    7.332844      dense        2.172698  1.712090           0.865272   blocks.9.out_proj          256   51.533529        256             84          0   1  0.126904       7.332844     7.027768  success  2.707922  0.000315                              1   7.332844  0.122292
41       157  Linear  0.041174  256  1024  4.000000   2.042451        2.689016  0.873948     True   20.728285      dense        3.002435  2.344274           1.316563  blocks.9.ffn.net.0          256  220.939781        256            168          0   1  0.080427      20.728285    10.658855  success  4.552833  0.316518                              0  20.728285  0.281569
42       160  Linear  0.041769  256  1024  4.000000   2.341680        2.568969  0.885771     True   12.504374      dense        3.022509  2.255524           1.097062  blocks.9.ffn.net.3          256  180.104192        256            139          0   1  0.113800      12.504374    14.403296  success  3.536152  0.317258                              0  12.504374  0.346349
43       165  Linear  0.042438  128   256  2.000000   2.003153        1.472716  0.779710     True    5.434997      dense        1.783192  1.527529           0.735199          src_head.0          128   33.692208        128             61          0   1  0.128441       5.434997     6.199122  success  2.331308  0.101095                              0   5.434997  0.099632
44       167  Linear  0.095500   64   128  2.000000   2.322562       -0.308201  0.845208     True    0.736718      dense        0.132367  0.782877          -0.132699          src_head.2           64    6.065640         64             22          0   1  0.281971       0.736718     8.233331  success  0.858323  0.072436                              0   0.736718  0.080101
45       169  Linear  0.061204  256   256  1.000000   1.729036        1.440082  0.802245     True    6.805840      dense        2.051631  1.898576           0.832882         dest_head.0          256   79.172867        256            124          0   1  0.065469       6.805840    11.633079  success  2.608800  0.000917   over-trained               1   6.805840  0.081908
46       171  Linear  0.051183   73   256  3.506849   2.836614        1.431106  0.878673     True    3.195302      dense        1.638164  1.414095           0.504512         dest_head.2           73   25.947451         73             19          0   1  0.421348       3.195302     8.120499  success  1.787541  0.188263                              0   3.195302  0.439767
47       173  Conv2d  0.044189  256   256  1.000000   3.138819        1.157812  1.039524     True    2.338129     conv2d        2.118503  2.441903           0.368868        value_conv.0         2304  276.632318       2304            406          1   9  0.106148       2.338129   118.313537  success  1.529094  0.001063                              8   2.338129  0.209615
48       177  Linear  0.059529  128   256  2.000000   2.718992        0.576748  0.873370     True    1.629741      dense        0.876600  1.196722           0.212119         value_mlp.0          128   15.729764        128             49          0   1  0.245570       1.629741     9.651697  success  1.276613  0.089701                              0   1.629741  0.102895
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sat Oct 25 23:47:29 2025      Time elapsed: 87.40722s
Begin: Training epoch 10                       Current time: Sat Oct 25 23:47:29 2025      
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:47:49 2025      Time elapsed: 8162.25589      ETA: 310737.08181s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:48:08 2025      Time elapsed: 8181.91750      ETA: 151651.84093s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:48:28 2025      Time elapsed: 8201.77088      ETA: 98612.62524s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:48:48 2025      Time elapsed: 8221.71124      ETA: 72083.85334s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:49:08 2025      Time elapsed: 8241.69553      ETA: 56158.91340s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:49:28 2025      Time elapsed: 8261.84268      ETA: 45536.52292s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:49:48 2025      Time elapsed: 8281.99688      ETA: 37943.37717s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:50:09 2025      Time elapsed: 8302.16991      ETA: 32243.55241s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:50:29 2025      Time elapsed: 8322.46426      ETA: 27806.27785s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:50:49 2025      Time elapsed: 8342.69537      ETA: 24252.21547s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:51:09 2025      Time elapsed: 8362.82920      ETA: 21340.41961s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:51:29 2025      Time elapsed: 8382.99308      ETA: 18910.63523s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:51:50 2025      Time elapsed: 8403.28428      ETA: 16851.81703s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:52:10 2025      Time elapsed: 8423.62645      ETA: 15084.30823s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:52:30 2025      Time elapsed: 8443.91590      ETA: 13549.67039s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:52:50 2025      Time elapsed: 8464.12392      ETA: 12204.20869s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:53:11 2025      Time elapsed: 8484.44644      ETA: 11014.80782s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:53:31 2025      Time elapsed: 8504.92704      ETA: 9955.48961s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:53:52 2025      Time elapsed: 8525.33457      ETA: 9005.44553s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:54:12 2025      Time elapsed: 8545.59309      ETA: 8148.22301s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:54:32 2025      Time elapsed: 8565.80640      ETA: 7370.67246s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:54:52 2025      Time elapsed: 8586.01846      ETA: 6661.96978s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:55:13 2025      Time elapsed: 8606.24135      ETA: 6013.14341s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:55:33 2025      Time elapsed: 8626.47076      ETA: 5416.70477s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:55:53 2025      Time elapsed: 8646.69184      ETA: 4866.35817s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:56:13 2025      Time elapsed: 8666.98715      ETA: 4356.82778s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:56:34 2025      Time elapsed: 8687.28857      ETA: 3883.53974s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:56:54 2025      Time elapsed: 8707.56381      ETA: 3442.59755s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:57:14 2025      Time elapsed: 8727.82622      ETA: 3030.66242s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:57:35 2025      Time elapsed: 8748.12897      ETA: 2644.85099s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:57:55 2025      Time elapsed: 8768.44193      ETA: 2282.62343s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:58:15 2025      Time elapsed: 8788.73204      ETA: 1941.76049s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:58:35 2025      Time elapsed: 8808.93910      ETA: 1620.31092s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:58:56 2025      Time elapsed: 8829.17828      ETA: 1316.58629s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:59:16 2025      Time elapsed: 8849.53263      ETA: 1029.07422s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:59:36 2025      Time elapsed: 8869.91650      ETA: 756.40677s
  Lap: Training for 3907 batches               Current time: Sat Oct 25 23:59:57 2025      Time elapsed: 8890.27930      ETA: 497.37508s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:00:17 2025      Time elapsed: 8910.66590      ETA: 250.90559s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:00:37 2025      Time elapsed: 8930.99885      ETA: 16.03000s
Epoch 10: Avg Policy Loss=2.7495, Avg Value Loss=0.4639
  End: Training epoch 10                       Current time: Sun Oct 26 00:00:39 2025      Time elapsed: 789.65292s
Begin: Validating epoch 10                     Current time: Sun Oct 26 00:00:39 2025      
Validation: Policy Loss=2.7591, Value Loss=0.4773, Top-1 Acc=0.2039, Top-5 Acc=0.5137
  End: Validating epoch 10                     Current time: Sun Oct 26 00:01:02 2025      Time elapsed: 23.80051s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_10.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 00:01:03 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.072680   19    32  1.684211   3.917994        0.280041  0.926974     True    1.178896     conv2d        0.608263  1.470203           0.071476     conv_stem.net.0          171   29.525862        171             25          0   9  0.583599       1.178896    25.045343  success  1.085770  0.120301                              0   1.178896  0.332963
1          6  Conv2d  0.109362   32    64  2.000000  21.322953       -4.406040  0.968599     True    0.621393     conv2d       -4.252351  1.736802          -0.206634     conv_stem.net.3          288   54.550930        288              7          0   9  7.681354       0.621393    87.788135  success  0.788285  0.148723  under-trained               0   0.621393  0.525760
2          9  Conv2d  0.160197   64   256  4.000000   3.743376        3.059980  0.972381     True    6.568084     conv2d        4.131080  2.323779           0.817439                proj           64  210.755358         64             32          0   1  0.484965       6.568084    32.087798  success  2.562827  0.445225                              0   6.568084  3.156275
3         14  Linear  0.036638  256   768  3.000000   2.024775        2.616225  0.816410     True   19.593229      dense        3.062912  2.295615           1.292106        blocks.0.qkv          256  197.521630        256            141          0   1  0.086302      19.593229    10.081117  success  4.426424  0.236769                              0  19.593229  0.246213
4         15  Linear  0.055388  256   256  1.000000   2.204097        1.871794  0.768400     True    7.066978      dense        2.126758  1.687101           0.849234   blocks.0.out_proj          256   48.652056        256             85          0   1  0.130603       7.066978     6.884422  success  2.658379  0.001513                              0   7.066978  0.121085
5         22  Linear  0.035582  256  1024  4.000000   2.200810        1.922539  0.912763     True    7.474116      dense        2.645829  2.237716           0.873560  blocks.0.ffn.net.0          256  172.868490        256            157          0   1  0.095835       7.474116    23.128955  success  2.733883  0.316174                              0   7.474116  0.298461
6         25  Linear  0.036563  256  1024  4.000000   2.635202        2.713111  0.919093     True   10.704457      dense        2.913626  2.162640           1.029565  blocks.0.ffn.net.3          256  145.425402        256            113          0   1  0.153827      10.704457    13.585500  success  3.271767  0.307987                              0  10.704457  0.402480
7         29  Linear  0.037203  256   768  3.000000   1.973105        2.667484  0.815270     True   22.486498      dense        3.065150  2.320941           1.351922        blocks.1.qkv          256  209.382929        256            157          0   1  0.077662      22.486498     9.311496  success  4.741993  0.231772   over-trained               0  22.486498  0.220575
8         30  Linear  0.042265  256   256  1.000000   2.082750        1.735073  0.758730     True    6.808761      dense        2.164673  1.754314           0.833068   blocks.1.out_proj          256   56.795558        256             93          0   1  0.112276       6.808761     8.341541  success  2.609360  0.000621                              1   6.808761  0.113928
9         37  Linear  0.038050  256  1024  4.000000   2.207188        1.986149  0.911396     True    7.940634      dense        2.676503  2.244073           0.899855  blocks.1.ffn.net.0          256  175.417547        256            149          0   1  0.098897       7.940634    22.091127  success  2.817913  0.307051                              0   7.940634  0.318285
10        40  Linear  0.032962  256  1024  4.000000   2.618852        2.582604  0.919084     True    9.686322      dense        2.864461  2.164444           0.986159  blocks.1.ffn.net.3          256  146.030760        256            114          0   1  0.151619       9.686322    15.075976  success  3.112286  0.314004                              0   9.686322  0.398695
11        44  Linear  0.040960  256   768  3.000000   1.984090        2.579346  0.816316     True   19.953304      dense        3.037828  2.308368           1.300015        blocks.2.qkv          256  203.408019        256            161          0   1  0.077557      19.953304    10.194202  success  4.466912  0.234128   over-trained               0  19.953304  0.211422
12        45  Linear  0.053322  256   256  1.000000   2.119551        2.028021  0.741780     True    9.053496      dense        2.279605  1.739630           0.956816   blocks.2.out_proj          256   54.907229        256             96          0   1  0.114264       9.053496     6.064754  success  3.008903  0.000338                              2   9.053496  0.106601
13        52  Linear  0.039790  256  1024  4.000000   2.142986        2.103051  0.906660     True    9.579983      dense        2.701920  2.264081           0.981365  blocks.2.ffn.net.0          256  183.687957        256            161          0   1  0.090080       9.579983    19.174143  success  3.095155  0.311876                              0   9.579983  0.291923
14        55  Linear  0.034014  256  1024  4.000000   2.544622        2.418942  0.917830     True    8.925032      dense        2.804651  2.181036           0.950610  blocks.2.ffn.net.3          256  151.717494        256            124          0   1  0.138711       8.925032    16.999099  success  2.987479  0.314796                              0   8.925032  0.380815
15        59  Linear  0.036002  256   768  3.000000   2.003692        2.431695  0.822465     True   16.353355      dense        3.004089  2.294556           1.213607        blocks.3.qkv          256  197.040782        256            148          0   1  0.082503      16.353355    12.048951  success  4.043928  0.233114                              0  16.353355  0.233556
16        60  Linear  0.050473  256   256  1.000000   2.144837        1.915655  0.745536     True    7.818929      dense        2.260771  1.741597           0.893147   blocks.3.out_proj          256   55.156485        256             85          0   1  0.124175       7.818929     7.054225  success  2.796235  0.003336                              0   7.818929  0.122368
17        67  Linear  0.039577  256  1024  4.000000   2.140768        2.010001  0.908074     True    8.687927      dense        2.678990  2.261739           0.938916  blocks.3.ffn.net.0          256  182.700096        256            159          0   1  0.090469       8.687927    21.029193  success  2.947529  0.311664                              0   8.687927  0.294407
18        70  Linear  0.032748  256  1024  4.000000   2.525896        2.298319  0.920828     True    8.126480      dense        2.739291  2.179673           0.909902  blocks.3.ffn.net.3          256  151.242068        256            118          0   1  0.140470       8.126480    18.611018  success  2.850698  0.311701                              0   8.126480  0.392658
19        74  Linear  0.037133  256   768  3.000000   1.980781        2.400377  0.819168     True   16.286728      dense        3.014425  2.308758           1.211834        blocks.4.qkv          256  203.590874        256            156          0   1  0.078525      16.286728    12.500416  success  4.035682  0.235317   over-trained               0  16.286728  0.219132
20        75  Linear  0.058587  256   256  1.000000   2.089641        1.772525  0.750405     True    7.050886      dense        2.200724  1.757168           0.848244   blocks.4.out_proj          256   57.170031        256             92          0   1  0.113603       7.050886     8.108205  success  2.655350  0.000856                              1   7.050886  0.113870
21        82  Linear  0.040236  256  1024  4.000000   2.124836        2.138391  0.905343     True   10.147970      dense        2.715158  2.273430           1.006379  blocks.4.ffn.net.0          256  187.685231        256            162          0   1  0.088375      10.147970    18.494854  success  3.185588  0.319266                              0  10.147970  0.291462
22        85  Linear  0.030029  256  1024  4.000000   2.544215        2.494965  0.917034     True    9.564060      dense        2.833985  2.188170           0.980642  blocks.4.ffn.net.3          256  154.230319        256            111          0   1  0.146570       9.564060    16.126030  success  3.092582  0.312360                              0   9.564060  0.416024
23        89  Linear  0.037530  256   768  3.000000   2.019611        2.425603  0.819968     True   15.886379      dense        3.017261  2.289121           1.201025        blocks.5.qkv          256  194.590372        256            151          0   1  0.082975      15.886379    12.248881  success  3.985772  0.231899                              0  15.886379  0.227146
24        90  Linear  0.053472  256   256  1.000000   2.122306        1.833876  0.750423     True    7.313002      dense        2.189516  1.734802           0.864096   blocks.5.out_proj          256   54.300216        256             93          0   1  0.116378       7.313002     7.425161  success  2.704256  0.000131                              2   7.313002  0.110058
25        97  Linear  0.045571  256  1024  4.000000   2.072082        2.268012  0.897771     True   12.432458      dense        2.776079  2.298111           1.094557  blocks.5.ffn.net.0          256  198.660161        256            171          0   1  0.081984      12.432458    15.979154  success  3.525969  0.315865                              0  12.432458  0.273747
26       100  Linear  0.032628  256  1024  4.000000   2.454359        2.463836  0.906143     True   10.089303      dense        2.882334  2.213623           1.003861  blocks.5.ffn.net.3          256  163.539566        256            123          0   1  0.131135      10.089303    16.209204  success  3.176366  0.315680                              0  10.089303  0.385198
27       104  Linear  0.036049  256   768  3.000000   2.046393        2.558069  0.821515     True   17.784355      dense        3.035707  2.277692           1.250038        blocks.6.qkv          256  189.536272        256            149          0   1  0.085724      17.784355    10.657472  success  4.217150  0.235254                              0  17.784355  0.233578
28       105  Linear  0.063014  256   256  1.000000   2.142080        1.970668  0.748285     True    8.317231      dense        2.229789  1.723281           0.919979   blocks.6.out_proj          256   52.878724        256             87          0   1  0.122444       8.317231     6.357732  success  2.883961  0.001208                              0   8.317231  0.116429
29       112  Linear  0.043990  256  1024  4.000000   2.075818        2.317903  0.894843     True   13.080400      dense        2.807580  2.304898           1.116621  blocks.6.ffn.net.0          256  201.789093        256            166          0   1  0.083500      13.080400    15.426830  success  3.616683  0.310847                              0  13.080400  0.284373
30       115  Linear  0.036795  256  1024  4.000000   2.410444        2.499905  0.902919     True   10.892159      dense        2.897369  2.220059           1.037114  blocks.6.ffn.net.3          256  165.981131        256            134          0   1  0.121844      10.892159    15.238589  success  3.300327  0.311145                              0  10.892159  0.357625
31       119  Linear  0.035124  256   768  3.000000   2.023233        2.343551  0.827711     True   14.398577      dense        2.971383  2.284245           1.158320        blocks.7.qkv          256  192.417620        256            151          0   1  0.083270      14.398577    13.363656  success  3.794546  0.234792                              0  14.398577  0.229905
32       120  Linear  0.064962  256   256  1.000000   2.058057        1.676545  0.746335     True    6.525671      dense        2.184384  1.758833           0.814625   blocks.7.out_proj          256   57.389597        256             98          0   1  0.106880       6.525671     8.794437  success  2.554539  0.000652                              1   6.525671  0.102316
33       127  Linear  0.042826  256  1024  4.000000   2.053368        2.445629  0.888479     True   15.525053      dense        2.862687  2.316983           1.191033  blocks.7.ffn.net.0          256  207.483224        256            171          0   1  0.080553      15.525053    13.364413  success  3.940184  0.311595                              0  15.525053  0.273899
34       130  Linear  0.038898  256  1024  4.000000   2.390614        2.565252  0.897263     True   11.831814      dense        2.945250  2.230838           1.073051  blocks.7.ffn.net.3          256  170.152527        256            134          0   1  0.120131      11.831814    14.380933  success  3.439740  0.317548                              0  11.831814  0.356781
35       134  Linear  0.038064  256   768  3.000000   1.990119        2.347298  0.825836     True   15.117354      dense        2.975281  2.298770           1.179476        blocks.8.qkv          256  198.961758        256            160          0   1  0.078276      15.117354    13.161149  success  3.888104  0.238867   over-trained               0  15.117354  0.215607
36       135  Linear  0.059474  256   256  1.000000   2.086031        2.095863  0.730731     True   10.109118      dense        2.329528  1.763215           1.004713   blocks.8.out_proj          256   57.971596        256             96          0   1  0.110843      10.109118     5.734585  success  3.179484  0.001369                              0  10.109118  0.105944
37       142  Linear  0.045665  256  1024  4.000000   2.039632        2.518943  0.884150     True   17.179049      dense        2.904411  2.331650           1.234999  blocks.8.ffn.net.0          256  214.610108        256            170          0   1  0.079736      17.179049    12.492549  success  4.144762  0.322097                              0  17.179049  0.277258
38       145  Linear  0.042427  256  1024  4.000000   2.346357        2.504783  0.890788     True   11.682080      dense        2.959492  2.244178           1.067520  blocks.8.ffn.net.3          256  175.460024        256            140          0   1  0.113788      11.682080    15.019587  success  3.417906  0.319252                              0  11.682080  0.341103
39       149  Linear  0.039226  256   768  3.000000   2.021448        2.331048  0.827435     True   14.228447      dense        2.972278  2.286446           1.153157        blocks.9.qkv          256  193.395542        256            153          0   1  0.082579      14.228447    13.592175  success  3.772061  0.235662                              0  14.228447  0.226984
40       150  Linear  0.056637  256   256  1.000000   2.144531        1.864681  0.757120     True    7.404664      dense        2.170983  1.715887           0.869505   blocks.9.out_proj          256   51.986016        256             86          0   1  0.123418       7.404664     7.020713  success  2.721151  0.000151                              1   7.404664  0.118554
41       157  Linear  0.042302  256  1024  4.000000   2.030784        2.680326  0.873333     True   20.885664      dense        2.997532  2.346702           1.319848  blocks.9.ffn.net.0          256  222.178355        256            169          0   1  0.079291      20.885664    10.637840  success  4.570084  0.316205                              0  20.885664  0.277665
42       160  Linear  0.041753  256  1024  4.000000   2.335950        2.565998  0.884683     True   12.545314      dense        3.026210  2.257641           1.098482  blocks.9.ffn.net.3          256  180.984176        256            138          0   1  0.113724      12.545314    14.426437  success  3.541936  0.317079                              0  12.545314  0.347775
43       165  Linear  0.042615  128   256  2.000000   1.981993        1.466424  0.778452     True    5.493807      dense        1.785638  1.533676           0.739873          src_head.0          128   34.172473        128             60          0   1  0.126775       5.493807     6.220181  success  2.343887  0.100862   over-trained               0   5.493807  0.100111
44       167  Linear  0.096029   64   128  2.000000   2.320417       -0.303627  0.845213     True    0.739860      dense        0.140473  0.786664          -0.130850          src_head.2           64    6.118762         64             22          0   1  0.281514       0.739860     8.270161  success  0.860151  0.072486                              0   0.739860  0.080862
45       169  Linear  0.062576  256   256  1.000000   1.719511        1.441331  0.801624     True    6.890037      dense        2.055910  1.902546           0.838222         dest_head.0          256   79.899836        256            125          0   1  0.064355       6.890037    11.596431  success  2.624888  0.001077   over-trained               0   6.890037  0.079994
46       171  Linear  0.052098   73   256  3.506849   2.836197        1.446990  0.878616     True    3.237327      dense        1.654087  1.419799           0.510187         dest_head.2           73   26.290519         73             19          0   1  0.421252       3.237327     8.121057  success  1.799257  0.188868                              0   3.237327  0.445558
47       173  Conv2d  0.041991  256   256  1.000000   3.132143        1.149686  1.039437     True    2.328416     conv2d        2.113319  2.441571           0.367061        value_conv.0         2304  276.420758       2304            406          0   9  0.105816       2.328416   118.716207  success  1.525915  0.000990                              9   2.328416  0.209357
48       177  Linear  0.060571  128   256  2.000000   2.708146        0.602842  0.871760     True    1.669564      dense        0.893753  1.197524           0.222603         value_mlp.0          128   15.758817        128             49          0   1  0.244021       1.669564     9.438879  success  1.292116  0.089591                              0   1.669564  0.102404
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 00:02:32 2025      Time elapsed: 89.20296s
Begin: Training epoch 11                       Current time: Sun Oct 26 00:02:32 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:02:51 2025      Time elapsed: 9064.95701      ETA: 345102.91353s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:03:11 2025      Time elapsed: 9084.63913      ETA: 168383.78640s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:03:31 2025      Time elapsed: 9104.42561      ETA: 109465.54402s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:03:51 2025      Time elapsed: 9124.24600      ETA: 79996.82683s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:04:11 2025      Time elapsed: 9144.13382      ETA: 62308.12792s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:04:30 2025      Time elapsed: 9164.09875      ETA: 50509.45762s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:04:50 2025      Time elapsed: 9184.10418      ETA: 42076.31733s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:05:11 2025      Time elapsed: 9204.15724      ETA: 35746.64570s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:05:31 2025      Time elapsed: 9224.30837      ETA: 30819.43921s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:05:51 2025      Time elapsed: 9244.55597      ETA: 26873.92422s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:06:11 2025      Time elapsed: 9264.88065      ETA: 23642.29092s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:06:32 2025      Time elapsed: 9285.16783      ETA: 20945.79112s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:06:52 2025      Time elapsed: 9305.60599      ETA: 18661.31910s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:07:12 2025      Time elapsed: 9326.12447      ETA: 16700.42432s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:07:33 2025      Time elapsed: 9346.50671      ETA: 14998.02778s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:07:53 2025      Time elapsed: 9366.81783      ETA: 13505.78046s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:08:14 2025      Time elapsed: 9387.15778      ETA: 12186.73955s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:08:34 2025      Time elapsed: 9407.62928      ETA: 11012.15272s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:08:55 2025      Time elapsed: 9428.21903      ETA: 9959.17663s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:09:15 2025      Time elapsed: 9448.72288      ETA: 9009.35727s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:09:36 2025      Time elapsed: 9469.28518      ETA: 8148.09444s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:09:56 2025      Time elapsed: 9489.86028      ETA: 7363.26887s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:10:17 2025      Time elapsed: 9510.49735      ETA: 6644.94315s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:10:37 2025      Time elapsed: 9531.11012      ETA: 5984.74290s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:10:58 2025      Time elapsed: 9551.76127      ETA: 5375.73125s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:11:19 2025      Time elapsed: 9572.42339      ETA: 4811.98361s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:11:39 2025      Time elapsed: 9593.10952      ETA: 4288.47526s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:12:00 2025      Time elapsed: 9613.82009      ETA: 3800.89244s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:12:21 2025      Time elapsed: 9634.53023      ETA: 3345.50757s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:12:42 2025      Time elapsed: 9655.16234      ETA: 2919.07742s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:13:02 2025      Time elapsed: 9675.74368      ETA: 2518.81456s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:13:23 2025      Time elapsed: 9696.36252      ETA: 2142.29009s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:13:43 2025      Time elapsed: 9716.90172      ETA: 1787.32101s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:14:04 2025      Time elapsed: 9737.36863      ETA: 1452.01350s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:14:24 2025      Time elapsed: 9757.76538      ETA: 1134.68872s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:14:44 2025      Time elapsed: 9778.11581      ETA: 833.85599s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:15:05 2025      Time elapsed: 9798.56867      ETA: 548.19019s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:15:25 2025      Time elapsed: 9818.98714      ETA: 276.48201s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:15:46 2025      Time elapsed: 9839.37614      ETA: 17.66042s
Epoch 11: Avg Policy Loss=2.7542, Avg Value Loss=0.4790
  End: Training epoch 11                       Current time: Sun Oct 26 00:15:47 2025      Time elapsed: 795.31694s
Begin: Validating epoch 11                     Current time: Sun Oct 26 00:15:47 2025      
Validation: Policy Loss=2.7511, Value Loss=0.4758, Top-1 Acc=0.2052, Top-5 Acc=0.5171
  End: Validating epoch 11                     Current time: Sun Oct 26 00:16:11 2025      Time elapsed: 23.86946s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_11.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 00:16:11 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.077530   19    32  1.684211   3.310362        0.249608  0.924698     True    1.189603     conv2d        0.689092  1.460959           0.075402     conv_stem.net.0          171   28.904060        171             47          0   9  0.337001       1.189603    24.297235  success  1.090689  0.123765                              0   1.189603  0.232210
1          6  Conv2d  0.109430   32    64  2.000000  21.501208       -4.702390  0.968451     True    0.604361     conv2d       -4.547479  1.722979          -0.218704     conv_stem.net.3          288   52.841958        288              7          0   9  7.748728       0.604361    87.434419  success  0.777407  0.146804  under-trained               0   0.604361  0.512042
2          9  Conv2d  0.156746   64   256  4.000000   3.592744        2.864737  0.972546     True    6.271441     conv2d        3.956730  2.305882           0.797367                proj           64  202.246820         64             34          0   1  0.444652       6.271441    32.248857  success  2.504285  0.430039                              0   6.271441  2.892929
3         14  Linear  0.035157  256   768  3.000000   1.961229        2.538052  0.813591     True   19.683992      dense        3.030233  2.316801           1.294113        blocks.0.qkv          256  207.396316        256            154          0   1  0.077458      19.683992    10.536293  success  4.436665  0.235098   over-trained               0  19.683992  0.216705
4         15  Linear  0.053490  256   256  1.000000   2.130934        1.834802  0.760952     True    7.261594      dense        2.127093  1.706357           0.861032   blocks.0.out_proj          256   50.857688        256             88          0   1  0.120558       7.261594     7.003653  success  2.694735  0.000630                              1   7.261594  0.113551
5         22  Linear  0.041032  256  1024  4.000000   2.104983        1.963984  0.904287     True    8.570708      dense        2.670001  2.257922           0.933017  blocks.0.ffn.net.0          256  181.101315        256            170          0   1  0.084748       8.570708    21.130262  success  2.927577  0.314240                              0   8.570708  0.263321
6         25  Linear  0.032300  256  1024  4.000000   2.558482        2.634726  0.915142     True   10.710269      dense        2.876564  2.172914           1.029800  blocks.0.ffn.net.3          256  148.906694        256            119          0   1  0.142866      10.710269    13.903170  success  3.272655  0.306891                              0  10.710269  0.385473
7         29  Linear  0.037560  256   768  3.000000   1.926825        2.603016  0.813015     True   22.435505      dense        3.043803  2.339643           1.350936        blocks.1.qkv          256  218.596191        256            163          0   1  0.072595      22.435505     9.743315  success  4.736613  0.228202   over-trained               0  22.435505  0.205469
8         30  Linear  0.039864  256   256  1.000000   2.029234        1.720878  0.754905     True    7.047634      dense        2.168217  1.776405           0.848043   blocks.1.out_proj          256   59.759293        256             93          1   1  0.106727       7.047634     8.479342  success  2.654738  0.000053                              2   7.047634  0.112077
9         37  Linear  0.044634  256  1024  4.000000   2.115753        2.064446  0.903107     True    9.456927      dense        2.700630  2.265064           0.975750  blocks.1.ffn.net.0          256  184.104298        256            158          0   1  0.088765       9.456927    19.467666  success  3.075212  0.305699                              0   9.456927  0.288675
10        40  Linear  0.028905  256  1024  4.000000   2.530287        2.482814  0.915979     True    9.577195      dense        2.814989  2.174418           0.981238  blocks.1.ffn.net.3          256  149.423211        256            115          0   1  0.142700       9.577195    15.601980  success  3.094704  0.310055                              0   9.577195  0.391235
11        44  Linear  0.039778  256   768  3.000000   1.947389        2.525816  0.814535     True   19.816502      dense        3.022743  2.325042           1.297027        blocks.2.qkv          256  211.369479        256            160          0   1  0.074898      19.816502    10.666337  success  4.451573  0.232866   over-trained               0  19.816502  0.208272
12        45  Linear  0.052019  256   256  1.000000   2.073887        1.956740  0.740966     True    8.780388      dense        2.252116  1.755218           0.943514   blocks.2.out_proj          256   56.913895        256             96          0   1  0.109603       8.780388     6.481934  success  2.963172  0.000333                              1   8.780388  0.104870
13        52  Linear  0.045407  256  1024  4.000000   2.060158        2.160906  0.898507     True   11.191887      dense        2.729859  2.286531           1.048903  blocks.2.ffn.net.0          256  193.433235        256            174          0   1  0.080370      11.191887    17.283344  success  3.345428  0.306182                              0  11.191887  0.259270
14        55  Linear  0.028882  256  1024  4.000000   2.473948        2.377189  0.914277     True    9.138788      dense        2.789497  2.192955           0.960889  blocks.2.ffn.net.3          256  155.939250        256            122          0   1  0.133445       9.138788    17.063449  success  3.023043  0.313140                              0   9.138788  0.382453
15        59  Linear  0.038023  256   768  3.000000   1.948450        2.351044  0.820691     True   16.092480      dense        2.974055  2.311293           1.206623        blocks.3.qkv          256  204.782507        256            152          0   1  0.076929      16.092480    12.725354  success  4.011543  0.232104   over-trained               0  16.092480  0.218831
16        60  Linear  0.049268  256   256  1.000000   2.065672        1.834070  0.744151     True    7.724682      dense        2.217689  1.755726           0.887881   blocks.3.out_proj          256   56.980420        256             92          0   1  0.111104       7.724682     7.376410  success  2.779331  0.000411                              1   7.724682  0.109031
17        67  Linear  0.043437  256  1024  4.000000   2.056347        2.090274  0.899524     True   10.387197      dense        2.710985  2.284298           1.016498  blocks.3.ffn.net.0          256  192.441221        256            171          0   1  0.080781      10.387197    18.526770  success  3.222918  0.307936                              0  10.387197  0.261975
18        70  Linear  0.028999  256  1024  4.000000   2.466487        2.253369  0.917575     True    8.195862      dense        2.730073  2.190873           0.913595  blocks.3.ffn.net.3          256  155.193137        256            120          0   1  0.133871       8.195862    18.935548  success  2.862842  0.308599                              0   8.195862  0.387054
19        74  Linear  0.036130  256   768  3.000000   1.935475        2.346470  0.817359     True   16.306038      dense        2.995571  2.326120           1.212348        blocks.4.qkv          256  211.894767        256            162          0   1  0.073498      16.306038    12.994865  success  4.038074  0.231191   over-trained               0  16.306038  0.204460
20        75  Linear  0.055560  256   256  1.000000   2.042323        1.708783  0.747400     True    6.865719      dense        2.195084  1.775199           0.836686   blocks.4.out_proj          256   59.593537        256             92          0   1  0.108670       6.865719     8.679869  success  2.620252  0.000407                              1   6.865719  0.111866
21        82  Linear  0.046774  256  1024  4.000000   2.034879        2.199494  0.896796     True   12.047482      dense        2.743726  2.297957           1.080896  blocks.4.ffn.net.0          256  198.589705        256            172          0   1  0.078909      12.047482    16.483919  success  3.470948  0.315670                              0  12.047482  0.261410
22        85  Linear  0.025783  256  1024  4.000000   2.452371        2.422160  0.912724     True    9.720326      dense        2.807074  2.201211           0.987681  blocks.4.ffn.net.3          256  158.932041        256            119          0   1  0.133139       9.720326    16.350484  success  3.117744  0.307635                              0   9.720326  0.391278
23        89  Linear  0.032123  256   768  3.000000   1.976862        2.369897  0.818173     True   15.805846      dense        2.999002  2.305737           1.198818        blocks.5.qkv          256  202.179260        256            152          0   1  0.079234      15.805846    12.791423  success  3.975657  0.229387   over-trained               0  15.805846  0.220718
24        90  Linear  0.054553  256   256  1.000000   2.067996        1.793557  0.745862     True    7.367023      dense        2.182660  1.749938           0.867292   blocks.5.out_proj          256   56.226044        256             94          0   1  0.110155       7.367023     7.632126  success  2.714226  0.000217                              1   7.367023  0.105574
25        97  Linear  0.045658  256  1024  4.000000   1.994117        2.304589  0.889697     True   14.311782      dense        2.801199  2.323248           1.155694  blocks.5.ffn.net.0          256  210.498021        256            186          0   1  0.072892      14.311782    14.708023  success  3.783092  0.316290   over-trained               0  14.311782  0.239682
26       100  Linear  0.028658  256  1024  4.000000   2.367736        2.396016  0.900974     True   10.278828      dense        2.866393  2.228796           1.011944  blocks.5.ffn.net.3          256  169.354038        256            127          0   1  0.121367      10.278828    16.476007  success  3.206061  0.314374                              0  10.278828  0.369527
27       104  Linear  0.031626  256   768  3.000000   1.999787        2.478080  0.820506     True   17.344902      dense        3.006938  2.294273           1.239172        blocks.6.qkv          256  196.912373        256            150          0   1  0.081632      17.344902    11.352752  success  4.164721  0.232955   over-trained               0  17.344902  0.227269
28       105  Linear  0.053132  256   256  1.000000   2.083543        1.892070  0.744225     True    8.092864      dense        2.209079  1.739130           0.908102   blocks.6.out_proj          256   54.844132        256             91          1   1  0.113586       8.092864     6.776851  success  2.844796  0.000080                              2   8.092864  0.108340
29       112  Linear  0.046533  256  1024  4.000000   1.996535        2.348617  0.886846     True   15.008822      dense        2.830459  2.330510           1.176347  blocks.6.ffn.net.0          256  214.047470        256            177          0   1  0.074904      15.008822    14.261443  success  3.874122  0.307256   over-trained               0  15.008822  0.254650
30       115  Linear  0.029272  256  1024  4.000000   2.338834        2.446009  0.897087     True   11.112815      dense        2.891868  2.236171           1.045824  blocks.6.ffn.net.3          256  172.254566        256            137          0   1  0.114384      11.112815    15.500534  success  3.333589  0.308612                              0  11.112815  0.346558
31       119  Linear  0.038299  256   768  3.000000   1.969111        2.276112  0.824749     True   14.318859      dense        2.951939  2.301993           1.155908        blocks.7.qkv          256  200.444117        256            156          0   1  0.077591      14.318859    13.998610  success  3.784027  0.229982   over-trained               0  14.318859  0.214916
32       120  Linear  0.055831  256   256  1.000000   2.014791        1.641318  0.740659     True    6.525813      dense        2.196638  1.776749           0.814635   blocks.7.out_proj          256   59.806608        256            103          0   1  0.099990       6.525813     9.164622  success  2.554567  0.000498                              1   6.525813  0.095041
33       127  Linear  0.048378  256  1024  4.000000   1.983302        2.452465  0.881793     True   17.240770      dense        2.875403  2.341708           1.236557  blocks.7.ffn.net.0          256  219.638504        256            181          0   1  0.073088      17.240770    12.739483  success  4.152201  0.310376   over-trained               0  17.240770  0.248273
34       130  Linear  0.031545  256  1024  4.000000   2.341166        2.519861  0.891978     True   11.921403      dense        2.947826  2.246585           1.076327  blocks.7.ffn.net.3          256  176.435301        256            128          0   1  0.118543      11.921403    14.799877  success  3.452739  0.314263                              0  11.921403  0.368044
35       134  Linear  0.033971  256   768  3.000000   1.959342        2.311648  0.824040     True   15.128929      dense        2.970179  2.314673           1.179808        blocks.8.qkv          256  206.382325        256            157          0   1  0.076564      15.128929    13.641569  success  3.889592  0.235756   over-trained               0  15.128929  0.217124
36       135  Linear  0.053695  256   256  1.000000   2.041396        2.020860  0.729754     True    9.771029      dense        2.296935  1.774887           0.989940   blocks.8.out_proj          256   59.550690        256             96          0   1  0.106287       9.771029     6.094618  success  3.125865  0.000712                              1   9.771029  0.103132
37       142  Linear  0.050031  256  1024  4.000000   1.960385        2.528490  0.876177     True   19.489143      dense        2.919820  2.359775           1.289793  blocks.8.ffn.net.0          256  228.968059        256            180          0   1  0.071583      19.489143    11.748493  success  4.414651  0.319736   over-trained               0  19.489143  0.248944
38       145  Linear  0.036534  256  1024  4.000000   2.275016        2.481048  0.882761     True   12.318644      dense        2.972770  2.265002           1.090563  blocks.8.ffn.net.3          256  184.077880        256            141          0   1  0.107376      12.318644    14.943032  success  3.509793  0.314652                              0  12.318644  0.333759
39       149  Linear  0.037420  256   768  3.000000   1.964974        2.264421  0.825612     True   14.203397      dense        2.947096  2.303050           1.152392        blocks.9.qkv          256  200.932580        256            157          0   1  0.077013      14.203397    14.146798  success  3.768739  0.231245   over-trained               0  14.203397  0.213392
40       150  Linear  0.055418  256   256  1.000000   2.072389        1.800563  0.752932     True    7.393235      dense        2.148310  1.733878           0.868835   blocks.9.out_proj          256   54.184867        256             94          0   1  0.110608       7.393235     7.328979  success  2.719050  0.000507                              1   7.393235  0.105153
41       157  Linear  0.044413  256  1024  4.000000   1.950085        2.676835  0.865553     True   23.587193      dense        3.002090  2.375204           1.372676  blocks.9.ffn.net.0          256  237.248797        256            185          0   1  0.069852      23.587193    10.058374  success  4.856665  0.311222   over-trained               0  23.587193  0.240243
42       160  Linear  0.040966  256  1024  4.000000   2.268238        2.541321  0.876151     True   13.194540      dense        3.039505  2.278808           1.120394  blocks.9.ffn.net.3          256  190.023944        256            138          0   1  0.107960      13.194540    14.401710  success  3.632429  0.315232                              0  13.194540  0.342588
43       165  Linear  0.039145  128   256  2.000000   1.906099        1.491682  0.770082     True    6.061550      dense        1.842640  1.579230           0.782584          src_head.0          128   37.951551        128             71          0   1  0.107534       6.061550     6.261031  success  2.462022  0.100137   over-trained               0   6.061550  0.082582
44       167  Linear  0.094686   64   128  2.000000   2.041576       -0.232922  0.842966     True    0.768972      dense        0.300773  0.819236          -0.114090          src_head.2           64    6.595328         64             30          0   1  0.190165       0.768972     8.576812  success  0.876910  0.071390                              0   0.768972  0.054297
45       169  Linear  0.067846  256   256  1.000000   1.669856        1.469707  0.797778     True    7.588226      dense        2.095932  1.934325           0.880140         dest_head.0          256   85.965622        256            132          0   1  0.058303       7.588226    11.328817  success  2.754673  0.001137   over-trained               0   7.588226  0.070002
46       171  Linear  0.063632   73   256  3.506849   2.758951        1.538737  0.878480     True    3.611814      dense        1.759180  1.466866           0.557725         dest_head.2           73   29.299888         73             21          0   1  0.383835       3.611814     8.112236  success  1.900477  0.198055                              0   3.611814  0.454858
47       173  Conv2d  0.034168  256   256  1.000000   2.769064        1.197995  1.033914     True    2.707917     conv2d        2.191968  2.446960           0.432635        value_conv.0         2304  279.872106       2304            120          0   9  0.161493       2.707917   103.353273  success  1.645575  0.001671                              5   2.707917  0.354126
48       177  Linear  0.066080  128   256  2.000000   2.576949        0.702123  0.851716     True    1.872678      dense        1.042336  1.220745           0.272463         value_mlp.0          128   16.624359        128             50          0   1  0.223014       1.872678     8.877318  success  1.368458  0.089281                              0   1.872678  0.097513
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 00:17:38 2025      Time elapsed: 87.11891s
Begin: Training epoch 12                       Current time: Sun Oct 26 00:17:38 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:17:58 2025      Time elapsed: 9971.33070      ETA: 379608.55983s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:18:17 2025      Time elapsed: 9990.91430      ETA: 185181.59696s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:18:37 2025      Time elapsed: 10010.61010     ETA: 120360.90223s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:18:57 2025      Time elapsed: 10030.42342     ETA: 87941.73741s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:19:17 2025      Time elapsed: 10050.34886     ETA: 68483.07714s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:19:37 2025      Time elapsed: 10070.37159     ETA: 55504.53144s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:19:57 2025      Time elapsed: 10090.47951     ETA: 46228.81116s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:20:17 2025      Time elapsed: 10110.60570     ETA: 39267.06491s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:20:37 2025      Time elapsed: 10130.70660     ETA: 33847.81640s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:20:57 2025      Time elapsed: 10150.85263     ETA: 29508.52862s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:21:18 2025      Time elapsed: 10171.13955     ETA: 25954.89885s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:21:38 2025      Time elapsed: 10191.41740     ETA: 22990.13910s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:21:58 2025      Time elapsed: 10211.63697     ETA: 20478.25969s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:22:18 2025      Time elapsed: 10231.92197     ETA: 18322.44885s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:22:39 2025      Time elapsed: 10252.26435     ETA: 16451.46688s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:22:59 2025      Time elapsed: 10272.62011     ETA: 14811.83413s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:23:19 2025      Time elapsed: 10292.91073     ETA: 13362.61999s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:23:40 2025      Time elapsed: 10313.17916     ETA: 12072.14917s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:24:00 2025      Time elapsed: 10333.48682     ETA: 10915.42530s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:24:20 2025      Time elapsed: 10353.94050     ETA: 9872.48227s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:24:41 2025      Time elapsed: 10374.61113     ETA: 8927.10587s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:25:01 2025      Time elapsed: 10394.98114     ETA: 8065.56037s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:25:22 2025      Time elapsed: 10415.22485     ETA: 7277.07232s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:25:42 2025      Time elapsed: 10435.50152     ETA: 6552.62533s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:26:02 2025      Time elapsed: 10455.95708     ETA: 5884.61265s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:26:23 2025      Time elapsed: 10476.55581     ETA: 5266.48402s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:26:43 2025      Time elapsed: 10497.00283     ETA: 4692.54905s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:27:04 2025      Time elapsed: 10517.34132     ETA: 4158.10602s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:27:24 2025      Time elapsed: 10537.79574     ETA: 3659.15873s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:27:45 2025      Time elapsed: 10558.21740     ETA: 3192.10106s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:28:05 2025      Time elapsed: 10578.51675     ETA: 2753.82678s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:28:25 2025      Time elapsed: 10598.78889     ETA: 2341.66992s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:28:45 2025      Time elapsed: 10619.07112     ETA: 1953.26551s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:29:06 2025      Time elapsed: 10639.35290     ETA: 1586.51527s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:29:26 2025      Time elapsed: 10659.61251     ETA: 1239.56066s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:29:46 2025      Time elapsed: 10679.80809     ETA: 910.75030s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:30:06 2025      Time elapsed: 10699.96566     ETA: 598.61970s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:30:27 2025      Time elapsed: 10720.18270     ETA: 301.85778s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:30:47 2025      Time elapsed: 10740.49289     ETA: 19.27781s
Epoch 12: Avg Policy Loss=2.7348, Avg Value Loss=0.4738
  End: Training epoch 12                       Current time: Sun Oct 26 00:30:48 2025      Time elapsed: 790.05360s
Begin: Validating epoch 12                     Current time: Sun Oct 26 00:30:48 2025      
Validation: Policy Loss=2.7325, Value Loss=0.4697, Top-1 Acc=0.2095, Top-5 Acc=0.5230
  End: Validating epoch 12                     Current time: Sun Oct 26 00:31:12 2025      Time elapsed: 23.41833s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_12.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 00:31:12 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.075502   19    32  1.684211   3.494717        0.263175  0.922698     True    1.189342     conv2d        0.660304  1.450910           0.075307     conv_stem.net.0          171   28.242920        171             39          0   9  0.399474       1.189342    23.746686  success  1.090569  0.122819                              0   1.189342  0.255118
1          6  Conv2d  0.108218   32    64  2.000000   4.966846       -1.147710  0.968277     True    0.587389     conv2d       -0.095634  1.709826          -0.231074     conv_stem.net.3          288   51.265651        288             60          0   9  0.512118       0.587389    87.277156  success  0.766413  0.144957                              0   0.587389  0.295543
2          9  Conv2d  0.158702   64   256  4.000000   3.836072        2.990785  0.972722     True    6.020710     conv2d        4.054035  2.287984           0.779648                proj           64  194.081545         64             32          0   1  0.501351       6.020710    32.235660  success  2.453713  0.404354                              0   6.020710  2.934452
3         14  Linear  0.035286  256   768  3.000000   1.904115        2.480946  0.810454     True   20.088114      dense        3.010420  2.338389           1.302939        blocks.0.qkv          256  217.966336        256            168          0   1  0.069754      20.088114    10.850513  success  4.481977  0.232921   over-trained               0  20.088114  0.188936
4         15  Linear  0.048889  256   256  1.000000   2.088217        1.810266  0.755646     True    7.360297      dense        2.137928  1.727991           0.866895   blocks.0.out_proj          256   53.455297        256             87          0   1  0.116669       7.360297     7.262655  success  2.712987  0.000308                              2   7.360297  0.114025
5         22  Linear  0.043503  256  1024  4.000000   2.038035        2.042427  0.895432     True   10.049743      dense        2.708797  2.280890           1.002155  blocks.0.ffn.net.0          256  190.936775        256            180          0   1  0.077371      10.049743    18.999171  success  3.170133  0.305546                              0  10.049743  0.239407
6         25  Linear  0.029937  256  1024  4.000000   2.481609        2.554672  0.911648     True   10.701429      dense        2.843418  2.186662           1.029442  blocks.0.ffn.net.3          256  153.695742        256            118          0   1  0.136393      10.701429    14.362169  success  3.271304  0.305993                              0  10.701429  0.386079
7         29  Linear  0.038290  256   768  3.000000   1.874857        2.534976  0.810911     True   22.495222      dense        3.019019  2.358594           1.352090        blocks.1.qkv          256  228.346127        256            169          0   1  0.067297      22.495222    10.150872  success  4.742913  0.223235   over-trained               0  22.495222  0.188556
8         30  Linear  0.038004  256   256  1.000000   1.971283        1.700006  0.752107     True    7.284267      dense        2.167029  1.798614           0.862386   blocks.1.out_proj          256   62.894623        256             96          0   1  0.099131       7.284267     8.634311  success  2.698938  0.000287   over-trained               1   7.284267  0.105891
9         37  Linear  0.049771  256  1024  4.000000   2.023450        2.111171  0.894178     True   11.049748      dense        2.726033  2.289885           1.043352  blocks.1.ffn.net.0          256  194.932892        256            174          0   1  0.077588      11.049748    17.641387  success  3.324116  0.303055                              0  11.049748  0.248650
10        40  Linear  0.029446  256  1024  4.000000   2.448953        2.400922  0.912946     True    9.558449      dense        2.784296  2.189259           0.980387  blocks.1.ffn.net.3          256  154.617797        256            119          0   1  0.132825       9.558449    16.176034  success  3.091674  0.309844                              0   9.558449  0.381362
11        44  Linear  0.040470  256   768  3.000000   1.902963        2.450439  0.812488     True   19.395308      dense        3.003718  2.342921           1.287697        blocks.2.qkv          256  220.252770        256            163          0   1  0.070726      19.395308    11.355982  success  4.404010  0.230989   over-trained               0  19.395308  0.197401
12        45  Linear  0.044151  256   256  1.000000   2.034379        1.914936  0.738597     True    8.735502      dense        2.247522  1.774281           0.941288   blocks.2.out_proj          256   59.467714        256             98          0   1  0.104488       8.735502     6.807590  success  2.955588  0.002237                              0   8.735502  0.101873
13        52  Linear  0.047189  256  1024  4.000000   1.981829        2.204765  0.890050     True   12.956563      dense        2.758672  2.311514           1.112490  blocks.2.ffn.net.0          256  204.886965        256            185          0   1  0.072186      12.956563    15.813373  success  3.599523  0.302577   over-trained               0  12.956563  0.231043
14        55  Linear  0.029678  256  1024  4.000000   2.395567        2.318697  0.911282     True    9.287768      dense        2.769440  2.208409           0.967911  blocks.2.ffn.net.3          256  161.588031        256            119          0   1  0.127931       9.287768    17.397939  success  3.047584  0.309707                              0   9.287768  0.388053
15        59  Linear  0.037685  256   768  3.000000   1.908061        2.290704  0.818602     True   15.868645      dense        2.962322  2.328785           1.200540        blocks.3.qkv          256  213.198701        256            160          0   1  0.071789      15.868645    13.435218  success  3.983547  0.228207   over-trained               0  15.868645  0.201380
16        60  Linear  0.050296  256   256  1.000000   2.004505        1.785844  0.741404     True    7.778847      dense        2.202835  1.774169           0.890915   blocks.3.out_proj          256   59.452400        256             95          0   1  0.103060       7.778847     7.642829  success  2.789058  0.000849                              1   7.778847  0.102346
17        67  Linear  0.049492  256  1024  4.000000   1.980010        2.157134  0.890450     True   12.287299      dense        2.748350  2.310504           1.089456  blocks.3.ffn.net.0          256  204.410843        256            182          0   1  0.072643      12.287299    16.635946  success  3.505324  0.303465   over-trained               0  12.287299  0.234029
18        70  Linear  0.027346  256  1024  4.000000   2.391455        2.203802  0.914169     True    8.347026      dense        2.721195  2.206145           0.921532  blocks.3.ffn.net.3          256  160.747836        256            117          0   1  0.128640       8.347026    19.258097  success  2.889122  0.307833                              0   8.347026  0.392968
19        74  Linear  0.038128  256   768  3.000000   1.887696        2.296280  0.815264     True   16.460596      dense        2.980060  2.345022           1.216446        blocks.4.qkv          256  221.320906        256            165          0   1  0.069107      16.460596    13.445498  success  4.057166  0.225645   over-trained               0  16.460596  0.193218
20        75  Linear  0.047892  256   256  1.000000   2.004005        1.674502  0.744166     True    6.848220      dense        2.204928  1.795445           0.835578   blocks.4.out_proj          256   62.437402        256             91          0   1  0.105248       6.848220     9.117318  success  2.616910  0.001970                              0   6.848220  0.112254
21        82  Linear  0.049486  256  1024  4.000000   1.959955        2.253890  0.887835     True   14.124414      dense        2.779762  2.325030           1.149970  blocks.4.ffn.net.0          256  211.363703        256            187          0   1  0.070199      14.124414    14.964422  success  3.758246  0.310970   over-trained               0  14.124414  0.228098
22        85  Linear  0.026275  256  1024  4.000000   2.362175        2.376018  0.908321     True   10.135852      dense        2.794828  2.218352           1.005860  blocks.4.ffn.net.3          256  165.330275        256            131          0   1  0.119014      10.135852    16.311434  success  3.183685  0.303162                              0  10.135852  0.361182
23        89  Linear  0.033968  256   768  3.000000   1.926338        2.309841  0.815809     True   15.815532      dense        2.980598  2.323872           1.199084        blocks.5.qkv          256  210.800894        256            162          0   1  0.072780      15.815532    13.328726  success  3.976875  0.224782   over-trained               0  15.815532  0.199285
24        90  Linear  0.054828  256   256  1.000000   2.034343        1.764427  0.741865     True    7.367504      dense        2.190364  1.766906           0.867320   blocks.5.out_proj          256   58.466397        256             93          0   1  0.107256       7.367504     7.935713  success  2.714315  0.000775                              1   7.367504  0.105469
25        97  Linear  0.052834  256  1024  4.000000   1.926278        2.340318  0.881306     True   16.403749      dense        2.832134  2.350613           1.214943  blocks.5.ffn.net.0          256  224.188415        256            192          0   1  0.066848      16.403749    13.666901  success  4.050154  0.313004   over-trained               0  16.403749  0.220211
26       100  Linear  0.029025  256  1024  4.000000   2.286505        2.325434  0.896505     True   10.399821      dense        2.853911  2.247367           1.017026  blocks.5.ffn.net.3          256  176.753231        256            137          0   1  0.109914      10.399821    16.995795  success  3.224875  0.314719                              0  10.399821  0.344242
27       104  Linear  0.031207  256   768  3.000000   1.953891        2.425950  0.817814     True   17.442120      dense        2.993978  2.313146           1.241599        blocks.6.qkv          256  205.658164        256            155          0   1  0.076618      17.442120    11.790893  success  4.176376  0.230073   over-trained               0  17.442120  0.214369
28       105  Linear  0.056627  256   256  1.000000   2.019535        1.850439  0.738199     True    8.246500      dense        2.206772  1.759003           0.916270   blocks.6.out_proj          256   57.412015        256             99          0   1  0.102467       8.246500     6.961986  success  2.871672  0.001494                              0   8.246500  0.096052
29       112  Linear  0.053109  256  1024  4.000000   1.910372        2.354531  0.879241     True   17.080423      dense        2.842300  2.357705           1.232499  blocks.6.ffn.net.0          256  227.879382        256            196          0   1  0.065027      17.080423    13.341553  success  4.132847  0.302223   over-trained               0  17.080423  0.213210
30       115  Linear  0.026981  256  1024  4.000000   2.271399        2.387124  0.892506     True   11.244727      dense        2.885898  2.255028           1.050949  blocks.6.ffn.net.3          256  179.898771        256            141          0   1  0.107071      11.244727    15.998500  success  3.353316  0.307788                              0  11.244727  0.336309
31       119  Linear  0.036129  256   768  3.000000   1.928820        2.238306  0.822453     True   14.469494      dense        2.944341  2.319320           1.160453        blocks.7.qkv          256  208.602958        256            160          0   1  0.073430      14.469494    14.416742  success  3.803879  0.228549   over-trained               0  14.469494  0.204200
32       120  Linear  0.047509  256   256  1.000000   2.013601        1.624738  0.736128     True    6.410351      dense        2.233204  1.796506           0.806882   blocks.7.out_proj          256   62.590081        256             92          0   1  0.105675       6.410351     9.763909  success  2.531867  0.001110                              0   6.410351  0.108589
33       127  Linear  0.050766  256  1024  4.000000   1.915040        2.465307  0.874410     True   19.379387      dense        2.894115  2.368825           1.287340  blocks.7.ffn.net.0          256  233.789755        256            190          0   1  0.066384      19.379387    12.063836  success  4.402203  0.305624   over-trained               0  19.379387  0.224076
34       130  Linear  0.032425  256  1024  4.000000   2.270173        2.468581  0.886562     True   12.229196      dense        2.942536  2.266493           1.087398  blocks.7.ffn.net.3          256  184.711239        256            136          0   1  0.108916      12.229196    15.104120  success  3.497027  0.308414                              0  12.229196  0.348223
35       134  Linear  0.036313  256   768  3.000000   1.917628        2.270025  0.822507     True   15.267476      dense        2.957118  2.331326           1.183767        blocks.8.qkv          256  214.449963        256            163          0   1  0.071874      15.267476    14.046196  success  3.907362  0.233165   over-trained               0  15.267476  0.202993
36       135  Linear  0.043200  256   256  1.000000   2.023158        2.008959  0.726888     True    9.839703      dense        2.307606  1.791077           0.992982   blocks.8.out_proj          256   61.812638        256             89          0   1  0.108455       9.839703     6.281962  success  3.136830  0.000480                              1   9.839703  0.111473
37       142  Linear  0.052262  256  1024  4.000000   1.890161        2.534857  0.868655     True   21.932093      dense        2.936403  2.388750           1.341080  blocks.8.ffn.net.0          256  244.765317        256            191          0   1  0.064410      21.932093    11.160144  success  4.683171  0.314700   over-trained               0  21.932093  0.221178
38       145  Linear  0.033781  256  1024  4.000000   2.214570        2.450277  0.875318     True   12.777174      dense        2.992159  2.288685           1.106435  blocks.8.ffn.net.3          256  194.395026        256            144          0   1  0.101214      12.777174    15.214243  success  3.574517  0.310878                              0  12.777174  0.325513
39       149  Linear  0.040638  256   768  3.000000   1.913412        2.214102  0.823109     True   14.359800      dense        2.934134  2.322410           1.157148        blocks.9.qkv          256  210.092294        256            163          0   1  0.071544      14.359800    14.630586  success  3.789433  0.226518   over-trained               0  14.359800  0.197982
40       150  Linear  0.046716  256   256  1.000000   2.033633        1.790605  0.744427     True    7.594436      dense        2.181507  1.759178           0.880496   blocks.9.out_proj          256   57.435185        256             91          0   1  0.108354       7.594436     7.562798  success  2.755800  0.001500                              0   7.594436  0.107220
41       157  Linear  0.050636  256  1024  4.000000   1.886085        2.668778  0.858835     True   26.000568      dense        3.010336  2.403391           1.414983  blocks.9.ffn.net.0          256  253.157886        256            194          0   1  0.063617      26.000568     9.736629  success  5.099075  0.310923   over-trained               0  26.000568  0.217254
42       160  Linear  0.039851  256  1024  4.000000   2.203274        2.528205  0.867621     True   14.043541      dense        3.057294  2.302577           1.147477  blocks.9.ffn.net.3          256  200.713636        256            141          0   1  0.101334      14.043541    14.292238  success  3.747471  0.308815                              0  14.043541  0.332073
43       165  Linear  0.043495  128   256  2.000000   1.835020        1.496450  0.764281     True    6.538756      dense        1.886583  1.622594           0.815495          src_head.0          128   41.936690        128             74          0   1  0.097069       6.538756     6.413558  success  2.557099  0.097862   over-trained               0   6.538756  0.076775
44       167  Linear  0.097928   64   128  2.000000   2.090441       -0.201993  0.842769     True    0.800521      dense        0.343755  0.851993          -0.096627          src_head.2           64    7.112015         64             27          0   1  0.209855       0.800521     8.884228  success  0.894719  0.072566                              0   0.800521  0.068314
45       169  Linear  0.071809  256   256  1.000000   1.630336        1.491485  0.794709     True    8.219262      dense        2.131046  1.963173           0.914833         dest_head.0          256   91.869951        256            139          0   1  0.053464       8.219262    11.177396  success  2.866925  0.000303   over-trained               1   8.219262  0.061419
46       171  Linear  0.064275   73   256  3.506849   2.715356        1.636460  0.879023     True    4.005610      dense        1.859980  1.509856           0.602669         dest_head.2           73   32.348658         73             23          0   1  0.357676       4.005610     8.075839  success  2.001402  0.209356                              0   4.005610  0.466416
47       173  Conv2d  0.030529  256   256  1.000000   2.685301        1.295925  1.028476     True    3.038081     conv2d        2.284388  2.454977           0.482599        value_conv.0         2304  285.087015       2304            128          0   9  0.148961       3.038081    93.837868  success  1.743009  0.002176                              7   3.038081  0.353715
48       177  Linear  0.060589  128   256  2.000000   2.442290        0.825323  0.831177     True    2.177358      dense        1.178259  1.246299           0.337930         value_mlp.0          128   17.631894        128             55          0   1  0.194478       2.177358     8.097837  success  1.475587  0.089974                              0   2.177358  0.087403
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 00:32:40 2025      Time elapsed: 87.87700s
Begin: Training epoch 13                       Current time: Sun Oct 26 00:32:40 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:32:59 2025      Time elapsed: 10872.61623     ETA: 413920.50003s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:33:19 2025      Time elapsed: 10892.14790     ETA: 201885.96147s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:33:38 2025      Time elapsed: 10911.79495     ETA: 131196.14798s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:33:58 2025      Time elapsed: 10931.53917     ETA: 95842.26974s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:34:18 2025      Time elapsed: 10951.38820     ETA: 74622.75925s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:34:38 2025      Time elapsed: 10971.31062     ETA: 60470.20706s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:34:58 2025      Time elapsed: 10991.36475     ETA: 50356.15254s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:35:18 2025      Time elapsed: 11011.56991     ETA: 42766.18466s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:35:38 2025      Time elapsed: 11031.78472     ETA: 36858.41852s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:35:58 2025      Time elapsed: 11051.98747     ETA: 32128.12760s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:36:19 2025      Time elapsed: 11072.27118     ETA: 28254.42293s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:36:39 2025      Time elapsed: 11092.67404     ETA: 25023.22386s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:37:00 2025      Time elapsed: 11113.17425     ETA: 22286.18868s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:37:20 2025      Time elapsed: 11133.61952     ETA: 19937.13153s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:37:40 2025      Time elapsed: 11154.01718     ETA: 17898.47958s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:38:01 2025      Time elapsed: 11174.37723     ETA: 16112.05517s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:38:21 2025      Time elapsed: 11194.79148     ETA: 14533.47341s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:38:42 2025      Time elapsed: 11215.31718     ETA: 13128.15184s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:39:02 2025      Time elapsed: 11235.76360     ETA: 11868.51450s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:39:23 2025      Time elapsed: 11256.20722     ETA: 10732.79359s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:39:43 2025      Time elapsed: 11276.72795     ETA: 9703.35591s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:40:04 2025      Time elapsed: 11297.24914     ETA: 8765.63831s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:40:24 2025      Time elapsed: 11317.65006     ETA: 7907.59289s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:40:45 2025      Time elapsed: 11338.15580     ETA: 7119.41700s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:41:05 2025      Time elapsed: 11358.82566     ETA: 6392.74708s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:41:26 2025      Time elapsed: 11379.36078     ETA: 5720.31713s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:41:46 2025      Time elapsed: 11399.83303     ETA: 5096.14758s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:42:07 2025      Time elapsed: 11420.43618     ETA: 4515.15102s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:42:27 2025      Time elapsed: 11440.99689     ETA: 3972.78754s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:42:48 2025      Time elapsed: 11461.45672     ETA: 3465.18041s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:43:08 2025      Time elapsed: 11481.89659     ETA: 2988.99695s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:43:29 2025      Time elapsed: 11502.34288     ETA: 2541.29888s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:43:49 2025      Time elapsed: 11522.68107     ETA: 2119.47497s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:44:09 2025      Time elapsed: 11543.06712     ETA: 1721.27501s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:44:30 2025      Time elapsed: 11563.55463     ETA: 1344.67621s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:44:50 2025      Time elapsed: 11583.95630     ETA: 987.85405s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:45:11 2025      Time elapsed: 11604.22952     ETA: 649.20960s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:45:31 2025      Time elapsed: 11624.51874     ETA: 327.32197s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:45:51 2025      Time elapsed: 11644.83778     ETA: 20.90099s
Epoch 13: Avg Policy Loss=2.7139, Avg Value Loss=0.4670
  End: Training epoch 13                       Current time: Sun Oct 26 00:45:52 2025      Time elapsed: 792.97970s
Begin: Validating epoch 13                     Current time: Sun Oct 26 00:45:52 2025      
Validation: Policy Loss=2.7119, Value Loss=0.4649, Top-1 Acc=0.2146, Top-5 Acc=0.5316
  End: Validating epoch 13                     Current time: Sun Oct 26 00:46:16 2025      Time elapsed: 23.72755s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_13.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 00:46:16 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.060686   19    32  1.684211   3.515435        0.252795  0.921119     True    1.180076     conv2d        0.644297  1.440598           0.071910     conv_stem.net.0          171   27.580231        171             35          0   9  0.425186       1.180076    23.371567  success  1.086313  0.121900                              0   1.180076  0.262592
1          6  Conv2d  0.109147   32    64  2.000000   5.124048       -1.250779  0.968163     True    0.570033     conv2d       -0.214244  1.697498          -0.244100     conv_stem.net.3          288   49.830790        288             59          0   9  0.536905       0.570033    87.417339  success  0.755005  0.144526                              0   0.570033  0.291535
2          9  Conv2d  0.157224   64   256  4.000000   3.857981        2.944644  0.972819     True    5.797762     conv2d        4.001438  2.271143           0.763260                proj           64  186.699281         64             32          0   1  0.505225       5.797762    32.201954  success  2.407854  0.375102                              0   5.797762  2.827782
3         14  Linear  0.036654  256   768  3.000000   1.862143        2.430514  0.808319     True   20.194069      dense        2.996543  2.355804           1.305224        blocks.0.qkv          256  226.884186        256            175          0   1  0.065172      20.194069    11.235189  success  4.493781  0.229756   over-trained               0  20.194069  0.173461
4         15  Linear  0.040638  256   256  1.000000   2.027003        1.789773  0.751221     True    7.637739      dense        2.139295  1.747895           0.882965   blocks.0.out_proj          256   55.962180        256             90          0   1  0.108256       7.637739     7.327061  success  2.763646  0.000724                              1   7.637739  0.107561
5         22  Linear  0.045542  256  1024  4.000000   1.977810        2.081257  0.887631     True   11.279868      dense        2.738271  2.302175           1.052304  blocks.0.ffn.net.0          256  200.527759        256            185          0   1  0.071890      11.279868    17.777491  success  3.358552  0.301156   over-trained               0  11.279868  0.222613
6         25  Linear  0.025793  256  1024  4.000000   2.402637        2.480677  0.908765     True   10.776585      dense        2.813814  2.200447           1.032481  blocks.0.ffn.net.3          256  158.652649        256            124          0   1  0.125961      10.776585    14.721979  success  3.282771  0.304696                              0  10.776585  0.370111
7         29  Linear  0.039865  256   768  3.000000   1.843563        2.482444  0.809873     True   22.209904      dense        3.005081  2.372377           1.346547        blocks.1.qkv          256  235.709617        256            174          0   1  0.063950      22.209904    10.612816  success  4.712739  0.218060   over-trained               0  22.209904  0.176633
8         30  Linear  0.038016  256   256  1.000000   1.937661        1.678346  0.751266     True    7.348035      dense        2.167108  1.814184           0.866171   blocks.1.out_proj          256   65.190410        256             92          0   1  0.097758       7.348035     8.871815  success  2.710726  0.000867   over-trained               1   7.348035  0.109843
9         37  Linear  0.054180  256  1024  4.000000   1.956019        2.146242  0.886505     True   12.509790      dense        2.749773  2.311747           1.097250  blocks.1.ffn.net.0          256  204.996741        256            183          0   1  0.070671      12.509790    16.386905  success  3.536918  0.301429   over-trained               0  12.509790  0.224189
10        40  Linear  0.027031  256  1024  4.000000   2.380969        2.322406  0.910537     True    9.449386      dense        2.761377  2.203262           0.975404  blocks.1.ffn.net.3          256  159.684381        256            118          0   1  0.127129       9.449386    16.898917  success  3.073985  0.306563                              0   9.449386  0.383724
11        44  Linear  0.040544  256   768  3.000000   1.863210        2.375235  0.811914     True   18.828180      dense        2.979660  2.355681           1.274808        blocks.2.qkv          256  226.819994        256            167          0   1  0.066797      18.828180    12.046836  success  4.339145  0.228140   over-trained               0  18.828180  0.184815
12        45  Linear  0.042693  256   256  1.000000   1.988958        1.859301  0.738913     True    8.606197      dense        2.223381  1.787080           0.934811   blocks.2.out_proj          256   61.246367        256             97          0   1  0.100414       8.606197     7.116542  success  2.933632  0.000700   over-trained               1   8.606197  0.100728
13        52  Linear  0.052646  256  1024  4.000000   1.930516        2.246405  0.882713     True   14.575692      dense        2.789455  2.333808           1.163629  blocks.2.ffn.net.0          256  215.679023        256            191          0   1  0.067330      14.575692    14.797172  success  3.817812  0.298067   over-trained               0  14.575692  0.214540
14        55  Linear  0.028181  256  1024  4.000000   2.329013        2.243565  0.908980     True    9.189917      dense        2.751646  2.223173           0.963312  blocks.2.ffn.net.3          256  167.175753        256            122          0   1  0.120323       9.189917    18.191215  success  3.031487  0.309816                              0   9.189917  0.380592
15        59  Linear  0.037696  256   768  3.000000   1.863916        2.241256  0.815775     True   15.938391      dense        2.950120  2.344619           1.202444        blocks.3.qkv          256  221.115247        256            169          0   1  0.066455      15.938391    13.873122  success  3.992291  0.223296   over-trained               0  15.938391  0.181067
16        60  Linear  0.043798  256   256  1.000000   1.977293        1.761400  0.739249     True    7.777030      dense        2.208773  1.790997           0.890814   blocks.3.out_proj          256   61.801148        256             97          0   1  0.099229       7.777030     7.946625  success  2.788733  0.001712   over-trained               0   7.777030  0.099815
17        67  Linear  0.052864  256  1024  4.000000   1.917285        2.195357  0.882825     True   13.964791      dense        2.776840  2.334604           1.145034  blocks.3.ffn.net.0          256  216.074862        256            193          0   1  0.066028      13.964791    15.472831  success  3.736949  0.299790   over-trained               0  13.964791  0.209033
18        70  Linear  0.028069  256  1024  4.000000   2.322403        2.156133  0.910819     True    8.480202      dense        2.718301  2.221852           0.928406  blocks.3.ffn.net.3          256  166.668102        256            119          0   1  0.121224       8.480202    19.653790  success  2.912079  0.309682                              0   8.480202  0.386885
19        74  Linear  0.038611  256   768  3.000000   1.856818        2.264198  0.814049     True   16.572855      dense        2.971802  2.359628           1.219397        blocks.4.qkv          256  228.890522        256            173          0   1  0.065143      16.572855    13.811170  success  4.070977  0.224057   over-trained               0  16.572855  0.178251
20        75  Linear  0.038035  256   256  1.000000   1.953451        1.625060  0.743106     True    6.790346      dense        2.193960  1.810789           0.831892   blocks.4.out_proj          256   64.682785        256             99          0   1  0.095825       6.790346     9.525698  success  2.605829  0.002232   over-trained               0   6.790346  0.100020
21        82  Linear  0.053929  256  1024  4.000000   1.904310        2.299850  0.880148     True   16.132740      dense        2.812531  2.349617           1.207708  blocks.4.ffn.net.0          256  223.674847        256            192          0   1  0.065263      16.132740    13.864653  success  4.016558  0.310690   over-trained               0  16.132740  0.211972
22        85  Linear  0.027683  256  1024  4.000000   2.308834        2.336121  0.905062     True   10.275868      dense        2.794709  2.234755           1.011819  blocks.4.ffn.net.3          256  171.693823        256            127          0   1  0.116140      10.275868    16.708449  success  3.205600  0.300542                              0  10.275868  0.371217
23        89  Linear  0.033984  256   768  3.000000   1.888125        2.256638  0.814646     True   15.673773      dense        2.964701  2.337807           1.195174        blocks.5.qkv          256  217.673996        256            166          0   1  0.068932      15.673773    13.887786  success  3.959012  0.221899   over-trained               0  15.673773  0.188034
24        90  Linear  0.050719  256   256  1.000000   1.974468        1.688832  0.739277     True    7.166961      dense        2.174371  1.781326           0.855335   blocks.5.out_proj          256   60.440215        256             99          0   1  0.097938       7.166961     8.433172  success  2.677118  0.000847   over-trained               1   7.166961  0.095007
25        97  Linear  0.054730  256  1024  4.000000   1.873087        2.364714  0.874632     True   18.300764      dense        2.855056  2.374036           1.262469  blocks.5.ffn.net.0          256  236.611383        256            201          0   1  0.061583      18.300764    12.929044  success  4.277939  0.311874   over-trained               0  18.300764  0.199327
26       100  Linear  0.027601  256  1024  4.000000   2.227575        2.277823  0.892877     True   10.533130      dense        2.850591  2.264074           1.022557  blocks.5.ffn.net.3          256  183.684990        256            141          0   1  0.103380      10.533130    17.438786  success  3.245478  0.316365                              0  10.533130  0.333920
27       104  Linear  0.033627  256   768  3.000000   1.899630        2.348748  0.816230     True   17.235512      dense        2.964098  2.328057           1.236424        blocks.6.qkv          256  212.841745        256            165          0   1  0.070036      17.235512    12.349024  success  4.151567  0.226197   over-trained               0  17.235512  0.191166
28       105  Linear  0.044858  256   256  1.000000   1.989253        1.831411  0.733941     True    8.330149      dense        2.216922  1.775660           0.920653   blocks.6.out_proj          256   59.656810        256             99          0   1  0.099424       8.330149     7.161554  success  2.886200  0.000499   over-trained               1   8.330149  0.094748
29       112  Linear  0.059610  256  1024  4.000000   1.865045        2.385791  0.872910     True   19.020130      dense        2.869294  2.381291           1.279213  blocks.6.ffn.net.0          256  240.597530        256            198          0   1  0.061476      19.020130    12.649626  success  4.361207  0.298549   over-trained               0  19.020130  0.202890
30       115  Linear  0.029139  256  1024  4.000000   2.214108        2.349295  0.888452     True   11.509520      dense        2.884657  2.272311           1.061057  blocks.6.ffn.net.3          256  187.202070        256            142          0   1  0.101886      11.509520    16.264977  success  3.392568  0.307667                              0  11.509520  0.331661
31       119  Linear  0.037024  256   768  3.000000   1.889449        2.208377  0.819986     True   14.750072      dense        2.937590  2.334707           1.168794        blocks.7.qkv          256  216.125806        256            165          0   1  0.069244      14.750072    14.652526  success  3.840582  0.227560   over-trained               0  14.750072  0.191146
32       120  Linear  0.044409  256   256  1.000000   1.956644        1.601282  0.732735     True    6.582364      dense        2.227526  1.813922           0.818382   blocks.7.out_proj          256   65.151147        256            100          0   1  0.095664       6.582364     9.897834  success  2.565612  0.000679   over-trained               1   6.582364  0.095853
33       127  Linear  0.056428  256  1024  4.000000   1.859122        2.472481  0.868546     True   21.375601      dense        2.906529  2.391457           1.329918  blocks.7.ffn.net.0          256  246.295708        256            200          0   1  0.060749      21.375601    11.522282  success  4.623375  0.299929   over-trained               0  21.375601  0.200714
34       130  Linear  0.025752  256  1024  4.000000   2.199411        2.402607  0.882477     True   12.370473      dense        2.926007  2.283176           1.092386  blocks.7.ffn.net.3          256  191.944717        256            144          0   1  0.099951      12.370473    15.516360  success  3.517168  0.306768                              0  12.370473  0.325834
35       134  Linear  0.034857  256   768  3.000000   1.871127        2.226964  0.821351     True   15.494315      dense        2.938277  2.346142           1.190172        blocks.8.qkv          256  221.892374        256            168          0   1  0.067209      15.494315    14.320889  success  3.936282  0.228134   over-trained               0  15.494315  0.188540
36       135  Linear  0.042104  256   256  1.000000   1.971810        1.961899  0.724636     True    9.884924      dense        2.292137  1.807511           0.994973   blocks.8.out_proj          256   64.196518        256             97          0   1  0.098672       9.884924     6.494387  success  3.144030  0.000599   over-trained               1   9.884924  0.099149
37       142  Linear  0.059143  256  1024  4.000000   1.838236        2.534604  0.862946     True   23.923456      dense        2.948748  2.412856           1.378824  blocks.8.ffn.net.0          256  258.735469        256            200          0   1  0.059272      23.923456    10.815138  success  4.891161  0.308684   over-trained               0  23.923456  0.199729
38       145  Linear  0.029665  256  1024  4.000000   2.157019        2.418624  0.869014     True   13.221501      dense        3.001796  2.309818           1.121281  blocks.8.ffn.net.3          256  204.088340        256            147          0   1  0.095429      13.221501    15.436094  success  3.636138  0.307104                              0  13.221501  0.315475
39       149  Linear  0.036517  256   768  3.000000   1.877179        2.169931  0.822377     True   14.320335      dense        2.921469  2.336287           1.155953        blocks.9.qkv          256  216.913684        256            167          0   1  0.067878      14.320335    15.147249  success  3.784222  0.225290   over-trained               0  14.320335  0.187455
40       150  Linear  0.045442  256   256  1.000000   1.978720        1.766864  0.740344     True    7.815066      dense        2.180280  1.777104           0.892933   blocks.9.out_proj          256   59.855537        256             97          0   1  0.099374       7.815066     7.658993  success  2.795544  0.000349   over-trained               1   7.815066  0.097219
41       157  Linear  0.053466  256  1024  4.000000   1.838915        2.663232  0.853777     True   28.071304      dense        3.018989  2.427314           1.448263  blocks.9.ffn.net.0          256  267.494252        256            203          0   1  0.058880      28.071304     9.529100  success  5.298236  0.308184   over-trained               0  28.071304  0.197682
42       160  Linear  0.038780  256  1024  4.000000   2.143925        2.497736  0.860895     True   14.622762      dense        3.063598  2.323852           1.165029  blocks.9.ffn.net.3          256  210.791135        256            149          0   1  0.093714      14.622762    14.415275  success  3.823972  0.304480                              0  14.622762  0.311241
43       165  Linear  0.048494  128   256  2.000000   1.804810        1.517728  0.760772     True    6.933216      dense        1.935025  1.659326           0.840935          src_head.0          128   45.637958        128             74          0   1  0.093557       6.933216     6.582510  success  2.633100  0.095827   over-trained               0   6.933216  0.078097
44       167  Linear  0.094131   64   128  2.000000   2.071621       -0.175059  0.844151     True    0.823183      dense        0.399233  0.880721          -0.084503          src_head.2           64    7.598383         64             28          0   1  0.202517       0.823183     9.230486  success  0.907295  0.074367                              0   0.823183  0.070060
45       169  Linear  0.077598  256   256  1.000000   1.606844        1.511431  0.792603     True    8.722091      dense        2.162529  1.987553           0.940621         dest_head.0          256   97.174567        256            142          0   1  0.050925       8.722091    11.141201  success  2.953319  0.000746   over-trained               1   8.722091  0.057899
46       171  Linear  0.059422   73   256  3.506849   2.708553        1.736168  0.879705     True    4.375167      dense        1.956543  1.546581           0.640995         dest_head.2           73   35.203138         73             23          0   1  0.356258       4.375167     8.046124  success  2.091690  0.217696                              0   4.375167  0.503947
47       173  Conv2d  0.027215  256   256  1.000000   2.790108        1.449510  1.023875     True    3.307635     conv2d        2.398674  2.462154           0.519518        value_conv.0         2304  289.837299       2304            426          2   9  0.086731       3.307635    87.626752  success  1.818690  0.001630                              5   3.307635  0.195561
48       177  Linear  0.052993  128   256  2.000000   2.393652        0.953498  0.810643     True    2.502329      dense        1.314429  1.275569           0.398344         value_mlp.0          128   18.861169        128             54          0   1  0.189652       2.502329     7.537446  success  1.581875  0.090666                              0   2.502329  0.088156
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 00:47:43 2025      Time elapsed: 87.13472s
Begin: Training epoch 14                       Current time: Sun Oct 26 00:47:43 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:48:03 2025      Time elapsed: 11776.68987     ETA: 448338.58355s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:48:23 2025      Time elapsed: 11796.38923     ETA: 218646.07444s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:48:42 2025      Time elapsed: 11816.12186     ETA: 142069.17190s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:49:02 2025      Time elapsed: 11835.90350     ETA: 103771.28395s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:49:22 2025      Time elapsed: 11855.83408     ETA: 80785.65343s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:49:42 2025      Time elapsed: 11875.93708     ETA: 65456.20655s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:50:02 2025      Time elapsed: 11896.02637     ETA: 54500.79513s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:50:22 2025      Time elapsed: 11916.06099     ETA: 46279.00191s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:50:43 2025      Time elapsed: 11936.13851     ETA: 39879.96501s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:51:03 2025      Time elapsed: 11956.26332     ETA: 34756.85751s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:51:23 2025      Time elapsed: 11976.41489     ETA: 30561.63329s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:51:43 2025      Time elapsed: 11996.54123     ETA: 27062.19760s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:52:03 2025      Time elapsed: 12016.63319     ETA: 24097.97133s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:52:23 2025      Time elapsed: 12036.73656     ETA: 21554.35611s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:52:43 2025      Time elapsed: 12056.96736     ETA: 19347.41363s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:53:04 2025      Time elapsed: 12077.30388     ETA: 17413.96255s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:53:24 2025      Time elapsed: 12097.69927     ETA: 15705.66018s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:53:45 2025      Time elapsed: 12118.15206     ETA: 14184.97023s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:54:05 2025      Time elapsed: 12138.52584     ETA: 12822.11652s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:54:25 2025      Time elapsed: 12158.83807     ETA: 11593.45210s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:54:46 2025      Time elapsed: 12179.20552     ETA: 10479.91638s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:55:06 2025      Time elapsed: 12199.72572     ETA: 9465.87810s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:55:27 2025      Time elapsed: 12220.27580     ETA: 8538.25357s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:55:47 2025      Time elapsed: 12240.81146     ETA: 7686.20953s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:56:08 2025      Time elapsed: 12261.36474     ETA: 6900.69608s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:56:28 2025      Time elapsed: 12281.79511     ETA: 6173.96393s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:56:49 2025      Time elapsed: 12302.13283     ETA: 5499.50901s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:57:09 2025      Time elapsed: 12322.46820     ETA: 4871.77582s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:57:29 2025      Time elapsed: 12342.89586     ETA: 4285.96418s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:57:50 2025      Time elapsed: 12363.23933     ETA: 3737.81936s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:58:10 2025      Time elapsed: 12383.55137     ETA: 3223.71805s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:58:30 2025      Time elapsed: 12404.03799     ETA: 2740.51714s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:58:51 2025      Time elapsed: 12424.64052     ETA: 2285.38085s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:59:11 2025      Time elapsed: 12445.07773     ETA: 1855.78071s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:59:32 2025      Time elapsed: 12465.42312     ETA: 1449.55063s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 00:59:52 2025      Time elapsed: 12485.88271     ETA: 1064.76833s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:00:13 2025      Time elapsed: 12506.34888     ETA: 699.67952s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:00:33 2025      Time elapsed: 12526.70218     ETA: 352.72556s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:00:53 2025      Time elapsed: 12547.06561     ETA: 22.52037s
Epoch 14: Avg Policy Loss=2.6944, Avg Value Loss=0.4600
  End: Training epoch 14                       Current time: Sun Oct 26 01:00:55 2025      Time elapsed: 791.31454s
Begin: Validating epoch 14                     Current time: Sun Oct 26 01:00:55 2025      
Validation: Policy Loss=2.6931, Value Loss=0.4582, Top-1 Acc=0.2188, Top-5 Acc=0.5388
  End: Validating epoch 14                     Current time: Sun Oct 26 01:01:19 2025      Time elapsed: 23.85106s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_14.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 01:01:19 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.061325   19    32  1.684211   3.454868        0.229729  0.919991     True    1.165452     conv2d        0.633252  1.430562           0.066494     conv_stem.net.0          171   26.950215        171             35          0   9  0.414948       1.165452    23.124262  success  1.079561  0.123543                              0   1.165452  0.254803
1          6  Conv2d  0.108930   32    64  2.000000   4.987653       -1.266792  0.968038     True    0.557204     conv2d       -0.215052  1.686518          -0.253986     conv_stem.net.3          288   48.586767        288             59          0   9  0.519148       0.557204    87.197418  success  0.746461  0.144948                              0   0.557204  0.282209
2          9  Conv2d  0.157534   64   256  4.000000   3.858994        2.888163  0.972912     True    5.603041     conv2d        3.941798  2.256024           0.748424                proj           64  180.311561         64             32          0   1  0.505404       5.603041    32.181019  success  2.367074  0.354446                              0   5.603041  2.728333
3         14  Linear  0.038261  256   768  3.000000   1.831607        2.384009  0.807152     True   20.025999      dense        2.982820  2.367050           1.301594        blocks.0.qkv          256  232.836103        256            179          0   1  0.062157      20.025999    11.626691  success  4.475042  0.225441   over-trained               0  20.025999  0.162900
4         15  Linear  0.036270  256   256  1.000000   1.993585        1.756592  0.750911     True    7.605397      dense        2.130313  1.760151           0.881122   blocks.0.out_proj          256   57.563971        256             90          0   1  0.104733       7.605397     7.568832  success  2.757788  0.000132   over-trained               1   7.605397  0.106625
5         22  Linear  0.050059  256  1024  4.000000   1.928431        2.104327  0.881761     True   12.337075      dense        2.753968  2.318295           1.091212  blocks.0.ffn.net.0          256  208.110809        256            192          0   1  0.067004      12.337075    16.868731  success  3.512417  0.297545   over-trained               0  12.337075  0.204384
6         25  Linear  0.023973  256  1024  4.000000   2.360586        2.432995  0.906687     True   10.731837      dense        2.801813  2.210824           1.030674  blocks.0.ffn.net.3          256  162.489006        256            121          0   1  0.123690      10.731837    15.140838  success  3.275948  0.304908                              0  10.731837  0.377356
7         29  Linear  0.041636  256   768  3.000000   1.816179        2.431203  0.809152     True   21.809048      dense        2.990064  2.382243           1.338637        blocks.1.qkv          256  241.125219        256            176          0   1  0.061522      21.809048    11.056201  success  4.670016  0.215003   over-trained               0  21.809048  0.168331
8         30  Linear  0.032446  256   256  1.000000   1.901458        1.641450  0.751291     True    7.298920      dense        2.159524  1.826623           0.863259   blocks.1.out_proj          256   67.084617        256            102          1   1  0.089258       7.298920     9.191033  success  2.701651  0.000017   over-trained               1   7.298920  0.096240
9         37  Linear  0.053833  256  1024  4.000000   1.909758        2.178131  0.880715     True   13.820609      dense        2.767895  2.328579           1.140527  blocks.1.ffn.net.0          256  213.097805        256            197          0   1  0.064818      13.820609    15.418843  success  3.717608  0.296027   over-trained               0  13.820609  0.198188
10        40  Linear  0.025873  256  1024  4.000000   2.327109        2.253943  0.908839     True    9.301641      dense        2.742723  2.214699           0.968560  blocks.1.ffn.net.3          256  163.945312        256            121          0   1  0.120646       9.301641    17.625419  success  3.049859  0.305611                              0   9.301641  0.376213
11        44  Linear  0.041365  256   768  3.000000   1.836187        2.330475  0.810697     True   18.586283      dense        2.969748  2.366387           1.269193        blocks.2.qkv          256  232.480915        256            171          0   1  0.063945      18.586283    12.508199  success  4.311181  0.224013   over-trained               0  18.586283  0.174481
12        45  Linear  0.039105  256   256  1.000000   1.963869        1.821581  0.738649     True    8.463452      dense        2.217275  1.799068           0.927548   blocks.2.out_proj          256   62.960515        256             92          1   1  0.100490       8.463452     7.439106  success  2.909201  0.000024   over-trained               1   8.463452  0.105863
13        52  Linear  0.057691  256  1024  4.000000   1.888463        2.271383  0.876947     True   15.950261      dense        2.810859  2.352453           1.202768  blocks.2.ffn.net.0          256  225.140243        256            197          0   1  0.063300      15.950261    14.115145  success  3.993778  0.293935   over-trained               0  15.950261  0.199401
14        55  Linear  0.028749  256  1024  4.000000   2.281999        2.184815  0.907319     True    9.065940      dense        2.741407  2.235227           0.957413  blocks.2.ffn.net.3          256  171.880580        256            121          0   1  0.116545       9.065940    18.958937  success  3.010970  0.307194                              0   9.065940  0.383693
15        59  Linear  0.040397  256   768  3.000000   1.837647        2.203443  0.814457     True   15.814548      dense        2.941867  2.355003           1.199057        blocks.3.qkv          256  226.466041        256            171          0   1  0.064056      15.814548    14.320109  success  3.976751  0.220827   over-trained               0  15.814548  0.173364
16        60  Linear  0.036862  256   256  1.000000   1.956180        1.740725  0.738756     True    7.759955      dense        2.207968  1.802825           0.889859   blocks.3.out_proj          256   63.507465        256             93          0   1  0.099151       7.759955     8.183999  success  2.785670  0.000891   over-trained               1   7.759955  0.104022
17        67  Linear  0.055555  256  1024  4.000000   1.877122        2.230268  0.877034     True   15.421679      dense        2.800904  2.353570           1.188132  blocks.3.ffn.net.0          256  225.719864        256            198          0   1  0.062334      15.421679    14.636529  success  3.927045  0.295694   over-trained               0  15.421679  0.195683
18        70  Linear  0.029076  256  1024  4.000000   2.254388        2.084794  0.908764     True    8.409523      dense        2.702108  2.234242           0.924771  blocks.3.ffn.net.3          256  171.491131        256            132          0   1  0.109180       8.409523    20.392492  success  2.899918  0.310046                              0   8.409523  0.351987
19        74  Linear  0.039731  256   768  3.000000   1.828283        2.227461  0.813178     True   16.532364      dense        2.960315  2.370097           1.218335        blocks.4.qkv          256  234.475369        256            175          0   1  0.062612      16.532364    14.182810  success  4.066001  0.221456   over-trained               0  16.532364  0.170407
20        75  Linear  0.032414  256   256  1.000000   1.927828        1.616774  0.742396     True    6.896840      dense        2.194693  1.822397           0.838650   blocks.4.out_proj          256   66.435050        256             99          0   1  0.093250       6.896840     9.632680  success  2.626184  0.001530   over-trained               0   6.896840  0.099043
21        82  Linear  0.058866  256  1024  4.000000   1.860705        2.318089  0.874519     True   17.612156      dense        2.832216  2.369340           1.245813  blocks.4.ffn.net.0          256  234.066812        256            202          0   1  0.060559      17.612156    13.290072  success  4.196684  0.305821   over-trained               0  17.612156  0.191760
22        85  Linear  0.027789  256  1024  4.000000   2.251310        2.281687  0.902554     True   10.315560      dense        2.784151  2.248539           1.013493  blocks.4.ffn.net.3          256  177.230906        256            132          0   1  0.108913      10.315560    17.180929  success  3.211785  0.295543                              0  10.315560  0.357859
23        89  Linear  0.035356  256   768  3.000000   1.861976        2.232180  0.814095     True   15.806053      dense        2.954316  2.348133           1.198823        blocks.5.qkv          256  222.911758        256            166          0   1  0.066902      15.806053    14.102936  success  3.975683  0.218948   over-trained               0  15.806053  0.183818
24        90  Linear  0.044407  256   256  1.000000   1.952238        1.666494  0.738182     True    7.138924      dense        2.175430  1.791510           0.853633   blocks.5.out_proj          256   61.874273        256             96          0   1  0.097187       7.138924     8.667171  success  2.671876  0.002255   over-trained               0   7.138924  0.097253
25        97  Linear  0.059981  256  1024  4.000000   1.833812        2.374435  0.869699     True   19.715536      dense        2.870351  2.392575           1.294809  blocks.5.ffn.net.0          256  246.930559        256            205          0   1  0.058236      19.715536    12.524669  success  4.440218  0.310132   over-trained               0  19.715536  0.186861
26       100  Linear  0.026930  256  1024  4.000000   2.183840        2.233767  0.890333     True   10.540513      dense        2.848097  2.278050           1.022862  blocks.5.ffn.net.3          256  189.692570        256            137          0   1  0.101142      10.540513    17.996522  success  3.246616  0.314138                              0  10.540513  0.340778
27       104  Linear  0.037280  256   768  3.000000   1.863770        2.303417  0.814978     True   17.214369      dense        2.948372  2.339953           1.235891        blocks.6.qkv          256  218.752440        256            168          0   1  0.066641      17.214369    12.707549  success  4.149020  0.222348   over-trained               0  17.214369  0.180866
28       105  Linear  0.041468  256   256  1.000000   1.974802        1.833048  0.731938     True    8.476543      dense        2.224560  1.786658           0.928219   blocks.6.out_proj          256   61.186865        256             98          0   1  0.098470       8.476543     7.218375  success  2.911450  0.000539   over-trained               1   8.476543  0.095454
29       112  Linear  0.061462  256  1024  4.000000   1.824076        2.390573  0.868487     True   20.444029      dense        2.880772  2.399823           1.310566  blocks.6.ffn.net.0          256  251.086528        256            207          0   1  0.057277      20.444029    12.281656  success  4.521507  0.295653   over-trained               0  20.444029  0.184246
30       115  Linear  0.029351  256  1024  4.000000   2.176975        2.326123  0.885530     True   11.708776      dense        2.887998  2.286049           1.068512  blocks.6.ffn.net.3          256  193.218651        256            138          0   1  0.100191      11.708776    16.502036  success  3.421809  0.307115                              0  11.708776  0.339228
31       119  Linear  0.037629  256   768  3.000000   1.859252        2.179332  0.818372     True   14.864673      dense        2.931096  2.346211           1.172155        blocks.7.qkv          256  221.927194        256            171          0   1  0.065709      14.864673    14.929841  success  3.855473  0.225421   over-trained               0  14.864673  0.178324
32       120  Linear  0.044732  256   256  1.000000   1.936500        1.599141  0.730236     True    6.695601      dense        2.238501  1.827354           0.825790   blocks.7.out_proj          256   67.197664        256             95          0   1  0.096083       6.695601    10.036091  success  2.587586  0.000166   over-trained               1   6.695601  0.100613
33       127  Linear  0.060663  256  1024  4.000000   1.831059        2.493118  0.864133     True   22.991747      dense        2.926575  2.409377           1.361572  blocks.7.ffn.net.0          256  256.671318        256            203          0   1  0.058329      22.991747    11.163628  success  4.794971  0.298234   over-trained               0  22.991747  0.192238
34       130  Linear  0.026041  256  1024  4.000000   2.157019        2.371387  0.879187     True   12.571346      dense        2.925305  2.296951           1.099382  blocks.7.ffn.net.3          256  198.130360        256            146          0   1  0.095756      12.571346    15.760473  success  3.545609  0.306431                              0  12.571346  0.319113
35       134  Linear  0.037590  256   768  3.000000   1.837140        2.192449  0.820414     True   15.610029      dense        2.925451  2.357396           1.193404        blocks.8.qkv          256  227.717236        256            175          0   1  0.063282      15.610029    14.587880  success  3.950953  0.226445   over-trained               0  15.610029  0.173614
36       135  Linear  0.035476  256   256  1.000000   1.942554        1.934172  0.722775     True    9.901134      dense        2.288892  1.820368           0.995685   blocks.8.out_proj          256   66.125385        256             98          0   1  0.095212       9.901134     6.678567  success  3.146607  0.000704   over-trained               1   9.901134  0.096423
37       142  Linear  0.061149  256  1024  4.000000   1.811784        2.555119  0.858622     True   25.720396      dense        2.968325  2.430673           1.410278  blocks.8.ffn.net.0          256  269.570921        256            202          0   1  0.057117      25.720396    10.480823  success  5.071528  0.308709   over-trained               0  25.720396  0.192568
38       145  Linear  0.029665  256  1024  4.000000   2.118324        2.402150  0.864937     True   13.614017      dense        3.007766  2.324852           1.133986  blocks.8.ffn.net.3          256  211.277121        256            145          0   1  0.092872      13.614017    15.519087  success  3.689718  0.306214                              0  13.614017  0.316238
39       149  Linear  0.036099  256   768  3.000000   1.847599        2.144170  0.821205     True   14.471614      dense        2.915385  2.348712           1.160517        blocks.9.qkv          256  223.209394        256            175          0   1  0.064072      14.471614    15.423946  success  3.804157  0.224575   over-trained               0  14.471614  0.172873
40       150  Linear  0.047766  256   256  1.000000   1.932892        1.738302  0.736362     True    7.930981      dense        2.183371  1.794026           0.899327   blocks.9.out_proj          256   62.233814        256            106          0   1  0.090610       7.930981     7.846925  success  2.816200  0.000299   over-trained               1   7.930981  0.085689
41       157  Linear  0.057066  256  1024  4.000000   1.801857        2.655754  0.850148     True   29.778185      dense        3.022653  2.445402           1.473898  blocks.9.ffn.net.0          256  278.870294        256            210          0   1  0.055333      29.778185     9.364919  success  5.456939  0.303789   over-trained               0  29.778185  0.182211
42       160  Linear  0.036202  256  1024  4.000000   2.105381        2.474247  0.855974     True   14.969294      dense        3.071424  2.340518           1.175201  blocks.9.ffn.net.3          256  219.037152        256            148          0   1  0.090862      14.969294    14.632431  success  3.869017  0.304357                              0  14.969294  0.309904
43       165  Linear  0.053409  128   256  2.000000   1.770345        1.522546  0.758999     True    7.244832      dense        1.967305  1.690106           0.860028          src_head.0          128   48.989862        128             74          0   1  0.089551       7.244832     6.762043  success  2.691622  0.094542   over-trained               0   7.244832  0.078045
44       167  Linear  0.096796   64   128  2.000000   2.081758       -0.151426  0.845778     True    0.845786      dense        0.440015  0.905788          -0.072740          src_head.2           64    8.049858         64             28          0   1  0.204433       0.845786     9.517606  success  0.919666  0.077557                              0   0.845786  0.075359
45       169  Linear  0.078156  256   256  1.000000   1.586427        1.521815  0.791380     True    9.104839      dense        2.184422  2.006385           0.959272         dest_head.0          256  101.481053        256            145          0   1  0.048700       9.104839    11.145837  success  3.017423  0.000332   over-trained               1   9.104839  0.054357
46       171  Linear  0.065249   73   256  3.506849   2.755030        1.844536  0.880913     True    4.672137      dense        2.054981  1.575699           0.669516         dest_head.2           73   37.644256         73             21          0   1  0.382979       4.672137     8.057182  success  2.161513  0.227704                              0   4.672137  0.575777
47       173  Conv2d  0.021808  256   256  1.000000   2.715300        1.476386  1.020452     True    3.497265     conv2d        2.431652  2.467282           0.543728        value_conv.0         2304  293.279993       2304            426          1   9  0.083107       3.497265    83.859823  success  1.870098  0.001592                              9   3.497265  0.193497
48       177  Linear  0.053858  128   256  2.000000   2.247670        1.011808  0.793654     True    2.819414      dense        1.385404  1.299898           0.450159         value_mlp.0          128   19.947945        128             60          0   1  0.161073       2.819414     7.075209  success  1.679111  0.091005                              0   2.819414  0.075498
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 01:02:46 2025      Time elapsed: 87.21712s
Begin: Training epoch 15                       Current time: Sun Oct 26 01:02:46 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:03:05 2025      Time elapsed: 12679.10249     ETA: 482693.43187s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:03:25 2025      Time elapsed: 12698.75695     ETA: 235371.46024s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:03:45 2025      Time elapsed: 12718.56468     ETA: 152919.54275s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:04:05 2025      Time elapsed: 12738.50033     ETA: 111684.80174s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:04:25 2025      Time elapsed: 12758.48882     ETA: 86936.34289s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:04:45 2025      Time elapsed: 12778.49856     ETA: 70430.82457s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:05:05 2025      Time elapsed: 12798.59250     ETA: 58635.83740s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:05:25 2025      Time elapsed: 12818.78765     ETA: 49784.96655s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:05:45 2025      Time elapsed: 12838.94076     ETA: 42896.32766s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:06:06 2025      Time elapsed: 12859.15369     ETA: 37381.55980s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:06:26 2025      Time elapsed: 12879.43567     ETA: 32865.97813s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:06:46 2025      Time elapsed: 12899.74048     ETA: 29099.66459s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:07:06 2025      Time elapsed: 12920.01536     ETA: 25909.60004s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:07:27 2025      Time elapsed: 12940.20912     ETA: 23172.21735s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:07:47 2025      Time elapsed: 12960.38596     ETA: 20797.09934s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:08:07 2025      Time elapsed: 12980.66151     ETA: 18716.49132s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:08:27 2025      Time elapsed: 13000.96389     ETA: 16878.31018s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:08:48 2025      Time elapsed: 13021.27003     ETA: 15242.11998s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:09:08 2025      Time elapsed: 13041.57578     ETA: 13776.02244s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:09:28 2025      Time elapsed: 13061.88273     ETA: 12454.50519s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:09:49 2025      Time elapsed: 13082.20097     ETA: 11256.92246s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:10:09 2025      Time elapsed: 13102.51358     ETA: 10166.35941s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:10:29 2025      Time elapsed: 13122.90149     ETA: 9168.91422s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:10:50 2025      Time elapsed: 13143.42841     ETA: 8252.97776s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:11:10 2025      Time elapsed: 13163.94843     ETA: 7408.67018s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:11:31 2025      Time elapsed: 13184.50324     ETA: 6627.74836s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:11:51 2025      Time elapsed: 13204.94675     ETA: 5903.10027s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:12:12 2025      Time elapsed: 13225.26899     ETA: 5228.70456s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:12:32 2025      Time elapsed: 13245.53444     ETA: 4599.39765s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:12:52 2025      Time elapsed: 13265.77425     ETA: 4010.68575s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:13:12 2025      Time elapsed: 13286.00666     ETA: 3458.64754s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:13:33 2025      Time elapsed: 13306.39972     ETA: 2939.88269s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:13:53 2025      Time elapsed: 13326.94493     ETA: 2451.35017s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:14:14 2025      Time elapsed: 13347.35528     ETA: 1990.32621s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:14:34 2025      Time elapsed: 13367.74600     ETA: 1554.47789s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:14:55 2025      Time elapsed: 13388.25922     ETA: 1141.72099s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:15:15 2025      Time elapsed: 13408.78563     ETA: 750.16720s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:15:36 2025      Time elapsed: 13429.21956     ETA: 378.13855s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:15:56 2025      Time elapsed: 13449.61034     ETA: 24.14033s
Epoch 15: Avg Policy Loss=2.6762, Avg Value Loss=0.4523
  End: Training epoch 15                       Current time: Sun Oct 26 01:15:57 2025      Time elapsed: 791.40687s
Begin: Validating epoch 15                     Current time: Sun Oct 26 01:15:57 2025      
Validation: Policy Loss=2.6767, Value Loss=0.4515, Top-1 Acc=0.2230, Top-5 Acc=0.5442
  End: Validating epoch 15                     Current time: Sun Oct 26 01:16:21 2025      Time elapsed: 23.72060s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_15.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 01:16:21 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.059379   19    32  1.684211   3.359937        0.203945  0.919143     True    1.150004     conv2d        0.627066  1.421844           0.060699     conv_stem.net.0          171   26.414610        171             36          0   9  0.393323       1.150004    22.969155  success  1.072382  0.123114                              0   1.150004  0.243216
1          6  Conv2d  0.111773   32    64  2.000000   4.917739       -1.296868  0.967951     True    0.544864     conv2d       -0.232660  1.677189          -0.263712     conv_stem.net.3          288   47.554209        288             59          0   9  0.510046       0.544864    87.277266  success  0.738149  0.143762                              0   0.544864  0.275148
2          9  Conv2d  0.157885   64   256  4.000000   3.861576        2.842262  0.972984     True    5.445489     conv2d        3.892973  2.243345           0.736037                proj           64  175.123872         64             32          0   1  0.505860       5.445489    32.159440  success  2.333557  0.339433                              0   5.445489  2.648688
3         14  Linear  0.039817  256   768  3.000000   1.809969        2.351391  0.806369     True   19.912851      dense        2.973331  2.375192           1.299133        blocks.0.qkv          256  237.242253        256            183          0   1  0.059875      19.912851    11.914027  success  4.462382  0.222484   over-trained               0  19.912851  0.154122
4         15  Linear  0.036813  256   256  1.000000   1.975433        1.750307  0.750196     True    7.691967      dense        2.132921  1.769957           0.886037   blocks.0.out_proj          256   58.878476        256             89          0   1  0.103396       7.691967     7.654540  success  2.773440  0.000090   over-trained               1   7.691967  0.107917
5         22  Linear  0.053395  256  1024  4.000000   1.904118        2.128151  0.877707     True   13.111643      dense        2.769137  2.329463           1.117657  blocks.0.ffn.net.0          256  213.532011        256            194          0   1  0.064912      13.111643    16.285679  success  3.621000  0.294087   over-trained               0  13.111643  0.197068
6         25  Linear  0.025247  256  1024  4.000000   2.328107        2.400902  0.905587     True   10.746516      dense        2.789759  2.217536           1.031268  blocks.0.ffn.net.3          256  165.019622        256            116          0   1  0.123312      10.746516    15.355639  success  3.278188  0.303930                              0  10.746516  0.389295
7         29  Linear  0.042563  256   768  3.000000   1.793414        2.393210  0.808468     True   21.599483      dense        2.977500  2.389419           1.334443        blocks.1.qkv          256  245.142974        256            184          0   1  0.058491      21.599483    11.349483  success  4.647524  0.213952   over-trained               0  21.599483  0.154094
8         30  Linear  0.036534  256   256  1.000000   1.870672        1.616733  0.751752     True    7.315640      dense        2.150425  1.835082           0.864252   blocks.1.out_proj          256   68.404156        256            103          0   1  0.085790       7.315640     9.350399  success  2.704744  0.000605   over-trained               1   7.315640  0.093068
9         37  Linear  0.055400  256  1024  4.000000   1.882079        2.194854  0.876560     True   14.661737      dense        2.782708  2.341420           1.166185  blocks.1.ffn.net.0          256  219.492443        256            198          0   1  0.062687      14.661737    14.970425  success  3.829065  0.290581   over-trained               0  14.661737  0.191453
10        40  Linear  0.026975  256  1024  4.000000   2.289631        2.210026  0.907445     True    9.230655      dense        2.733107  2.223008           0.965233  blocks.1.ffn.net.3          256  167.112237        256            121          0   1  0.117239       9.230655    18.104050  success  3.038199  0.304532                              0   9.230655  0.375587
11        44  Linear  0.042942  256   768  3.000000   1.812802        2.285922  0.810467     True   18.238470      dense        2.955004  2.372752           1.260988        blocks.2.qkv          256  235.913037        256            174          0   1  0.061618      18.238470    12.934914  success  4.270652  0.220786   over-trained               0  18.238470  0.165727
12        45  Linear  0.039915  256   256  1.000000   1.944718        1.793028  0.739525     True    8.356003      dense        2.207537  1.806372           0.921999   blocks.2.out_proj          256   64.028355        256             93          0   1  0.097963       8.356003     7.662558  success  2.890675  0.000542   over-trained               1   8.356003  0.104287
13        52  Linear  0.061253  256  1024  4.000000   1.851474        2.275281  0.872868     True   16.939585      dense        2.819029  2.365957           1.228903  blocks.2.ffn.net.0          256  232.250784        256            204          0   1  0.059615      16.939585    13.710536  success  4.115773  0.292926   over-trained               0  16.939585  0.183629
14        55  Linear  0.030486  256  1024  4.000000   2.232467        2.130553  0.906044     True    9.002216      dense        2.725834  2.244213           0.954349  blocks.2.ffn.net.3          256  175.473904        256            133          0   1  0.106868       9.002216    19.492300  success  3.000369  0.305062                              0   9.002216  0.352052
15        59  Linear  0.041900  256   768  3.000000   1.814181        2.171990  0.813730     True   15.748127      dense        2.930220  2.361994           1.197229        blocks.3.qkv          256  230.141117        256            176          0   1  0.061371      15.748127    14.613872  success  3.968391  0.219570   over-trained               0  15.748127  0.162248
16        60  Linear  0.036010  256   256  1.000000   1.927414        1.701010  0.739214     True    7.630181      dense        2.194617  1.810077           0.882535   blocks.3.out_proj          256   64.576815        256             99          0   1  0.093209       7.630181     8.463340  success  2.762278  0.000658   over-trained               1   7.630181  0.095531
17        67  Linear  0.059037  256  1024  4.000000   1.843918        2.250111  0.872858     True   16.606867      dense        2.813170  2.366906           1.220288  blocks.3.ffn.net.0          256  232.758605        256            202          0   1  0.059378      16.606867    14.015805  success  4.075152  0.293803   over-trained               0  16.606867  0.184058
18        70  Linear  0.031793  256  1024  4.000000   2.220708        2.033536  0.907751     True    8.235970      dense        2.694678  2.242420           0.915715  blocks.3.ffn.net.3          256  174.751055        256            130          0   1  0.107063       8.235970    21.218028  success  2.869838  0.308428                              0   8.235970  0.355331
19        74  Linear  0.040800  256   768  3.000000   1.808070        2.199724  0.812805     True   16.467009      dense        2.950171  2.376828           1.216615        blocks.4.qkv          256  238.137435        256            178          0   1  0.060567      16.467009    14.461487  success  4.057956  0.218769   over-trained               0  16.467009  0.162639
20        75  Linear  0.031685  256   256  1.000000   1.903320        1.597321  0.742715     True    6.906043      dense        2.188104  1.829886           0.839229   blocks.4.out_proj          256   67.590607        256             97          0   1  0.091718       6.906043     9.787168  success  2.627935  0.000327   over-trained               1   6.906043  0.099888
21        82  Linear  0.062101  256  1024  4.000000   1.833334        2.329245  0.870624     True   18.642195      dense        2.845838  2.383049           1.270497  blocks.4.ffn.net.0          256  241.573164        256            203          0   1  0.058489      18.642195    12.958408  success  4.317661  0.300685   over-trained               0  18.642195  0.184967
22        85  Linear  0.029666  256  1024  4.000000   2.223003        2.249161  0.901108     True   10.274654      dense        2.781435  2.257567           1.011767  blocks.4.ffn.net.3          256  180.953628        256            130          0   1  0.107264      10.274654    17.611651  success  3.205410  0.294913                              0  10.274654  0.362934
23        89  Linear  0.037766  256   768  3.000000   1.835686        2.201776  0.813296     True   15.828137      dense        2.943491  2.357025           1.199430        blocks.5.qkv          256  227.522957        256            174          0   1  0.063353      15.828137    14.374588  success  3.978459  0.218263   over-trained               0  15.828137  0.168991
24        90  Linear  0.039508  256   256  1.000000   1.944609        1.659848  0.736774     True    7.137792      dense        2.187027  1.801546           0.853564   blocks.5.out_proj          256   63.320757        256             94          0   1  0.097429       7.137792     8.871197  success  2.671665  0.000932   over-trained               1   7.137792  0.100112
25        97  Linear  0.060910  256  1024  4.000000   1.813601        2.399280  0.865853     True   21.034742      dense        2.888430  2.405810           1.322937  blocks.5.ffn.net.0          256  254.571416        256            209          0   1  0.056278      21.034742    12.102426  success  4.586365  0.305815   over-trained               0  21.034742  0.178420
26       100  Linear  0.024937  256  1024  4.000000   2.145081        2.192926  0.888956     True   10.526990      dense        2.837660  2.287149           1.022304  blocks.5.ffn.net.3          256  193.708788        256            144          0   1  0.095423      10.526990    18.401156  success  3.244532  0.312018                              0  10.526990  0.322957
27       104  Linear  0.036629  256   768  3.000000   1.846886        2.284168  0.814441     True   17.249144      dense        2.942936  2.347362           1.236768        blocks.6.qkv          256  222.516180        256            172          0   1  0.064574      17.249144    12.900129  success  4.153209  0.220934   over-trained               0  17.249144  0.173089
28       105  Linear  0.037638  256   256  1.000000   1.947586        1.813653  0.731309     True    8.535548      dense        2.214391  1.793826           0.931231   blocks.6.out_proj          256   62.205061        256             98          0   1  0.095721       8.535548     7.287764  success  2.921566  0.000568   over-trained               1   8.535548  0.093524
29       112  Linear  0.063202  256  1024  4.000000   1.797717        2.394232  0.865269     True   21.469324      dense        2.889496  2.412524           1.331818  blocks.6.ffn.net.0          256  258.537649        256            211          0   1  0.054917      21.469324    12.042189  success  4.633500  0.293549   over-trained               0  21.469324  0.174216
30       115  Linear  0.028721  256  1024  4.000000   2.141271        2.282062  0.883900     True   11.634598      dense        2.878576  2.295374           1.065751  blocks.6.ffn.net.3          256  197.412222        256            142          0   1  0.095773      11.634598    16.967688  success  3.410953  0.305969                              0  11.634598  0.327905
31       119  Linear  0.038801  256   768  3.000000   1.833831        2.157360  0.817620     True   15.011444      dense        2.920071  2.353431           1.176422        blocks.7.qkv          256  225.647825        256            174          0   1  0.063213      15.011444    15.031720  success  3.874460  0.223526   over-trained               0  15.011444  0.169674
32       120  Linear  0.044978  256   256  1.000000   1.910585        1.591855  0.728825     True    6.810467      dense        2.237680  1.836305           0.833177   blocks.7.out_proj          256   68.596930        256             95          0   1  0.093424       6.810467    10.072280  success  2.609687  0.001360   over-trained               0   6.810467  0.098825
33       127  Linear  0.062327  256  1024  4.000000   1.806326        2.493090  0.861377     True   23.999338      dense        2.933484  2.422004           1.380199  blocks.7.ffn.net.0          256  264.243276        256            208          0   1  0.055909      23.999338    11.010440  success  4.898912  0.295534   over-trained               0  23.999338  0.181501
34       130  Linear  0.027266  256  1024  4.000000   2.123310        2.344003  0.876949     True   12.703938      dense        2.921522  2.307031           1.103938  blocks.7.ffn.net.3          256  202.782827        256            148          0   1  0.092335      12.703938    15.962203  success  3.564258  0.303148                              0  12.703938  0.312175
35       134  Linear  0.039902  256   768  3.000000   1.822152        2.182873  0.820009     True   15.774806      dense        2.922527  2.364542           1.197964        blocks.8.qkv          256  231.495174        256            176          0   1  0.061972      15.774806    14.674993  success  3.971751  0.223341   over-trained               0  15.774806  0.169989
36       135  Linear  0.033389  256   256  1.000000   1.922141        1.896776  0.722417     True    9.700707      dense        2.281954  1.829823           0.986803   blocks.8.out_proj          256   67.580810        256             98          1   1  0.093150       9.700707     6.966586  success  3.114596  0.000021   over-trained               2   9.700707  0.095399
37       142  Linear  0.060380  256  1024  4.000000   1.788027        2.558239  0.855795     True   26.962523      dense        2.975230  2.442958           1.430761  blocks.8.ffn.net.0          256  277.305025        256            209          0   1  0.054509      26.962523    10.284832  success  5.192545  0.309891   over-trained               0  26.962523  0.179421
38       145  Linear  0.031051  256  1024  4.000000   2.097771        2.388078  0.862165     True   13.752719      dense        3.015821  2.335663           1.138389  blocks.8.ffn.net.3          256  216.602199        256            144          0   1  0.091481      13.752719    15.749773  success  3.708466  0.307479                              0  13.752719  0.317813
39       149  Linear  0.038716  256   768  3.000000   1.830252        2.128798  0.820817     True   14.558524      dense        2.911021  2.356047           1.163117        blocks.9.qkv          256  227.011171        256            173          0   1  0.063123      14.558524    15.593007  success  3.815563  0.224569   over-trained               0  14.558524  0.172399
40       150  Linear  0.041277  256   256  1.000000   1.922104        1.723253  0.735220     True    7.880346      dense        2.189601  1.803706           0.896545   blocks.9.out_proj          256   63.636509        256            106          0   1  0.089563       7.880346     8.075344  success  2.807195  0.000459   over-trained               1   7.880346  0.085571
41       157  Linear  0.058052  256  1024  4.000000   1.783644        2.664101  0.847568     True   31.162188      dense        3.032533  2.457787           1.493628  blocks.9.ffn.net.0          256  286.937417        256            212          0   1  0.053821      31.162188     9.207871  success  5.582310  0.300273   over-trained               0  31.162188  0.176557
42       160  Linear  0.034203  256  1024  4.000000   2.086733        2.472393  0.852339     True   15.304352      dense        3.084301  2.351773           1.184815  blocks.9.ffn.net.3          256  224.787855        256            148          0   1  0.089329      15.304352    14.687839  success  3.912078  0.302801                              0  15.304352  0.308981
43       165  Linear  0.053847  128   256  2.000000   1.728083        1.505170  0.758270     True    7.430290      dense        1.981924  1.713974           0.871006          src_head.0          128   51.757552        128             75          0   1  0.084072       7.430290     6.965751  success  2.725856  0.093512   over-trained               0   7.430290  0.074272
44       167  Linear  0.102193   64   128  2.000000   2.020282       -0.131396  0.847288     True    0.860918      dense        0.493190  0.925826          -0.065038          src_head.2           64    8.429965         64             29          0   1  0.189462       0.860918     9.791834  success  0.927857  0.080039                              0   0.860918  0.072482
45       169  Linear  0.080539  256   256  1.000000   1.572822        1.529984  0.790646     True    9.392108      dense        2.202098  2.021270           0.972763         dest_head.0          256  105.019443        256            147          0   1  0.047246       9.392108    11.181669  success  3.064655  0.000832   over-trained               1   9.392108  0.052217
46       171  Linear  0.067211   73   256  3.506849   2.870809        1.969863  0.882557     True    4.854786      dense        2.165644  1.597388           0.686170         dest_head.2           73   39.571957         73             20          0   1  0.418326       4.854786     8.151122  success  2.203358  0.236429                              0   4.854786  0.643498
47       173  Conv2d  0.017589  256   256  1.000000   2.668545        1.486360  1.018207     True    3.605726     conv2d        2.447239  2.470274           0.556993        value_conv.0         2304  295.307333       2304            422          1   9  0.081223       3.605726    81.899554  success  1.898875  0.001311                             10   3.605726  0.193278
48       177  Linear  0.054092  128   256  2.000000   2.197242        1.081578  0.781031     True    3.106300      dense        1.447060  1.318247           0.492243         value_mlp.0          128   20.808796        128             63          0   1  0.150838       3.106300     6.698901  success  1.762470  0.090611                              0   3.106300  0.070634
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 01:17:49 2025      Time elapsed: 88.03078s
Begin: Training epoch 16                       Current time: Sun Oct 26 01:17:49 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:18:09 2025      Time elapsed: 13582.43935     ETA: 517083.46647s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:18:29 2025      Time elapsed: 13602.29830     ETA: 252118.59960s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:18:49 2025      Time elapsed: 13622.26140     ETA: 163784.98967s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:19:09 2025      Time elapsed: 13642.37848     ETA: 119609.55336s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:19:29 2025      Time elapsed: 13662.59542     ETA: 93096.92526s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:19:49 2025      Time elapsed: 13682.89527     ETA: 75415.55780s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:20:10 2025      Time elapsed: 13703.18656     ETA: 62780.17047s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:20:30 2025      Time elapsed: 13723.50935     ETA: 53298.67949s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:20:50 2025      Time elapsed: 13743.87173     ETA: 45919.80258s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:21:11 2025      Time elapsed: 13764.32370     ETA: 40012.88900s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:21:31 2025      Time elapsed: 13784.73060     ETA: 35176.12618s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:21:51 2025      Time elapsed: 13805.09469     ETA: 31141.99277s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:22:12 2025      Time elapsed: 13825.43948     ETA: 27725.32365s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:22:32 2025      Time elapsed: 13845.86116     ETA: 24793.98138s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:22:53 2025      Time elapsed: 13866.29260     ETA: 22250.77754s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:23:13 2025      Time elapsed: 13886.66555     ETA: 20022.83591s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:23:33 2025      Time elapsed: 13907.06444     ETA: 18054.64189s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:23:54 2025      Time elapsed: 13927.44403     ETA: 16302.84699s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:24:14 2025      Time elapsed: 13947.83573     ETA: 14733.31911s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:24:35 2025      Time elapsed: 13968.28176     ETA: 13318.75666s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:24:55 2025      Time elapsed: 13988.66661     ETA: 12036.91456s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:25:15 2025      Time elapsed: 14009.04312     ETA: 10869.74391s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:25:36 2025      Time elapsed: 14029.54452     ETA: 9802.38176s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:25:56 2025      Time elapsed: 14050.10456     ETA: 8822.29482s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:26:17 2025      Time elapsed: 14070.54257     ETA: 7918.90136s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:26:37 2025      Time elapsed: 14090.82843     ETA: 7083.35106s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:26:57 2025      Time elapsed: 14111.11639     ETA: 6308.19166s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:27:18 2025      Time elapsed: 14131.40440     ETA: 5586.95167s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:27:38 2025      Time elapsed: 14151.69560     ETA: 4914.05430s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:27:58 2025      Time elapsed: 14172.11709     ETA: 4284.70340s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:28:19 2025      Time elapsed: 14192.64224     ETA: 3694.66525s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:28:39 2025      Time elapsed: 14213.08495     ETA: 3140.20346s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:29:00 2025      Time elapsed: 14233.40803     ETA: 2618.08445s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:29:20 2025      Time elapsed: 14253.80922     ETA: 2125.49449s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:29:41 2025      Time elapsed: 14274.46787     ETA: 1659.91669s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:30:02 2025      Time elapsed: 14295.19341     ETA: 1219.06233s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:30:22 2025      Time elapsed: 14315.84616     ETA: 800.91355s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:30:43 2025      Time elapsed: 14336.48015     ETA: 403.68510s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:31:03 2025      Time elapsed: 14357.09839     ETA: 25.76915s
Epoch 16: Avg Policy Loss=2.6603, Avg Value Loss=0.4442
  End: Training epoch 16                       Current time: Sun Oct 26 01:31:05 2025      Time elapsed: 795.68945s
Begin: Validating epoch 16                     Current time: Sun Oct 26 01:31:05 2025      
Validation: Policy Loss=2.6621, Value Loss=0.4453, Top-1 Acc=0.2268, Top-5 Acc=0.5496
  End: Validating epoch 16                     Current time: Sun Oct 26 01:31:29 2025      Time elapsed: 23.84698s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_16.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 01:31:29 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.060617   19    32  1.684211   3.365006        0.188776  0.918674     True    1.137888     conv2d        0.609172  1.414635           0.056100     conv_stem.net.0          171   25.979734        171             37          0   9  0.388805       1.137888    22.831533  success  1.066718  0.121793                              0   1.137888  0.236831
1          6  Conv2d  0.099628   32    64  2.000000  14.975464       -4.048783  0.967874     True    0.536585     conv2d       -3.692769  1.669864          -0.270361     conv_stem.net.3          288   46.758914        288              8          0   9  4.941073       0.536585    87.141599  success  0.732520  0.142204  under-trained               0   0.536585  0.440409
2          9  Conv2d  0.157162   64   256  4.000000   3.861582        2.806324  0.972983     True    5.330022     conv2d        3.854224  2.233454           0.726729                proj           64  171.180269         64             32          0   1  0.505861       5.330022    32.116239  success  2.308684  0.324757                              0   5.330022  2.587902
3         14  Linear  0.041704  256   768  3.000000   1.798668        2.331458  0.805947     True   19.779423      dense        2.968388  2.379855           1.296214        blocks.0.qkv          256  239.803092        256            183          0   1  0.059039      19.779423    12.123867  success  4.447406  0.221314   over-trained               0  19.779423  0.151498
4         15  Linear  0.034622  256   256  1.000000   1.954017        1.728510  0.751112     True    7.666432      dense        2.121215  1.775100           0.884593   blocks.0.out_proj          256   59.579928        256             91          0   1  0.100008       7.666432     7.771533  success  2.768832  0.000274   over-trained               1   7.666432  0.104503
5         22  Linear  0.054099  256  1024  4.000000   1.878473        2.123919  0.875001     True   13.510223      dense        2.771418  2.337133           1.130663  blocks.0.ffn.net.0          256  217.336698        256            198          0   1  0.062430      13.510223    16.086832  success  3.675626  0.292868   over-trained               0  13.510223  0.186709
6         25  Linear  0.027497  256  1024  4.000000   2.304846        2.372244  0.904781     True   10.696510      dense        2.779553  2.221957           1.029242  blocks.0.ffn.net.3          256  166.708213        256            116          0   1  0.121152      10.696510    15.585290  success  3.270552  0.303852                              0  10.696510  0.388741
7         29  Linear  0.044490  256   768  3.000000   1.782921        2.365777  0.808624     True   21.228073      dense        2.968785  2.392499           1.326911        blocks.1.qkv          256  246.887336        256            186          0   1  0.057407      21.228073    11.630228  success  4.607393  0.212901   over-trained               0  21.228073  0.149344
8         30  Linear  0.036628  256   256  1.000000   1.852339        1.590102  0.753186     True    7.218203      dense        2.138925  1.838492           0.858429   blocks.1.out_proj          256   68.943333        256            106          0   1  0.082787       7.218203     9.551316  success  2.686671  0.000122   over-trained               1   7.218203  0.088768
9         37  Linear  0.057842  256  1024  4.000000   1.869498        2.213345  0.873673     True   15.273010      dense        2.796292  2.349892           1.183925  blocks.1.ffn.net.0          256  223.816390        256            198          0   1  0.061793      15.273010    14.654373  success  3.908070  0.287986   over-trained               0  15.273010  0.188783
10        40  Linear  0.028321  256  1024  4.000000   2.261487        2.175393  0.906553     True    9.160744      dense        2.722828  2.228010           0.961931  blocks.1.ffn.net.3          256  169.048072        256            123          0   1  0.113744       9.160744    18.453531  success  3.026672  0.302761                              0   9.160744  0.368978
11        44  Linear  0.042191  256   768  3.000000   1.796181        2.256068  0.810127     True   18.031666      dense        2.945518  2.377319           1.256036        blocks.2.qkv          256  238.407149        256            178          0   1  0.059676      18.031666    13.221582  success  4.246371  0.219675   over-trained               0  18.031666  0.157321
12        45  Linear  0.040801  256   256  1.000000   1.935529        1.768545  0.740172     True    8.198364      dense        2.203835  1.812058           0.913727   blocks.2.out_proj          256   64.872047        256             92          0   1  0.097536       8.198364     7.912804  success  2.863279  0.000774   over-trained               1   8.198364  0.105822
13        52  Linear  0.063742  256  1024  4.000000   1.833867        2.280958  0.870357     True   17.530607      dense        2.826323  2.374086           1.243797  blocks.2.ffn.net.0          256  236.638831        256            206          0   1  0.058098      17.530607    13.498610  success  4.186957  0.291406   over-trained               0  17.530607  0.177483
14        55  Linear  0.030421  256  1024  4.000000   2.204475        2.080465  0.905672     True    8.785092      dense        2.712213  2.249040           0.943746  blocks.2.ffn.net.3          256  177.435133        256            132          0   1  0.104836       8.785092    20.197299  success  2.963966  0.305550                              0   8.785092  0.351822
15        59  Linear  0.042825  256   768  3.000000   1.798861        2.149427  0.813480     True   15.663276      dense        2.921127  2.366179           1.194883        blocks.3.qkv          256  232.369521        256            180          0   1  0.059544      15.663276    14.835308  success  3.957686  0.217505   over-trained               0  15.663276  0.154238
16        60  Linear  0.040195  256   256  1.000000   1.905881        1.677930  0.739649     True    7.592697      dense        2.184935  1.815086           0.880396   blocks.3.out_proj          256   65.326019        256             99          0   1  0.091044       7.592697     8.603797  success  2.755485  0.001246   over-trained               0   7.592697  0.094085
17        67  Linear  0.059485  256  1024  4.000000   1.821781        2.252740  0.870183     True   17.240862      dense        2.819096  2.375863           1.236559  blocks.3.ffn.net.0          256  237.609008        256            209          0   1  0.056844      17.240862    13.781736  success  4.152212  0.292004   over-trained               0  17.240862  0.171679
18        70  Linear  0.032535  256  1024  4.000000   2.198835        1.996499  0.906891     True    8.090592      dense        2.691079  2.248070           0.907980  blocks.3.ffn.net.3          256  177.039471        256            131          0   1  0.104743       8.090592    21.882140  success  2.844397  0.306496                              0   8.090592  0.352364
19        74  Linear  0.043820  256   768  3.000000   1.793070        2.176146  0.812416     True   16.354685      dense        2.942842  2.381550           1.213642        blocks.4.qkv          256  240.741074        256            179          0   1  0.059277      16.354685    14.720007  success  4.044093  0.217917   over-trained               0  16.354685  0.158089
20        75  Linear  0.031697  256   256  1.000000   1.887938        1.586898  0.742895     True    6.927003      dense        2.185120  1.835212           0.840545   blocks.4.out_proj          256   68.424541        256             97          0   1  0.090156       6.927003     9.877943  success  2.631920  0.000977   over-trained               1   6.927003  0.099117
21        82  Linear  0.062079  256  1024  4.000000   1.806049        2.323451  0.868019     True   19.341169      dense        2.847469  2.392377           1.286483  blocks.4.ffn.net.0          256  246.818211        256            209          0   1  0.055756      19.341169    12.761287  success  4.397860  0.299360   over-trained               0  19.341169  0.172078
22        85  Linear  0.028268  256  1024  4.000000   2.189288        2.207240  0.900174     True   10.190598      dense        2.768705  2.263545           1.008200  blocks.4.ffn.net.3          256  183.461639        256            136          0   1  0.101981      10.190598    18.003031  success  3.192271  0.294205                              0  10.190598  0.345939
23        89  Linear  0.039811  256   768  3.000000   1.823446        2.192956  0.812784     True   15.945698      dense        2.939866  2.362082           1.202644        blocks.5.qkv          256  230.187794        256            174          0   1  0.062425      15.945698    14.435730  success  3.993207  0.217753   over-trained               0  15.945698  0.166589
24        90  Linear  0.038799  256   256  1.000000   1.933605        1.656991  0.736603     True    7.193561      dense        2.187571  1.806924           0.856944   blocks.5.out_proj          256   64.109695        256             94          0   1  0.096294       7.193561     8.912094  success  2.682081  0.001786   over-trained               0   7.193561  0.099912
25        97  Linear  0.063326  256  1024  4.000000   1.787569        2.388709  0.863657     True   21.691492      dense        2.887323  2.414594           1.336289  blocks.5.ffn.net.0          256  259.773246        256            214          0   1  0.053837      21.691492    11.975813  success  4.657413  0.303204   over-trained               0  21.691492  0.166943
26       100  Linear  0.025916  256  1024  4.000000   2.122954        2.157678  0.888095     True   10.383806      dense        2.831730  2.293383           1.016357  blocks.5.ffn.net.3          256  196.509350        256            144          0   1  0.093580      10.383806    18.924597  success  3.222391  0.310659                              0  10.383806  0.321232
27       104  Linear  0.037360  256   768  3.000000   1.829114        2.262482  0.814214     True   17.255497      dense        2.932733  2.352168           1.236927        blocks.6.qkv          256  224.992548        256            176          0   1  0.062497      17.255497    13.038891  success  4.153974  0.220041   over-trained               0  17.255497  0.164767
28       105  Linear  0.039340  256   256  1.000000   1.932668        1.798047  0.730950     True    8.518129      dense        2.210377  1.799130           0.930344   blocks.6.out_proj          256   62.969464        256             98          0   1  0.094214       8.518129     7.392405  success  2.918583  0.000338   over-trained               1   8.518129  0.092633
29       112  Linear  0.066200  256  1024  4.000000   1.786453        2.403566  0.863254     True   22.153397      dense        2.898843  2.420632           1.345440  blocks.6.ffn.net.0          256  263.410098        256            211          0   1  0.054142      22.153397    11.890280  success  4.706739  0.290765   over-trained               0  22.153397  0.171804
30       115  Linear  0.029153  256  1024  4.000000   2.117381        2.250326  0.883068     True   11.555455      dense        2.869564  2.300847           1.062787  blocks.6.ffn.net.3          256  199.915630        256            142          0   1  0.093769      11.555455    17.300541  success  3.399332  0.304722                              0  11.555455  0.325152
31       119  Linear  0.039008  256   768  3.000000   1.820044        2.138292  0.817388     True   14.957450      dense        2.913394  2.357481           1.174858        blocks.7.qkv          256  227.761836        256            176          0   1  0.061813      14.957450    15.227317  success  3.867486  0.222588   over-trained               0  14.957450  0.164519
32       120  Linear  0.043601  256   256  1.000000   1.898974        1.581632  0.728389     True    6.805931      dense        2.237872  1.841875           0.832888   blocks.7.out_proj          256   69.482495        256             95          0   1  0.092233       6.805931    10.209110  success  2.608818  0.000180   over-trained               1   6.805931  0.098251
33       127  Linear  0.062936  256  1024  4.000000   1.786304        2.489252  0.859463     True   24.746885      dense        2.935060  2.430394           1.393521  blocks.7.ffn.net.0          256  269.398052        256            212          0   1  0.054004      24.746885    10.886140  success  4.974624  0.293051   over-trained               0  24.746885  0.172542
34       130  Linear  0.027942  256  1024  4.000000   2.103280        2.319978  0.875613     True   12.677353      dense        2.918418  2.313331           1.103029  blocks.7.ffn.net.3          256  205.745894        256            148          0   1  0.090689      12.677353    16.229405  success  3.560527  0.300389                              0  12.677353  0.310263
35       134  Linear  0.041548  256   768  3.000000   1.803112        2.161957  0.819917     True   15.812996      dense        2.912453  2.369593           1.199014        blocks.8.qkv          256  234.203254        256            180          0   1  0.059860      15.812996    14.810808  success  3.976556  0.221967   over-trained               0  15.812996  0.161437
36       135  Linear  0.031931  256   256  1.000000   1.909285        1.880820  0.722245     True    9.662537      dense        2.279466  1.836048           0.985091   blocks.8.out_proj          256   68.556434        256            100          0   1  0.090929       9.662537     7.095076  success  3.108462  0.000146   over-trained               2   9.662537  0.092736
37       142  Linear  0.062257  256  1024  4.000000   1.777238        2.567344  0.853939     True   27.833620      dense        2.983742  2.450980           1.444570  blocks.8.ffn.net.0          256  282.474933        256            212          0   1  0.053381      27.833620    10.148695  success  5.275758  0.307809   over-trained               0  27.833620  0.173929
38       145  Linear  0.028990  256  1024  4.000000   2.072070        2.364179  0.860475     True   13.834846      dense        3.008796  2.342166           1.140974  blocks.8.ffn.net.3          256  219.869989        256            151          0   1  0.087244      13.834846    15.892479  success  3.719522  0.305826                              0  13.834846  0.300090
39       149  Linear  0.041275  256   768  3.000000   1.806610        2.104580  0.820538     True   14.619518      dense        2.898763  2.361563           1.164933        blocks.9.qkv          256  229.912946        256            182          0   1  0.059790      14.619518    15.726438  success  3.823548  0.223314   over-trained               0  14.619518  0.157281
40       150  Linear  0.038235  256   256  1.000000   1.915021        1.738506  0.733464     True    8.087721      dense        2.201369  1.812237           0.907826   blocks.9.out_proj          256   64.898896        256            102          0   1  0.090601       8.087721     8.024374  success  2.843892  0.000956   over-trained               1   8.087721  0.089311
41       157  Linear  0.054884  256  1024  4.000000   3.770328        5.682122  0.845877     True   32.141270      dense        5.697526  2.465981           1.507063  blocks.9.ffn.net.0          256  292.402439        256             17          0   1  0.671903      32.141270     9.097414  success  5.669327  0.298886                              0  32.141270  4.356051
42       160  Linear  0.034728  256  1024  4.000000   2.053372        2.441835  0.849737     True   15.459069      dense        3.074191  2.359497           1.189183  blocks.9.ffn.net.3          256  228.821526        256            157          0   1  0.084068      15.459069    14.801766  success  3.931802  0.302238                              0  15.459069  0.285871
43       165  Linear  0.053313  128   256  2.000000   1.706083        1.502613  0.757889     True    7.598687      dense        1.998468  1.732474           0.880739          src_head.0          128   54.010014        128             78          0   1  0.079948       7.598687     7.107809  success  2.756572  0.092604   over-trained               0   7.598687  0.069650
44       167  Linear  0.101642   64   128  2.000000   2.034636       -0.122861  0.848721     True    0.870192      dense        0.515078  0.941408          -0.060385          src_head.2           64    8.737928         64             29          0   1  0.192127       0.870192    10.041378  success  0.932841  0.081243                              0   0.870192  0.076548
45       169  Linear  0.078322  256   256  1.000000   3.416447        3.357607  0.790045     True    9.611198      dense        3.501891  2.032178           0.982778         dest_head.0          256  107.690743        256             16          0   1  0.604112       9.611198    11.204715  success  3.100193  0.000203                              1   9.611198  1.998375
46       171  Linear  0.064643   73   256  3.506849   2.723297        1.902661  0.883568     True    4.996443      dense        2.124310  1.613321           0.698661         dest_head.2           73   41.050701         73             22          0   1  0.367408       4.996443     8.215985  success  2.235272  0.242588                              0   4.996443  0.601317
47       173  Conv2d  0.018032  256   256  1.000000   2.631513        1.483261  1.016851     True    3.661452     conv2d        2.448924  2.471515           0.563653        value_conv.0         2304  296.152430       2304            420          0   9  0.079610       3.661452    80.883870  success  1.913492  0.001121                              9   3.661452  0.192260
48       177  Linear  0.053140  128   256  2.000000   2.195832        1.156480  0.771824     True    3.362563      dense        1.501857  1.331203           0.526670         value_mlp.0          128   21.438937        128             63          0   1  0.150661       3.362563     6.375772  success  1.833729  0.089093                              0   3.362563  0.070878
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 01:32:55 2025      Time elapsed: 86.52181s
Begin: Training epoch 17                       Current time: Sun Oct 26 01:32:55 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:33:15 2025      Time elapsed: 14488.41397     ETA: 551573.92005s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:33:34 2025      Time elapsed: 14508.10127     ETA: 268907.65718s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:33:54 2025      Time elapsed: 14528.02839     ETA: 174675.32805s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:34:14 2025      Time elapsed: 14548.11762     ETA: 127550.62129s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:34:35 2025      Time elapsed: 14568.13132     ETA: 99267.24686s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:34:54 2025      Time elapsed: 14588.11827     ETA: 80404.84523s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:35:15 2025      Time elapsed: 14608.25955     ETA: 66926.69770s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:35:35 2025      Time elapsed: 14628.59571     ETA: 56813.80860s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:35:55 2025      Time elapsed: 14648.90759     ETA: 48943.62792s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:36:16 2025      Time elapsed: 14669.13766     ETA: 42643.18321s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:36:36 2025      Time elapsed: 14689.41068     ETA: 37484.70527s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:36:56 2025      Time elapsed: 14709.74490     ETA: 33182.73288s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:37:17 2025      Time elapsed: 14730.15548     ETA: 29539.62720s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:37:37 2025      Time elapsed: 14750.61777     ETA: 26414.14198s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:37:58 2025      Time elapsed: 14771.12958     ETA: 23702.73928s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:38:18 2025      Time elapsed: 14791.57375     ETA: 21327.60042s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:38:38 2025      Time elapsed: 14812.00212     ETA: 19229.46393s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:38:59 2025      Time elapsed: 14832.55526     ETA: 17362.32998s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:39:19 2025      Time elapsed: 14853.04145     ETA: 15689.50221s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:39:40 2025      Time elapsed: 14873.38979     ETA: 14181.77717s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:40:00 2025      Time elapsed: 14893.69334     ETA: 12815.66851s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:40:21 2025      Time elapsed: 14914.28624     ETA: 11572.13028s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:40:41 2025      Time elapsed: 14935.08689     ETA: 10435.08028s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:41:02 2025      Time elapsed: 14955.54797     ETA: 9390.83783s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:41:22 2025      Time elapsed: 14975.99893     ETA: 8428.49220s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:41:43 2025      Time elapsed: 14996.58216     ETA: 7538.66650s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:42:04 2025      Time elapsed: 15017.21056     ETA: 6713.24932s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:42:24 2025      Time elapsed: 15037.84322     ETA: 5945.31873s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:42:45 2025      Time elapsed: 15058.38839     ETA: 5228.89556s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:43:05 2025      Time elapsed: 15078.98413     ETA: 4558.87954s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:43:26 2025      Time elapsed: 15099.71042     ETA: 3930.79558s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:43:47 2025      Time elapsed: 15120.41942     ETA: 3340.66767s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:44:07 2025      Time elapsed: 15141.09993     ETA: 2785.04474s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:44:28 2025      Time elapsed: 15161.76168     ETA: 2260.88623s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:44:49 2025      Time elapsed: 15182.40275     ETA: 1765.49655s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:45:09 2025      Time elapsed: 15203.05430     ETA: 1296.48269s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:45:30 2025      Time elapsed: 15223.71034     ETA: 851.70488s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:45:51 2025      Time elapsed: 15244.36894     ETA: 429.24934s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:46:11 2025      Time elapsed: 15264.94251     ETA: 27.39861s
Epoch 17: Avg Policy Loss=2.6463, Avg Value Loss=0.4359
  End: Training epoch 17                       Current time: Sun Oct 26 01:46:13 2025      Time elapsed: 797.40135s
Begin: Validating epoch 17                     Current time: Sun Oct 26 01:46:13 2025      
Validation: Policy Loss=2.6498, Value Loss=0.4386, Top-1 Acc=0.2308, Top-5 Acc=0.5545
  End: Validating epoch 17                     Current time: Sun Oct 26 01:46:36 2025      Time elapsed: 23.80311s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_17.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 01:46:36 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.062699   19    32  1.684211   3.376922        0.173849  0.918367     True    1.125853     conv2d        0.592224  1.409072           0.051482     conv_stem.net.0          171   25.649085        171             37          0   9  0.390764       1.125853    22.781916  success  1.061062  0.120601                              0   1.125853  0.234538
1          6  Conv2d  0.100412   32    64  2.000000  14.810637       -4.083183  0.967836     True    0.530038     conv2d       -3.718949  1.664446          -0.275693     conv_stem.net.3          288   46.179127        288              8          0   9  4.882797       0.530038    87.124103  success  0.728037  0.141681  under-trained               0   0.530038  0.434708
2          9  Conv2d  0.156964   64   256  4.000000   4.837587        3.481876  0.972961     True    5.245112     conv2d        4.437305  2.226227           0.719755                proj           64  168.355190         64             24          0   1  0.783344       5.245112    32.097540  success  2.290221  0.313235                              0   5.245112  3.054372
3         14  Linear  0.042735  256   768  3.000000   1.786497        2.312916  0.805801     True   19.709040      dense        2.959125  2.382095           1.294665        blocks.0.qkv          256  241.043011        256            187          0   1  0.057514      19.709040    12.230074  success  4.439487  0.220247   over-trained               0  19.709040  0.144354
4         15  Linear  0.036777  256   256  1.000000   1.942501        1.707244  0.752049     True    7.566404      dense        2.111822  1.777458           0.878890   blocks.0.out_proj          256   59.904315        256             91          0   1  0.098801       7.566404     7.917144  success  2.750710  0.000317   over-trained               2   7.566404  0.103993
5         22  Linear  0.054995  256  1024  4.000000   1.865554        2.120196  0.873366     True   13.692933      dense        2.773345  2.341511           1.136496  blocks.0.ffn.net.0          256  219.538448        256            200          0   1  0.061204      13.692933    16.032975  success  3.700396  0.290523   over-trained               0  13.692933  0.181353
6         25  Linear  0.028368  256  1024  4.000000   2.285525        2.349875  0.904158     True   10.669781      dense        2.769825  2.224010           1.028155  blocks.0.ffn.net.3          256  167.498256        256            118          0   1  0.118342      10.669781    15.698378  success  3.266463  0.304087                              0  10.669781  0.381246
7         29  Linear  0.045893  256   768  3.000000   1.771863        2.345791  0.808517     True   21.082006      dense        2.959609  2.394137           1.323912        blocks.1.qkv          256  247.820215        256            187          0   1  0.056444      21.082006    11.755058  success  4.591515  0.211852   over-trained               0  21.082006  0.145324
8         30  Linear  0.037873  256   256  1.000000   1.843258        1.575268  0.754034     True    7.155017      dense        2.133223  1.840518           0.854611   blocks.1.out_proj          256   69.265617        256            107          0   1  0.081521       7.155017     9.680706  success  2.674886  0.000354   over-trained               1   7.155017  0.087231
9         37  Linear  0.056849  256  1024  4.000000   1.848636        2.202553  0.872058     True   15.539880      dense        2.793169  2.354599           1.191448  blocks.1.ffn.net.0          256  226.255201        256            201          0   1  0.059858      15.539880    14.559649  success  3.942065  0.286079   over-trained               0  15.539880  0.180351
10        40  Linear  0.031667  256  1024  4.000000   2.246432        2.151706  0.906009     True    9.074708      dense        2.716289  2.230559           0.957833  blocks.1.ffn.net.3          256  170.043281        256            122          0   1  0.112847       9.074708    18.738155  success  3.012426  0.302748                              0   9.074708  0.370233
11        44  Linear  0.042377  256   768  3.000000   1.786088        2.232260  0.810379     True   17.774786      dense        2.936150  2.378768           1.249804        blocks.2.qkv          256  239.203776        256            184          0   1  0.057951      17.774786    13.457477  success  4.216015  0.218266   over-trained               0  17.774786  0.148337
12        45  Linear  0.037188  256   256  1.000000   1.908922        1.734179  0.741084     True    8.099532      dense        2.185609  1.814756           0.908460   blocks.2.out_proj          256   65.276321        256             96          0   1  0.092766       8.099532     8.059271  success  2.845968  0.000762   over-trained               1   8.099532  0.098682
13        52  Linear  0.066033  256  1024  4.000000   1.824054        2.281068  0.868739     True   17.805267      dense        2.830841  2.379114           1.250548  blocks.2.ffn.net.0          256  239.394461        256            206          0   1  0.057415      17.805267    13.445148  success  4.219629  0.289576   over-trained               0  17.805267  0.175013
14        55  Linear  0.031543  256  1024  4.000000   2.190769        2.055442  0.905223     True    8.674176      dense        2.707364  2.251895           0.938228  blocks.2.ffn.net.3          256  178.605691        256            133          0   1  0.103253       8.674176    20.590508  success  2.945195  0.304842                              0   8.674176  0.348510
15        59  Linear  0.043735  256   768  3.000000   1.788554        2.133636  0.813124     True   15.593348      dense        2.915467  2.368823           1.192939        blocks.3.qkv          256  233.788407        256            181          0   1  0.058613      15.593348    14.992830  success  3.948841  0.217619   over-trained               0  15.593348  0.150619
16        60  Linear  0.042346  256   256  1.000000   1.895286        1.662064  0.739729     True    7.532625      dense        2.181352  1.818329           0.876946   blocks.3.out_proj          256   65.815684        256            102          0   1  0.088647       7.532625     8.737417  success  2.744563  0.000504   over-trained               1   7.532625  0.090332
17        67  Linear  0.061213  256  1024  4.000000   1.807474        2.244979  0.868699     True   17.460361      dense        2.819923  2.380996           1.242053  blocks.3.ffn.net.0          256  240.434245        256            213          0   1  0.055327      17.460361    13.770290  success  4.178560  0.289496   over-trained               0  17.460361  0.164223
18        70  Linear  0.034908  256  1024  4.000000   2.177451        1.965584  0.906382     True    7.992817      dense        2.682956  2.250876           0.902700  blocks.3.ffn.net.3          256  178.187156        256            139          0   1  0.099870       7.992817    22.293411  success  2.827157  0.305403                              0   7.992817  0.332115
19        74  Linear  0.044172  256   768  3.000000   1.783555        2.157335  0.812559     True   16.202065      dense        2.934597  2.383068           1.209570        blocks.4.qkv          256  241.583826        256            182          0   1  0.058081      16.202065    14.910682  success  4.025179  0.217330   over-trained               0  16.202065  0.152323
20        75  Linear  0.034871  256   256  1.000000   1.874544        1.581560  0.743322     True    6.977561      dense        2.178753  1.837463           0.843704   blocks.4.out_proj          256   68.780176        256            101          0   1  0.087020       6.977561     9.857337  success  2.641507  0.000671   over-trained               1   6.977561  0.093620
21        82  Linear  0.062887  256  1024  4.000000   1.794475        2.318993  0.866630     True   19.601791      dense        2.849930  2.397639           1.292296  blocks.4.ffn.net.0          256  249.826761        256            211          0   1  0.054694      19.601791    12.745098  success  4.427391  0.298566   over-trained               0  19.601791  0.167235
22        85  Linear  0.032485  256  1024  4.000000   2.166965        2.178200  0.899710     True   10.120089      dense        2.757936  2.266538           1.005184  blocks.4.ffn.net.3          256  184.730059        256            138          0   1  0.099339      10.120089    18.253799  success  3.181209  0.294284                              0  10.120089  0.338321
23        89  Linear  0.040480  256   768  3.000000   1.808519        2.175394  0.812775     True   15.953624      dense        2.928715  2.364316           1.202859        blocks.5.qkv          256  231.374998        256            179          0   1  0.060432      15.953624    14.502974  success  3.994199  0.217082   over-trained               0  15.953624  0.157448
24        90  Linear  0.037670  256   256  1.000000   1.905332        1.629581  0.736761     True    7.165950      dense        2.173075  1.809881           0.855274   blocks.5.out_proj          256   64.547799        256             95          0   1  0.092885       7.165950     9.007570  success  2.676929  0.001525   over-trained               0   7.165950  0.096121
25        97  Linear  0.064967  256  1024  4.000000   1.782195        2.397628  0.862288     True   22.147400      dense        2.894069  2.419218           1.345323  blocks.5.ffn.net.0          256  262.553419        256            214          0   1  0.053470      22.147400    11.854819  success  4.706102  0.301579   over-trained               0  22.147400  0.165606
26       100  Linear  0.025866  256  1024  4.000000   2.108212        2.134924  0.887763     True   10.296051      dense        2.825010  2.296280           1.012671  blocks.5.ffn.net.3          256  197.824246        256            147          0   1  0.091404      10.296051    19.213604  success  3.208746  0.308977                              0  10.296051  0.313491
27       104  Linear  0.037692  256   768  3.000000   1.819123        2.251967  0.813939     True   17.295816      dense        2.927527  2.354949           1.237941        blocks.6.qkv          256  226.437901        256            178          0   1  0.061396      17.295816    13.092062  success  4.158824  0.219883   over-trained               0  17.295816  0.160317
28       105  Linear  0.038582  256   256  1.000000   1.918949        1.793512  0.730375     True    8.602661      dense        2.207188  1.802737           0.934633   blocks.6.out_proj          256   63.494651        256            100          0   1  0.091895       8.602661     7.380815  success  2.933029  0.000309   over-trained               1   8.602661  0.089541
29       112  Linear  0.066555  256  1024  4.000000   1.768667        2.392494  0.862068     True   22.527348      dense        2.894565  2.425148           1.352710  blocks.6.ffn.net.0          256  266.162965        256            215          0   1  0.052423      22.527348    11.815104  success  4.746298  0.288911   over-trained               0  22.527348  0.162998
30       115  Linear  0.029997  256  1024  4.000000   2.100286        2.226460  0.882590     True   11.483518      dense        2.861277  2.303830           1.060075  blocks.6.ffn.net.3          256  201.293449        256            142          0   1  0.092334      11.483518    17.528901  success  3.388734  0.304107                              0  11.483518  0.322518
31       119  Linear  0.039734  256   768  3.000000   1.812603        2.125706  0.817288     True   14.884579      dense        2.909815  2.360061           1.172737        blocks.7.qkv          256  229.119191        256            177          0   1  0.061079      14.884579    15.393058  success  3.858054  0.221450   over-trained               0  14.884579  0.161785
32       120  Linear  0.043622  256   256  1.000000   1.891982        1.580174  0.727463     True    6.842190      dense        2.241773  1.846426           0.835195   blocks.7.out_proj          256   70.214375        256             95          1   1  0.091515       6.842190    10.261974  success  2.615758  0.000009   over-trained               1   6.842190  0.097929
33       127  Linear  0.062776  256  1024  4.000000   1.773109        2.484931  0.858312     True   25.203091      dense        2.934115  2.434920           1.401454  blocks.7.ffn.net.0          256  272.219695        256            216          0   1  0.052603      25.203091    10.801044  success  5.020268  0.289748   over-trained               0  25.203091  0.165107
34       130  Linear  0.027991  256  1024  4.000000   2.093968        2.303019  0.875020     True   12.584478      dense        2.915675  2.316294           1.099835  blocks.7.ffn.net.3          256  207.154122        256            149          0   1  0.089621      12.584478    16.461081  success  3.547461  0.299851                              0  12.584478  0.307360
35       134  Linear  0.042173  256   768  3.000000   1.792975        2.150456  0.819853     True   15.826270      dense        2.906536  2.371971           1.199379        blocks.8.qkv          256  235.489398        256            181          0   1  0.058941      15.826270    14.879652  success  3.978225  0.220726   over-trained               0  15.826270  0.158036
36       135  Linear  0.031716  256   256  1.000000   1.893612        1.866902  0.721959     True    9.680427      dense        2.273612  1.840374           0.985894   blocks.8.out_proj          256   69.242706        256             99          0   1  0.089811       9.680427     7.152857  success  3.111338  0.000163   over-trained               2   9.680427  0.092530
37       142  Linear  0.060920  256  1024  4.000000   3.684164        5.351395  0.852822     True   28.349129      dense        5.374660  2.455327           1.452540  blocks.8.ffn.net.0          256  285.316290        256             23          0   1  0.559687      28.349129    10.064376  success  5.324390  0.306767                              0  28.349129  3.684514
38       145  Linear  0.027294  256  1024  4.000000   2.057558        2.349110  0.859550     True   13.857923      dense        3.003599  2.345527           1.141698  blocks.8.ffn.net.3          256  221.578172        256            157          0   1  0.084402      13.857923    15.989278  success  3.722623  0.305484                              0  13.857923  0.286570
39       149  Linear  0.042349  256   768  3.000000   1.793403        2.091093  0.820549     True   14.655200      dense        2.890774  2.364356           1.165992        blocks.9.qkv          256  231.396322        256            186          0   1  0.058175      14.655200    15.789366  success  3.828211  0.222655   over-trained               0  14.655200  0.150231
40       150  Linear  0.038029  256   256  1.000000   1.909901        1.744051  0.732246     True    8.187718      dense        2.208987  1.818133           0.913163   blocks.9.out_proj          256   65.785969        256             98          0   1  0.091914       8.187718     8.034713  success  2.861419  0.000991   over-trained               1   8.187718  0.093352
41       157  Linear  0.055199  256  1024  4.000000   3.814585        5.770617  0.845050     True   32.566978      dense        5.784659  2.470541           1.512777  blocks.9.ffn.net.0          256  295.489114        256             17          0   1  0.682637      32.566978     9.073274  success  5.706748  0.297045                              0  32.566978  4.421842
42       160  Linear  0.033435  256  1024  4.000000   2.043477        2.438394  0.848097     True   15.604781      dense        3.076688  2.363800           1.193258  blocks.9.ffn.net.3          256  231.100030        256            152          0   1  0.084637      15.604781    14.809566  success  3.950289  0.300400                              0  15.604781  0.293186
43       165  Linear  0.051616  128   256  2.000000   1.689588        1.499002  0.757492     True    7.712584      dense        2.009320  1.745225           0.887200          src_head.0          128   55.619229        128             82          0   1  0.076152       7.712584     7.211491  success  2.777154  0.092489   over-trained               0   7.712584  0.064011
44       167  Linear  0.100969   64   128  2.000000   2.045490       -0.117083  0.849641     True    0.876518      dense        0.529879  0.951746          -0.057239          src_head.2           64    8.948407         64             29          0   1  0.194143       0.876518    10.209045  success  0.936225  0.082099                              0   0.876518  0.079403
45       169  Linear  0.080400  256   256  1.000000   3.395584        3.361357  0.789614     True    9.770572      dense        3.508953  2.039593           0.989920         dest_head.0          256  109.545057        256             16          0   1  0.598896       9.770572    11.211735  success  3.125791  0.000286                              1   9.770572  2.023616
46       171  Linear  0.064292   73   256  3.506849   2.844407        2.013133  0.884200     True    5.102128      dense        2.216030  1.624239           0.707751         dest_head.2           73   42.095839         73             20          0   1  0.412422       5.102128     8.250643  success  2.258789  0.246023                              0   5.102128  0.677030
47       173  Conv2d  0.014595  256   256  1.000000   2.619503        1.481675  1.016202     True    3.678172     conv2d        2.447369  2.471283           0.565632        value_conv.0         2304  295.993985       2304            414          1   9  0.079594       3.678172    80.473120  success  1.917856  0.001830                              7   3.678172  0.193426
48       177  Linear  0.055816  128   256  2.000000   2.186900        1.204892  0.766802     True    3.555977      dense        1.528960  1.337573           0.550959         value_mlp.0          128   21.755678        128             63          0   1  0.149535       3.555977     6.118059  success  1.885730  0.087627                              0   3.555977  0.070489
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 01:48:05 2025      Time elapsed: 88.52945s
Begin: Training epoch 18                       Current time: Sun Oct 26 01:48:05 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:48:25 2025      Time elapsed: 15398.31385     ETA: 586213.80845s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:48:44 2025      Time elapsed: 15417.94165     ETA: 285771.54852s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:49:04 2025      Time elapsed: 15437.73634     ETA: 185613.04997s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:49:24 2025      Time elapsed: 15457.88565     ETA: 135527.01252s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:49:44 2025      Time elapsed: 15478.08197     ETA: 105467.65062s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:50:05 2025      Time elapsed: 15498.14136     ETA: 85420.58919s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:50:25 2025      Time elapsed: 15518.22780     ETA: 71095.65225s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:50:45 2025      Time elapsed: 15538.49753     ETA: 60347.63980s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:51:05 2025      Time elapsed: 15558.84022     ETA: 51983.81395s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:51:26 2025      Time elapsed: 15579.13094     ETA: 45288.53365s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:51:46 2025      Time elapsed: 15599.48136     ETA: 39807.04019s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:52:06 2025      Time elapsed: 15619.92733     ETA: 35235.95275s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:52:27 2025      Time elapsed: 15640.44872     ETA: 31365.11525s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:52:47 2025      Time elapsed: 15660.94446     ETA: 28044.27699s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:53:08 2025      Time elapsed: 15681.31756     ETA: 25163.28759s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:53:28 2025      Time elapsed: 15701.61285     ETA: 22639.76303s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:53:48 2025      Time elapsed: 15722.03867     ETA: 20410.90550s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:54:09 2025      Time elapsed: 15742.68352     ETA: 18427.68566s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:54:30 2025      Time elapsed: 15763.23946     ETA: 16650.95874s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:54:50 2025      Time elapsed: 15783.67334     ETA: 15049.73254s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:55:11 2025      Time elapsed: 15804.21978     ETA: 13599.15484s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:55:31 2025      Time elapsed: 15824.98610     ETA: 12278.75058s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:55:52 2025      Time elapsed: 15845.72828     ETA: 11071.34146s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:56:13 2025      Time elapsed: 15866.35926     ETA: 9962.75142s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:56:33 2025      Time elapsed: 15886.98510     ETA: 8941.19522s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:56:54 2025      Time elapsed: 15907.56578     ETA: 7996.61095s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:57:14 2025      Time elapsed: 15928.00411     ETA: 7120.40776s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:57:35 2025      Time elapsed: 15948.52001     ETA: 6305.36131s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:57:56 2025      Time elapsed: 15969.19362     ETA: 5545.16482s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:58:16 2025      Time elapsed: 15989.78975     ETA: 4834.24644s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:58:37 2025      Time elapsed: 16010.25048     ETA: 4167.82972s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:58:57 2025      Time elapsed: 16030.59186     ETA: 3541.75889s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:59:17 2025      Time elapsed: 16050.88115     ETA: 2952.38935s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:59:38 2025      Time elapsed: 16071.33946     ETA: 2396.52033s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 01:59:58 2025      Time elapsed: 16091.93363     ETA: 1871.26200s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:00:19 2025      Time elapsed: 16112.34333     ETA: 1374.02483s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:00:39 2025      Time elapsed: 16132.64111     ETA: 902.55587s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:01:00 2025      Time elapsed: 16153.16564     ETA: 454.83914s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:01:20 2025      Time elapsed: 16173.95361     ETA: 29.03017s
Epoch 18: Avg Policy Loss=2.6360, Avg Value Loss=0.4286
  End: Training epoch 18                       Current time: Sun Oct 26 02:01:22 2025      Time elapsed: 796.62975s
Begin: Validating epoch 18                     Current time: Sun Oct 26 02:01:22 2025      
Validation: Policy Loss=2.6409, Value Loss=0.4348, Top-1 Acc=0.2331, Top-5 Acc=0.5569
  End: Validating epoch 18                     Current time: Sun Oct 26 02:01:46 2025      Time elapsed: 24.08354s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_18.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 02:01:46 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.063288   19    32  1.684211   3.376810        0.166881  0.918181     True    1.120520     conv2d        0.583751  1.405647           0.049420     conv_stem.net.0          171   25.447603        171             37          0   9  0.390745       1.120520    22.710520  success  1.058546  0.120094                              0   1.120520  0.232775
1          6  Conv2d  0.103096   32    64  2.000000  14.842662       -4.134452  0.967802     True    0.526560     conv2d       -3.775867  1.661081          -0.278552     conv_stem.net.3          288   45.822691        288              8          0   9  4.894120       0.526560    87.022694  success  0.725645  0.141466  under-trained               0   0.526560  0.431346
2          9  Conv2d  0.156988   64   256  4.000000   4.836933        3.462204  0.972940     True    5.197384     conv2d        4.415461  2.221814           0.715785                proj           64  166.653503         64             24          0   1  0.783211       5.197384    32.064879  success  2.279777  0.304181                              0   5.197384  3.022856
3         14  Linear  0.043842  256   768  3.000000   1.780043        2.300942  0.805827     True   19.617008      dense        2.953022  2.382746           1.292633        blocks.0.qkv          256  241.404994        256            186          0   1  0.057196      19.617008    12.305903  success  4.429109  0.219385   over-trained               0  19.617008  0.143608
4         15  Linear  0.039171  256   256  1.000000   1.937049        1.698067  0.752820     True    7.527070      dense        2.105837  1.778314           0.876626   blocks.0.out_proj          256   60.022549        256             90          0   1  0.098774       7.527070     7.974225  success  2.743551  0.000341   over-trained               1   7.527070  0.105054
5         22  Linear  0.055233  256  1024  4.000000   1.859397        2.117198  0.872559     True   13.760925      dense        2.774158  2.343757           1.138648  blocks.0.ffn.net.0          256  220.676916        256            204          0   1  0.060170      13.760925    16.036488  success  3.709572  0.289670   over-trained               0  13.760925  0.175647
6         25  Linear  0.029590  256  1024  4.000000   2.270852        2.326449  0.903972     True   10.579934      dense        2.758594  2.224778           1.024483  blocks.0.ffn.net.3          256  167.794738        256            120          0   1  0.116012      10.579934    15.859715  success  3.252681  0.303477                              0  10.579934  0.373745
7         29  Linear  0.046651  256   768  3.000000   1.764502        2.328708  0.808708     True   20.881119      dense        2.951489  2.394391           1.319754        blocks.1.qkv          256  247.965544        256            188          0   1  0.055757      20.881119    11.875108  success  4.569586  0.211187   over-trained               0  20.881119  0.142261
8         30  Linear  0.038380  256   256  1.000000   1.839878        1.565960  0.754880     True    7.097763      dense        2.128719  1.840978           0.851121   blocks.1.out_proj          256   69.339116        256            107          0   1  0.081194       7.097763     9.769151  success  2.664163  0.000473   over-trained               1   7.097763  0.087121
9         37  Linear  0.057844  256  1024  4.000000   1.843407        2.202220  0.871274     True   15.654785      dense        2.794798  2.356966           1.194647  blocks.1.ffn.net.0          256  227.491671        256            200          0   1  0.059638      15.654785    14.531766  success  3.956613  0.284592   over-trained               0  15.654785  0.180058
10        40  Linear  0.032605  256  1024  4.000000   2.224480        2.121900  0.905903     True    8.992607      dense        2.701820  2.231466           0.953886  blocks.1.ffn.net.3          256  170.398693        256            126          0   1  0.109085       8.992607    18.948753  success  2.998768  0.302176                              0   8.992607  0.356492
11        44  Linear  0.043497  256   768  3.000000   1.782574        2.223071  0.810407     True   17.664978      dense        2.933310  2.379642           1.247113        blocks.2.qkv          256  239.685562        256            184          0   1  0.057692      17.664978    13.568404  success  4.202972  0.217955   over-trained               0  17.664978  0.147411
12        45  Linear  0.037662  256   256  1.000000   1.902742        1.721360  0.741652     True    8.029212      dense        2.180837  1.816323           0.904673   blocks.2.out_proj          256   65.512353        256             96          0   1  0.092136       8.029212     8.159251  success  2.833586  0.000877   over-trained               1   8.029212  0.098417
13        52  Linear  0.066507  256  1024  4.000000   1.816559        2.277248  0.867921     True   17.931023      dense        2.831033  2.381658           1.253605  blocks.2.ffn.net.0          256  240.801105        256            208          0   1  0.056618      17.931023    13.429301  success  4.234504  0.288691   over-trained               0  17.931023  0.171006
14        55  Linear  0.031534  256  1024  4.000000   2.184610        2.040372  0.905046     True    8.589653      dense        2.704263  2.253086           0.933976  blocks.2.ffn.net.3          256  179.095993        256            133          0   1  0.102719       8.589653    20.850201  success  2.930811  0.304299                              0   8.589653  0.347988
15        59  Linear  0.043348  256   768  3.000000   1.779680        2.120043  0.813067     True   15.532807      dense        2.908225  2.369667           1.191250        blocks.3.qkv          256  234.243253        256            185          0   1  0.057323      15.532807    15.080548  success  3.941168  0.217430   over-trained               0  15.532807  0.144197
16        60  Linear  0.040700  256   256  1.000000   1.889646        1.651546  0.740033     True    7.481653      dense        2.177821  1.819645           0.873998   blocks.3.out_proj          256   66.015310        256            100          0   1  0.088965       7.481653     8.823627  success  2.735261  0.000256   over-trained               1   7.481653  0.092008
17        67  Linear  0.062449  256  1024  4.000000   1.798288        2.238867  0.867987     True   17.579201      dense        2.818481  2.383433           1.244999  blocks.3.ffn.net.0          256  241.787069        256            214          0   1  0.054570      17.579201    13.754156  success  4.192756  0.287729   over-trained               0  17.579201  0.160916
18        70  Linear  0.035560  256  1024  4.000000   2.168765        1.945781  0.906258     True    7.891943      dense        2.678273  2.251966           0.897184  blocks.3.ffn.net.3          256  178.634862        256            139          0   1  0.099133       7.891943    22.635094  success  2.809260  0.304196                              0   7.891943  0.330904
19        74  Linear  0.045196  256   768  3.000000   1.779737        2.148992  0.812540     True   16.124161      dense        2.931603  2.383878           1.207477        blocks.4.qkv          256  242.034743        256            182          0   1  0.057798      16.124161    15.010688  success  4.015490  0.217152   over-trained               0  16.124161  0.151254
20        75  Linear  0.035331  256   256  1.000000   1.870061        1.571579  0.743763     True    6.924515      dense        2.175493  1.838625           0.840389   blocks.4.out_proj          256   68.964427        256            101          0   1  0.086574       6.924515     9.959460  success  2.631447  0.000265   over-trained               1   6.924515  0.093398
21        82  Linear  0.065181  256  1024  4.000000   1.791466        2.320972  0.865919     True   19.750181      dense        2.853164  2.400217           1.295571  blocks.4.ffn.net.0          256  251.313932        256            211          0   1  0.054487      19.750181    12.724639  success  4.444118  0.296945   over-trained               0  19.750181  0.166464
22        85  Linear  0.032644  256  1024  4.000000   2.151199        2.155476  0.899505     True   10.045880      dense        2.748820  2.267905           1.001988  blocks.4.ffn.net.3          256  185.312581        256            140          0   1  0.097294      10.045880    18.446624  success  3.169524  0.294811                              0  10.045880  0.331194
23        89  Linear  0.040866  256   768  3.000000   1.804942        2.171212  0.812694     True   15.956074      dense        2.926844  2.365577           1.202926        blocks.5.qkv          256  232.047535        256            179          0   1  0.060164      15.956074    14.542897  success  3.994505  0.216986   over-trained               0  15.956074  0.156626
24        90  Linear  0.036919  256   256  1.000000   1.899837        1.629630  0.736513     True    7.207321      dense        2.173607  1.812276           0.857774   blocks.5.out_proj          256   64.904692        256             95          0   1  0.092321       7.207321     9.005384  success  2.684645  0.002035   over-trained               0   7.207321  0.095843
25        97  Linear  0.065721  256  1024  4.000000   1.772180        2.389445  0.861736     True   22.300171      dense        2.890524  2.421448           1.348308  blocks.5.ffn.net.0          256  263.905203        256            216          0   1  0.052540      22.300171    11.834223  success  4.722306  0.300137   over-trained               0  22.300171  0.160917
26       100  Linear  0.028292  256  1024  4.000000   2.103308        2.122526  0.887647     True   10.212611      dense        2.822321  2.297589           1.009137  blocks.5.ffn.net.3          256  198.421528        256            143          0   1  0.092263      10.212611    19.429069  success  3.195718  0.307732                              0  10.212611  0.321074
27       104  Linear  0.037721  256   768  3.000000   1.812043        2.243799  0.813882     True   17.308931      dense        2.922400  2.356106           1.238270        blocks.6.qkv          256  227.041964        256            181          0   1  0.060359      17.308931    13.117041  success  4.160400  0.219055   over-trained               0  17.308931  0.155410
28       105  Linear  0.039173  256   256  1.000000   1.911533        1.788833  0.730251     True    8.626029      dense        2.204596  1.804660           0.935811   blocks.6.out_proj          256   63.776330        256            101          0   1  0.090701       8.626029     7.393475  success  2.937010  0.000511   over-trained               1   8.626029  0.088019
29       112  Linear  0.066144  256  1024  4.000000   1.763826        2.390921  0.861510     True   22.674160      dense        2.895408  2.427526           1.355531  blocks.6.ffn.net.0          256  267.624853        256            217          0   1  0.051852      22.674160    11.803077  success  4.761739  0.288344   over-trained               0  22.674160  0.159762
30       115  Linear  0.029544  256  1024  4.000000   2.089528        2.210118  0.882359     True   11.421190      dense        2.854996  2.305201           1.057711  blocks.6.ffn.net.3          256  201.930000        256            144          0   1  0.090794      11.421190    17.680294  success  3.379525  0.304101                              0  11.421190  0.316389
31       119  Linear  0.040220  256   768  3.000000   1.808112        2.122700  0.817209     True   14.927492      dense        2.907150  2.361046           1.173987        blocks.7.qkv          256  229.639020        256            177          0   1  0.060741      14.927492    15.383630  success  3.863611  0.220413   over-trained               0  14.927492  0.160685
32       120  Linear  0.042106  256   256  1.000000   1.886384        1.588272  0.726640     True    6.949701      dense        2.244178  1.848955           0.841966   blocks.7.out_proj          256   70.624442        256             95          0   1  0.090941       6.949701    10.162228  success  2.636229  0.000119   over-trained               1   6.949701  0.097448
33       127  Linear  0.063398  256  1024  4.000000   1.767010        2.482529  0.857776     True   25.405739      dense        2.933671  2.437184           1.404932  blocks.7.ffn.net.0          256  273.642558        256            217          0   1  0.052068      25.405739    10.770896  success  5.040411  0.288068   over-trained               0  25.405739  0.162509
34       130  Linear  0.028593  256  1024  4.000000   2.086949        2.293544  0.874593     True   12.560118      dense        2.913085  2.317789           1.098994  blocks.7.ffn.net.3          256  207.868797        256            149          0   1  0.089046      12.560118    16.549908  success  3.544026  0.299238                              0  12.560118  0.306157
35       134  Linear  0.043081  256   768  3.000000   1.787476        2.145225  0.819856     True   15.854113      dense        2.903122  2.373185           1.200142        blocks.8.qkv          256  236.148470        256            182          0   1  0.058372      15.854113    14.895092  success  3.981722  0.219495   over-trained               0  15.854113  0.155662
36       135  Linear  0.033096  256   256  1.000000   1.887168        1.864389  0.721714     True    9.725883      dense        2.272274  1.842429           0.987929   blocks.8.out_proj          256   69.571199        256             99          0   1  0.089164       9.725883     7.153202  success  3.118635  0.000144   over-trained               1   9.725883  0.092028
37       142  Linear  0.056752  256  1024  4.000000   3.680896        5.359178  0.852362     True   28.572220      dense        5.382116  2.457313           1.455944  blocks.8.ffn.net.0          256  286.624259        256             24          0   1  0.547236      28.572220    10.031571  success  5.345299  0.304931                              0  28.572220  3.635451
38       145  Linear  0.027222  256  1024  4.000000   2.049341        2.337915  0.859065     True   13.829712      dense        2.999627  2.346939           1.140813  blocks.8.ffn.net.3          256  222.299529        256            160          0   1  0.082958      13.829712    16.074053  success  3.718832  0.304380                              0  13.829712  0.279636
39       149  Linear  0.042929  256   768  3.000000   1.790276        2.086097  0.820527     True   14.629786      dense        2.889516  2.365641           1.165238        blocks.9.qkv          256  232.081592        256            185          0   1  0.058102      14.629786    15.863635  success  3.824890  0.222425   over-trained               0  14.629786  0.150601
40       150  Linear  0.037669  256   256  1.000000   1.899760        1.737311  0.731599     True    8.212772      dense        2.208219  1.821295           0.914490   blocks.9.out_proj          256   66.266714        256            102          0   1  0.089089       8.212772     8.068739  success  2.865793  0.000937   over-trained               1   8.212772  0.088489
41       157  Linear  0.058328  256  1024  4.000000   3.757170        5.697216  0.844613     True   32.836617      dense        5.712275  2.472700           1.516358  blocks.9.ffn.net.0          256  296.961123        256             16          0   1  0.689292      32.836617     9.043597  success  5.730324  0.296454                              0  32.836617  4.500828
42       160  Linear  0.033130  256  1024  4.000000   2.038490        2.435262  0.847282     True   15.654538      dense        3.077284  2.365799           1.194640  blocks.9.ffn.net.3          256  232.166162        256            154          0   1  0.083684      15.654538    14.830598  success  3.956582  0.299438                              0  15.654538  0.288536
43       165  Linear  0.052997  128   256  2.000000   1.683118        1.501077  0.757262     True    7.795481      dense        2.017693  1.752886           0.891843          src_head.0          128   56.609118        128             82          0   1  0.075438       7.795481     7.261786  success  2.792039  0.092692   over-trained               0   7.795481  0.063966
44       167  Linear  0.100394   64   128  2.000000   2.046814       -0.112207  0.850182     True    0.881413      dense        0.540081  0.957786          -0.054820          src_head.2           64    9.073731         64             29          0   1  0.194389       0.881413    10.294524  success  0.938836  0.083025                              0   0.881413  0.080764
45       169  Linear  0.079743  256   256  1.000000   3.383784        3.364543  0.789308     True    9.869923      dense        3.513998  2.043941           0.994314         dest_head.0          256  110.647383        256             16          0   1  0.595946       9.869923    11.210562  success  3.141643  0.000574                              1   9.869923  2.040423
46       171  Linear  0.061924   73   256  3.506849   2.843562        2.026757  0.884616     True    5.161228      dense        2.230723  1.630615           0.712753         dest_head.2           73   42.718387         73             20          0   1  0.412233       5.161228     8.276787  success  2.271834  0.248394                              0   5.161228  0.686477
47       173  Conv2d  0.014550  256   256  1.000000   2.609014        1.473543  1.015970     True    3.671041     conv2d        2.441618  2.470719           0.564789        value_conv.0         2304  295.609824       2304            413          0   9  0.079174       3.671041    80.524784  success  1.915996  0.001657                              7   3.671041  0.192998
48       177  Linear  0.056213  128   256  2.000000   2.172737        1.231370  0.764092     True    3.687541      dense        1.540090  1.340376           0.566737         value_mlp.0          128   21.896552        128             63          0   1  0.147751       3.687541     5.937982  success  1.920297  0.086415                              0   3.687541  0.069750
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 02:03:12 2025      Time elapsed: 86.66935s
Begin: Training epoch 19                       Current time: Sun Oct 26 02:03:12 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:03:32 2025      Time elapsed: 16305.80169     ETA: 620761.87074s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:03:52 2025      Time elapsed: 16325.61012     ETA: 302595.18375s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:04:12 2025      Time elapsed: 16345.53764     ETA: 196527.84760s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:04:32 2025      Time elapsed: 16365.57762     ETA: 143485.20183s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:04:52 2025      Time elapsed: 16385.75655     ETA: 111652.54515s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:05:12 2025      Time elapsed: 16406.00720     ETA: 90424.44304s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:05:33 2025      Time elapsed: 16426.30250     ETA: 75255.93161s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:05:53 2025      Time elapsed: 16446.64614     ETA: 63874.66199s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:06:13 2025      Time elapsed: 16466.94110     ETA: 55017.87991s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:06:34 2025      Time elapsed: 16487.24517     ETA: 47928.42174s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:06:54 2025      Time elapsed: 16507.66700     ETA: 42124.56480s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:07:15 2025      Time elapsed: 16528.13185     ETA: 37284.71078s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:07:35 2025      Time elapsed: 16548.45352     ETA: 33186.01412s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:07:55 2025      Time elapsed: 16568.83919     ETA: 29670.05705s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:08:16 2025      Time elapsed: 16589.27725     ETA: 26620.26024s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:08:36 2025      Time elapsed: 16609.66823     ETA: 23949.06538s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:08:56 2025      Time elapsed: 16629.98186     ETA: 21589.62940s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:09:17 2025      Time elapsed: 16650.23759     ETA: 19490.02812s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:09:37 2025      Time elapsed: 16670.52549     ETA: 17609.33930s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:09:57 2025      Time elapsed: 16690.97719     ETA: 15914.84675s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:10:18 2025      Time elapsed: 16711.41128     ETA: 14379.77153s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:10:38 2025      Time elapsed: 16731.75486     ETA: 12982.32070s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:10:58 2025      Time elapsed: 16752.10138     ETA: 11704.62040s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:11:19 2025      Time elapsed: 16772.58324     ETA: 10531.78456s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:11:39 2025      Time elapsed: 16793.03507     ETA: 9451.12014s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:12:00 2025      Time elapsed: 16813.34971     ETA: 8451.94157s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:12:20 2025      Time elapsed: 16833.64671     ETA: 7525.26355s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:12:40 2025      Time elapsed: 16853.96956     ETA: 6663.33726s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:13:01 2025      Time elapsed: 16874.39119     ETA: 5859.48687s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:13:21 2025      Time elapsed: 16894.88689     ETA: 5107.88747s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:13:42 2025      Time elapsed: 16915.25803     ETA: 4403.42362s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:14:02 2025      Time elapsed: 16935.54375     ETA: 3741.69670s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:14:22 2025      Time elapsed: 16955.85718     ETA: 3118.85009s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:14:43 2025      Time elapsed: 16976.18560     ETA: 2531.44885s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:15:03 2025      Time elapsed: 16996.55500     ETA: 1976.45654s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:15:23 2025      Time elapsed: 17017.03977     ETA: 1451.17534s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:15:44 2025      Time elapsed: 17037.67058     ETA: 953.18860s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:16:05 2025      Time elapsed: 17058.33311     ETA: 480.32675s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:16:25 2025      Time elapsed: 17078.91906     ETA: 30.65447s
Epoch 19: Avg Policy Loss=2.6290, Avg Value Loss=0.4222
  End: Training epoch 19                       Current time: Sun Oct 26 02:16:27 2025      Time elapsed: 794.13824s
Begin: Validating epoch 19                     Current time: Sun Oct 26 02:16:27 2025      
Validation: Policy Loss=2.6351, Value Loss=0.4328, Top-1 Acc=0.2342, Top-5 Acc=0.5595
  End: Validating epoch 19                     Current time: Sun Oct 26 02:16:50 2025      Time elapsed: 23.88397s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_19.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 02:16:51 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.063352   19    32  1.684211   3.374303        0.162175  0.918086     True    1.117022     conv2d        0.579499  1.403860           0.048062     conv_stem.net.0          171   25.343094        171             37          0   9  0.390333       1.117022    22.688083  success  1.056893  0.119530                              0   1.117022  0.231783
1          6  Conv2d  0.105123   32    64  2.000000  14.896565       -4.175977  0.967792     True    0.524407     conv2d       -3.819626  1.659332          -0.280332     conv_stem.net.3          288   45.638539        288              8          0   9  4.913178       0.524407    87.028857  success  0.724159  0.141194  under-trained               0   0.524407  0.429615
2          9  Conv2d  0.156883   64   256  4.000000   4.838385        3.453351  0.972916     True    5.172976     conv2d        4.405606  2.219565           0.713740                proj           64  165.792380         64             24          0   1  0.783507       5.172976    32.049713  success  2.274418  0.299041                              0   5.172976  3.007432
3         14  Linear  0.044023  256   768  3.000000   1.778271        2.296696  0.805889     True   19.567408      dense        2.950746  2.382788           1.291533        blocks.0.qkv          256  241.428095        256            186          0   1  0.057066      19.567408    12.338277  success  4.423506  0.218883   over-trained               0  19.567408  0.143028
4         15  Linear  0.040410  256   256  1.000000   1.934281        1.692953  0.753202     True    7.503029      dense        2.102425  1.778421           0.875237   blocks.0.out_proj          256   60.037321        256             90          0   1  0.098482       7.503029     8.001744  success  2.739166  0.000151   over-trained               1   7.503029  0.104884
5         22  Linear  0.054600  256  1024  4.000000   1.857688        2.116451  0.872194     True   13.781389      dense        2.774945  2.344611           1.139293  blocks.0.ffn.net.0          256  221.111127        256            204          0   1  0.060050      13.781389    16.044183  success  3.712329  0.289181   over-trained               0  13.781389  0.175104
6         25  Linear  0.030305  256  1024  4.000000   2.266940        2.318018  0.903880     True   10.532506      dense        2.755180  2.224975           1.022532  blocks.0.ffn.net.3          256  167.870698        256            119          0   1  0.116140      10.532506    15.938343  success  3.245382  0.303368                              0  10.532506  0.375587
7         29  Linear  0.047124  256   768  3.000000   1.763393        2.324430  0.808768     True   20.804533      dense        2.949668  2.394343           1.318158        blocks.1.qkv          256  247.937732        256            188          0   1  0.055676      20.804533    11.917486  success  4.561199  0.210931   over-trained               0  20.804533  0.141815
8         30  Linear  0.038463  256   256  1.000000   1.838032        1.561729  0.755215     True    7.074150      dense        2.126553  1.841128           0.849674   blocks.1.out_proj          256   69.363062        256            107          0   1  0.081016       7.074150     9.805145  success  2.659727  0.000450   over-trained               1   7.074150  0.087001
9         37  Linear  0.057650  256  1024  4.000000   1.837525        2.196486  0.870880     True   15.680161      dense        2.792990  2.357994           1.195351  blocks.1.ffn.net.0          256  228.031212        256            203          0   1  0.058783      15.680161    14.542657  success  3.959818  0.284022   over-trained               0  15.680161  0.175340
10        40  Linear  0.033580  256  1024  4.000000   2.222314        2.115995  0.905783     True    8.956919      dense        2.700611  2.231823           0.952159  blocks.1.ffn.net.3          256  170.538593        256            126          0   1  0.108892       8.956919    19.039873  success  2.992811  0.301822                              0   8.956919  0.356324
11        44  Linear  0.044252  256   768  3.000000   1.781417        2.218253  0.810476     True   17.588078      dense        2.931671  2.379724           1.245218        blocks.2.qkv          256  239.730851        256            184          0   1  0.057607      17.588078    13.630304  success  4.193814  0.217715   over-trained               0  17.588078  0.147016
12        45  Linear  0.037169  256   256  1.000000   1.901489        1.716089  0.742063     True    7.989092      dense        2.178506  1.816754           0.902497   blocks.2.out_proj          256   65.577417        256             96          0   1  0.092008       7.989092     8.208369  success  2.826498  0.001085   over-trained               0   7.989092  0.098448
13        52  Linear  0.066787  256  1024  4.000000   1.813722        2.273806  0.867621     True   17.933651      dense        2.830724  2.382619           1.253669  blocks.2.ffn.net.0          256  241.334265        256            209          0   1  0.056286      17.933651    13.457063  success  4.234814  0.287968   over-trained               0  17.933651  0.169200
14        55  Linear  0.031579  256  1024  4.000000   2.180812        2.032827  0.904942     True    8.553472      dense        2.702156  2.253483           0.932142  blocks.2.ffn.net.3          256  179.259912        256            133          0   1  0.102389       8.553472    20.957562  success  2.924632  0.304026                              0   8.553472  0.347377
15        59  Linear  0.043649  256   768  3.000000   1.775840        2.114123  0.813097     True   15.505730      dense        2.904549  2.369782           1.190492        blocks.3.qkv          256  234.305007        256            189          0   1  0.056434      15.505730    15.110866  success  3.937732  0.217154   over-trained               0  15.505730  0.139251
16        60  Linear  0.040131  256   256  1.000000   1.887098        1.646277  0.740299     True    7.453935      dense        2.175348  1.819940           0.872386   blocks.3.out_proj          256   66.060156        256            100          0   1  0.088710       7.453935     8.862454  success  2.730190  0.000114   over-trained               1   7.453935  0.091816
17        67  Linear  0.062711  256  1024  4.000000   1.793427        2.232067  0.867742     True   17.562334      dense        2.816536  2.384413           1.244582  blocks.3.ffn.net.0          256  242.333466        256            215          0   1  0.054111      17.562334    13.798477  success  4.190744  0.287125   over-trained               0  17.562334  0.158682
18        70  Linear  0.035153  256  1024  4.000000   2.163006        1.935602  0.906168     True    7.849945      dense        2.675082  2.252315           0.894867  blocks.3.ffn.net.3          256  178.778238        256            141          0   1  0.097943       7.849945    22.774459  success  2.801775  0.304029                              0   7.849945  0.325726
19        74  Linear  0.045265  256   768  3.000000   1.777543        2.142986  0.812679     True   16.054195      dense        2.928569  2.383770           1.205589        blocks.4.qkv          256  241.974577        256            183          0   1  0.057478      16.054195    15.072358  success  4.006769  0.216987   over-trained               0  16.054195  0.149513
20        75  Linear  0.035844  256   256  1.000000   1.864650        1.564507  0.744071     True    6.902958      dense        2.171319  1.838781           0.839035   blocks.4.out_proj          256   68.989249        256            104          0   1  0.084786       6.902958     9.994157  success  2.627348  0.000243   over-trained               1   6.902958  0.089743
21        82  Linear  0.065919  256  1024  4.000000   1.789163        2.318343  0.865651     True   19.759201      dense        2.853222  2.401241           1.295769  blocks.4.ffn.net.0          256  251.907476        256            211          0   1  0.054328      19.759201    12.748870  success  4.445132  0.296012   over-trained               0  19.759201  0.165805
22        85  Linear  0.033134  256  1024  4.000000   2.145751        2.146607  0.899394     True   10.009190      dense        2.745550  2.268386           1.000399  blocks.4.ffn.net.3          256  185.518071        256            140          0   1  0.096834      10.009190    18.534774  success  3.163730  0.295078                              0  10.009190  0.330107
23        89  Linear  0.041647  256   768  3.000000   1.803175        2.167069  0.812780     True   15.915017      dense        2.924834  2.365757           1.201807        blocks.5.qkv          256  232.143890        256            179          0   1  0.060032      15.915017    14.586468  success  3.989363  0.216576   over-trained               0  15.915017  0.156146
24        90  Linear  0.036717  256   256  1.000000   1.897518        1.628385  0.736464     True    7.213830      dense        2.173318  1.813070           0.858166   blocks.5.out_proj          256   65.023508        256             95          0   1  0.092083       7.213830     9.013728  success  2.685858  0.002313   over-trained               0   7.213830  0.095698
25        97  Linear  0.066328  256  1024  4.000000   1.776763        2.397003  0.861489     True   22.340078      dense        2.895856  2.422291           1.349085  blocks.5.ffn.net.0          256  264.417750        256            214          0   1  0.053098      22.340078    11.836026  success  4.726529  0.299402   over-trained               0  22.340078  0.164053
26       100  Linear  0.027859  256  1024  4.000000   2.094803        2.110955  0.887594     True   10.179126      dense        2.816524  2.298007           1.007710  blocks.5.ffn.net.3          256  198.612918        256            149          0   1  0.089690      10.179126    19.511785  success  3.190474  0.307090                              0  10.179126  0.307318
27       104  Linear  0.038170  256   768  3.000000   1.810002        2.241364  0.813899     True   17.310966      dense        2.920638  2.356407           1.238321        blocks.6.qkv          256  227.199567        256            181          0   1  0.060207      17.310966    13.124603  success  4.160645  0.218908   over-trained               0  17.310966  0.154889
28       105  Linear  0.039107  256   256  1.000000   1.909063        1.788880  0.730144     True    8.650596      dense        2.204146  1.805439           0.937046   blocks.6.out_proj          256   63.890846        256            101          0   1  0.090455       8.650596     7.385716  success  2.941190  0.000796   over-trained               1   8.650596  0.087833
29       112  Linear  0.066732  256  1024  4.000000   1.761492        2.390292  0.861259     True   22.749401      dense        2.895284  2.428322           1.356970  blocks.6.ffn.net.0          256  268.115631        256            217          0   1  0.051693      22.749401    11.785613  success  4.769633  0.287874   over-trained               0  22.749401  0.159054
30       115  Linear  0.029485  256  1024  4.000000   2.086770        2.205083  0.882276     True   11.394536      dense        2.853060  2.305518           1.056697  blocks.6.ffn.net.3          256  202.077387        256            146          0   1  0.089942      11.394536    17.734587  success  3.375579  0.303722                              0  11.394536  0.311813
31       119  Linear  0.040598  256   768  3.000000   1.804110        2.117805  0.817141     True   14.923752      dense        2.904142  2.361378           1.173878        blocks.7.qkv          256  229.814643        256            176          0   1  0.060612      14.923752    15.399254  success  3.863127  0.220226   over-trained               0  14.923752  0.160773
32       120  Linear  0.041886  256   256  1.000000   1.884954        1.588648  0.726344     True    6.963129      dense        2.245736  1.850148           0.842804   blocks.7.out_proj          256   70.818712        256             95          1   1  0.090794       6.963129    10.170530  success  2.638774  0.000004   over-trained               1   6.963129  0.097400
33       127  Linear  0.062919  256  1024  4.000000   1.764109        2.480770  0.857552     True   25.482702      dense        2.932859  2.437953           1.406245  blocks.7.ffn.net.0          256  274.127641        256            219          0   1  0.051634      25.482702    10.757401  success  5.048039  0.287833   over-trained               0  25.482702  0.159721
34       130  Linear  0.028896  256  1024  4.000000   2.085028        2.290582  0.874461     True   12.548318      dense        2.912156  2.318207           1.098586  blocks.7.ffn.net.3          256  208.069040        256            149          0   1  0.088889      12.548318    16.581429  success  3.542361  0.298774                              0  12.548318  0.305808
35       134  Linear  0.043323  256   768  3.000000   1.782244        2.137435  0.819878     True   15.823194      dense        2.898868  2.373570           1.199294        blocks.8.qkv          256  236.357618        256            183          0   1  0.057825      15.823194    14.937416  success  3.977838  0.218944   over-trained               0  15.823194  0.153255
36       135  Linear  0.033996  256   256  1.000000   1.885758        1.863147  0.721698     True    9.727693      dense        2.272218  1.843443           0.988010   blocks.8.out_proj          256   69.733809        256             99          1   1  0.089022       9.727693     7.168587  success  3.118925  0.000067   over-trained               1   9.727693  0.091990
37       142  Linear  0.056742  256  1024  4.000000   3.690155        5.378873  0.852123     True   28.683222      dense        5.401227  2.458063           1.457628  blocks.8.ffn.net.0          256  287.119571        256             24          0   1  0.549126      28.683222    10.010018  success  5.355672  0.304478                              0  28.683222  3.644029
38       145  Linear  0.027360  256  1024  4.000000   2.046125        2.333239  0.858873     True   13.814044      dense        2.997770  2.347444           1.140321  blocks.8.ffn.net.3          256  222.558566        256            159          0   1  0.082963      13.814044    16.111036  success  3.716725  0.303907                              0  13.814044  0.280564
39       149  Linear  0.043173  256   768  3.000000   1.787397        2.083057  0.820488     True   14.635705      dense        2.887781  2.366170           1.165414        blocks.9.qkv          256  232.364469        256            187          0   1  0.057580      14.635705    15.876548  success  3.825664  0.222286   over-trained               0  14.635705  0.147873
40       150  Linear  0.037681  256   256  1.000000   1.896903        1.737930  0.731131     True    8.245049      dense        2.209985  1.823005           0.916193   blocks.9.out_proj          256   66.528087        256            102          0   1  0.088807       8.245049     8.068853  success  2.871419  0.001054   over-trained               0   8.245049  0.088301
41       157  Linear  0.058358  256  1024  4.000000   3.754350        5.700873  0.844363     True   32.996773      dense        5.715743  2.473504           1.518471  blocks.9.ffn.net.0          256  297.511496        256             16          0   1  0.688587      32.996773     9.016382  success  5.744282  0.295863                              0  32.996773  4.501544
42       160  Linear  0.032597  256  1024  4.000000   2.036177        2.433285  0.846906     True   15.668465      dense        3.077116  2.366521           1.195026  blocks.9.ffn.net.3          256  232.552720        256            153          0   1  0.083770      15.668465    14.842087  success  3.958341  0.298891                              0  15.668465  0.289743
43       165  Linear  0.053987  128   256  2.000000   1.679723        1.501350  0.757119     True    7.830838      dense        2.021923  1.756816           0.893808          src_head.0          128   57.123637        128             82          0   1  0.075063       7.830838     7.294703  success  2.798363  0.092830   over-trained               0   7.830838  0.063917
44       167  Linear  0.099988   64   128  2.000000   2.043786       -0.109797  0.850316     True    0.883644      dense        0.546624  0.960831          -0.053723          src_head.2           64    9.137577         64             29          0   1  0.193826       0.883644    10.340787  success  0.940024  0.083124                              0   0.883644  0.081153
45       169  Linear  0.078654  256   256  1.000000   3.369937        3.356883  0.789174     True    9.911205      dense        3.508692  2.046050           0.996126         dest_head.0          256  111.185927        256             16          0   1  0.592484       9.911205    11.218204  success  3.148207  0.000513                              1   9.911205  2.045500
46       171  Linear  0.061761   73   256  3.506849   2.842184        2.031617  0.884834     True    5.185712      dense        2.236634  1.633628           0.714808         dest_head.2           73   43.015838         73             20          0   1  0.411925       5.185712     8.295068  success  2.277216  0.249513                              0   5.185712  0.690813
47       173  Conv2d  0.014825  256   256  1.000000   2.607901        1.470085  1.015912     True    3.661883     conv2d        2.438499  2.470184           0.563704        value_conv.0         2304  295.245921       2304            413          1   9  0.079120       3.661883    80.626801  success  1.913605  0.001437                              7   3.661883  0.192841
48       177  Linear  0.056368  128   256  2.000000   2.168804        1.245618  0.762964     True    3.752616      dense        1.545258  1.341007           0.574334         value_mlp.0          128   21.928407        128             63          0   1  0.147255       3.752616     5.843499  success  1.937167  0.086071                              0   3.752616  0.069473
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 02:18:19 2025      Time elapsed: 88.63533s
Begin: Training epoch 20                       Current time: Sun Oct 26 02:18:19 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:18:39 2025      Time elapsed: 17212.54502     ETA: 655281.58914s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:18:59 2025      Time elapsed: 17232.31110     ETA: 319400.88642s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:19:19 2025      Time elapsed: 17252.15772     ETA: 207428.44302s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:19:38 2025      Time elapsed: 17272.06147     ETA: 151432.79895s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:19:58 2025      Time elapsed: 17292.00762     ETA: 117827.73999s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:20:18 2025      Time elapsed: 17312.01237     ETA: 95418.04155s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:20:39 2025      Time elapsed: 17332.15048     ETA: 79406.00944s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:20:59 2025      Time elapsed: 17352.38826     ETA: 67392.33794s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:21:19 2025      Time elapsed: 17372.73988     ETA: 58044.25425s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:21:39 2025      Time elapsed: 17393.01311     ETA: 50561.48914s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:22:00 2025      Time elapsed: 17413.17649     ETA: 44435.26039s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:22:20 2025      Time elapsed: 17433.63477     ETA: 39327.37446s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:22:41 2025      Time elapsed: 17454.19735     ETA: 35002.37886s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:23:01 2025      Time elapsed: 17474.54396     ETA: 31291.91551s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:23:21 2025      Time elapsed: 17494.84458     ETA: 28073.39394s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:23:42 2025      Time elapsed: 17515.16790     ETA: 25254.68272s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:24:02 2025      Time elapsed: 17535.47584     ETA: 22765.17364s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:24:22 2025      Time elapsed: 17555.73945     ETA: 20549.96835s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:24:42 2025      Time elapsed: 17575.99907     ETA: 18565.80536s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:25:03 2025      Time elapsed: 17596.44301     ETA: 16778.20842s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:25:23 2025      Time elapsed: 17616.81482     ETA: 15158.84971s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:25:44 2025      Time elapsed: 17637.19857     ETA: 13684.86272s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:26:04 2025      Time elapsed: 17657.74303     ETA: 12337.38828s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:26:25 2025      Time elapsed: 17678.30375     ETA: 11100.50156s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:26:45 2025      Time elapsed: 17698.73141     ETA: 9960.84604s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:27:05 2025      Time elapsed: 17719.07243     ETA: 8907.24141s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:27:26 2025      Time elapsed: 17739.48915     ETA: 7930.20867s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:27:46 2025      Time elapsed: 17759.86353     ETA: 7021.48890s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:28:07 2025      Time elapsed: 17780.26829     ETA: 6174.04489s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:28:27 2025      Time elapsed: 17800.77549     ETA: 5381.76779s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:28:48 2025      Time elapsed: 17821.23711     ETA: 4639.27044s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:29:08 2025      Time elapsed: 17841.71833     ETA: 3941.90464s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:29:29 2025      Time elapsed: 17862.36518     ETA: 3285.59263s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:29:50 2025      Time elapsed: 17883.12916     ETA: 2666.69014s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:30:10 2025      Time elapsed: 17903.80912     ETA: 2081.95723s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:30:31 2025      Time elapsed: 17924.41882     ETA: 1528.55461s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:30:51 2025      Time elapsed: 17945.07634     ETA: 1003.95427s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:31:12 2025      Time elapsed: 17965.78262     ETA: 505.87862s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:31:33 2025      Time elapsed: 17986.50976     ETA: 32.28348s
Epoch 20: Avg Policy Loss=2.6252, Avg Value Loss=0.4184
  End: Training epoch 20                       Current time: Sun Oct 26 02:31:34 2025      Time elapsed: 795.01120s
Begin: Validating epoch 20                     Current time: Sun Oct 26 02:31:34 2025      
Validation: Policy Loss=2.6317, Value Loss=0.4278, Top-1 Acc=0.2352, Top-5 Acc=0.5607
  End: Validating epoch 20                     Current time: Sun Oct 26 02:31:58 2025      Time elapsed: 24.12842s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_20.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 02:31:58 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.063317   19    32  1.684211   3.371943        0.160866  0.918054     True    1.116111     conv2d        0.578310  1.403218           0.047707     conv_stem.net.0          171   25.305703        171             37          0   9  0.389945       1.116111    22.673115  success  1.056461  0.119332                              0   1.116111  0.231357
1          6  Conv2d  0.106349   32    64  2.000000  14.905175       -4.188943  0.967787     True    0.523553     conv2d       -3.831889  1.658712          -0.281039     conv_stem.net.3          288   45.573422        288              8          0   9  4.916222       0.523553    87.046462  success  0.723570  0.140932  under-trained               0   0.523553  0.428993
2          9  Conv2d  0.156957   64   256  4.000000   4.841540        3.452038  0.972910     True    5.164211     conv2d        4.403802  2.218781           0.713004                proj           64  165.493452         64             24          0   1  0.784151       5.164211    32.046223  success  2.272490  0.297516                              0   5.164211  3.002627
3         14  Linear  0.044192  256   768  3.000000   1.777869        2.295201  0.805938     True   19.542683      dense        2.949847  2.382653           1.290984        blocks.0.qkv          256  241.353079        256            186          0   1  0.057036      19.542683    12.350049  success  4.420711  0.218793   over-trained               0  19.542683  0.142852
4         15  Linear  0.040795  256   256  1.000000   1.933278        1.689966  0.753395     True    7.484200      dense        2.100674  1.778322           0.874145   blocks.0.out_proj          256   60.023622        256             90          0   1  0.098376       7.484200     8.020045  success  2.735727  0.000185   over-trained               1   7.484200  0.104805
5         22  Linear  0.054867  256  1024  4.000000   1.856872        2.115109  0.872058     True   13.774350      dense        2.775063  2.344919           1.139071  blocks.0.ffn.net.0          256  221.268091        256            204          0   1  0.059993      13.774350    16.063777  success  3.711381  0.288927   over-trained               0  13.774350  0.174855
6         25  Linear  0.030476  256  1024  4.000000   2.265807        2.316452  0.903798     True   10.528149      dense        2.754674  2.225072           1.022352  blocks.0.ffn.net.3          256  167.908119        256            119          0   1  0.116036      10.528149    15.948494  success  3.244711  0.303320                              0  10.528149  0.375396
7         29  Linear  0.047468  256   768  3.000000   1.763533        2.323378  0.808799     True   20.770952      dense        2.949341  2.394232           1.317456        blocks.1.qkv          256  247.874728        256            188          0   1  0.055686      20.770952    11.933720  success  4.557516  0.210830   over-trained               0  20.770952  0.141770
8         30  Linear  0.038657  256   256  1.000000   1.837371        1.560082  0.755332     True    7.064546      dense        2.125647  1.841121           0.849084   blocks.1.out_proj          256   69.361952        256            107          0   1  0.080952       7.064546     9.818317  success  2.657921  0.000418   over-trained               1   7.064546  0.086940
9         37  Linear  0.057611  256  1024  4.000000   1.836761        2.195183  0.870765     True   15.672501      dense        2.792979  2.358267           1.195138  blocks.1.ffn.net.0          256  228.174635        256            203          0   1  0.058729      15.672501    14.558917  success  3.958851  0.283870   over-trained               0  15.672501  0.175095
10        40  Linear  0.033934  256  1024  4.000000   2.221431        2.114209  0.905731     True    8.948140      dense        2.700070  2.231884           0.951733  blocks.1.ffn.net.3          256  170.562760        256            126          0   1  0.108814       8.948140    19.061253  success  2.991344  0.301643                              0   8.948140  0.356167
11        44  Linear  0.044398  256   768  3.000000   1.781371        2.216965  0.810517     True   17.560101      dense        2.931184  2.379627           1.244527        blocks.2.qkv          256  239.677414        256            184          0   1  0.057603      17.560101    13.648977  success  4.190477  0.217661   over-trained               0  17.560101  0.146940
12        45  Linear  0.037198  256   256  1.000000   1.900757        1.713745  0.742203     True    7.972817      dense        2.177330  1.816760           0.901612   blocks.2.out_proj          256   65.578235        256             96          0   1  0.091933       7.972817     8.225228  success  2.823618  0.001125   over-trained               0   7.972817  0.098396
13        52  Linear  0.067127  256  1024  4.000000   1.813359        2.272440  0.867551     True   17.912922      dense        2.830715  2.382851           1.253166  blocks.2.ffn.net.0          256  241.463263        256            209          0   1  0.056261      17.912922    13.479837  success  4.232366  0.287692   over-trained               0  17.912922  0.169057
14        55  Linear  0.031282  256  1024  4.000000   2.176655        2.027752  0.904901     True    8.542615      dense        2.699704  2.253559           0.931591  blocks.2.ffn.net.3          256  179.291046        256            136          0   1  0.100897       8.542615    20.987841  success  2.922775  0.303896                              0   8.542615  0.339854
15        59  Linear  0.043340  256   768  3.000000   1.775420        2.113023  0.813119     True   15.493656      dense        2.903838  2.369707           1.190154        blocks.3.qkv          256  234.264870        256            189          0   1  0.056404      15.493656    15.120051  success  3.936198  0.217066   over-trained               0  15.493656  0.139083
16        60  Linear  0.039766  256   256  1.000000   1.886564        1.644372  0.740438     True    7.440853      dense        2.174352  1.819935           0.871623   blocks.3.out_proj          256   66.059387        256            100          1   1  0.088656       7.440853     8.877932  success  2.727793  0.000022   over-trained               1   7.440853  0.091781
17        67  Linear  0.062686  256  1024  4.000000   1.793323        2.231662  0.867673     True   17.556120      dense        2.816771  2.384620           1.244429  blocks.3.ffn.net.0          256  242.448735        256            215          0   1  0.054104      17.556120    13.809927  success  4.190002  0.286846   over-trained               0  17.556120  0.158605
18        70  Linear  0.035296  256  1024  4.000000   2.162929        1.934134  0.906146     True    7.838257      dense        2.674867  2.252352           0.894220  blocks.3.ffn.net.3          256  178.793601        256            141          0   1  0.097936       7.838257    22.810377  success  2.799689  0.303905                              0   7.838257  0.325737
19        74  Linear  0.045109  256   768  3.000000   1.777305        2.141871  0.812696     True   16.036982      dense        2.928042  2.383711           1.205123        blocks.4.qkv          256  241.941982        256            183          0   1  0.057460      16.036982    15.086504  success  4.004620  0.216909   over-trained               0  16.036982  0.149389
20        75  Linear  0.035593  256   256  1.000000   1.864176        1.562439  0.744155     True    6.888729      dense        2.170676  1.838841           0.838139   blocks.4.out_proj          256   68.998642        256            104          0   1  0.084739       6.888729    10.016165  success  2.624639  0.000184   over-trained               1   6.888729  0.089712
21        82  Linear  0.066205  256  1024  4.000000   1.788624        2.317501  0.865578     True   19.755560      dense        2.853204  2.401486           1.295689  blocks.4.ffn.net.0          256  252.049463        256            211          0   1  0.054291      19.755560    12.758406  success  4.444723  0.295799   over-trained               0  19.755560  0.165622
22        85  Linear  0.032990  256  1024  4.000000   2.135908        2.136130  0.899348     True   10.002399      dense        2.739382  2.268455           1.000104  blocks.4.ffn.net.3          256  185.547502        256            145          0   1  0.094332      10.002399    18.550299  success  3.162657  0.294965                              0  10.002399  0.317643
23        89  Linear  0.041992  256   768  3.000000   1.802646        2.165669  0.812795     True   15.899490      dense        2.924154  2.365740           1.201383        blocks.5.qkv          256  232.134807        256            179          0   1  0.059993      15.899490    14.600141  success  3.987417  0.216573   over-trained               0  15.899490  0.155973
24        90  Linear  0.036431  256   256  1.000000   1.896880        1.628586  0.736413     True    7.220387      dense        2.173390  1.813313           0.858560   blocks.5.out_proj          256   65.059906        256             95          0   1  0.092018       7.220387     9.010584  success  2.687078  0.002411   over-trained               0   7.220387  0.095653
25        97  Linear  0.066433  256  1024  4.000000   1.769562        2.387286  0.861425     True   22.339983      dense        2.890357  2.422465           1.349083  blocks.5.ffn.net.0          256  264.524066        256            216          0   1  0.052362      22.339983    11.840836  success  4.726519  0.299142   over-trained               0  22.339983  0.160087
26       100  Linear  0.027650  256  1024  4.000000   2.094023        2.109499  0.887573     True   10.171630      dense        2.815861  2.298035           1.007391  blocks.5.ffn.net.3          256  198.625367        256            149          0   1  0.089626      10.171630    19.527388  success  3.189299  0.306775                              0  10.171630  0.307119
27       104  Linear  0.038408  256   768  3.000000   1.809603        2.241841  0.813865     True   17.332365      dense        2.920364  2.356460           1.238858        blocks.6.qkv          256  227.227221        256            181          0   1  0.060177      17.332365    13.109995  success  4.163216  0.218883   over-trained               0  17.332365  0.154749
28       105  Linear  0.039177  256   256  1.000000   1.908548        1.789438  0.730092     True    8.661462      dense        2.204247  1.805704           0.937591   blocks.6.out_proj          256   63.929899        256            101          0   1  0.090404       8.661462     7.380960  success  2.943036  0.000820   over-trained               1   8.661462  0.087798
29       112  Linear  0.066859  256  1024  4.000000   1.760912        2.389902  0.861181     True   22.761238      dense        2.895201  2.428496           1.357196  blocks.6.ffn.net.0          256  268.222874        256            217          0   1  0.051654      22.761238    11.784195  success  4.770874  0.287729   over-trained               0  22.761238  0.158845
30       115  Linear  0.029435  256  1024  4.000000   2.084228        2.201869  0.882248     True   11.387900      dense        2.851124  2.305536           1.056444  blocks.6.ffn.net.3          256  202.085937        256            147          0   1  0.089426      11.387900    17.745671  success  3.374596  0.303576                              0  11.387900  0.309170
31       119  Linear  0.040533  256   768  3.000000   1.805940        2.119554  0.817139     True   14.916140      dense        2.905540  2.361364           1.173656        blocks.7.qkv          256  229.807256        256            177          0   1  0.060578      14.916140    15.406617  success  3.862142  0.219998   over-trained               0  14.916140  0.160047
32       120  Linear  0.041610  256   256  1.000000   1.883752        1.586931  0.726300     True    6.957143      dense        2.245288  1.850364           0.842431   blocks.7.out_proj          256   70.854001        256             95          1   1  0.090671       6.957143    10.184353  success  2.637640  0.000011   over-trained               1   6.957143  0.097272
33       127  Linear  0.063082  256  1024  4.000000   1.763649        2.480559  0.857482     True   25.497194      dense        2.932880  2.438146           1.406492  blocks.7.ffn.net.0          256  274.249727        256            219          0   1  0.051603      25.497194    10.756075  success  5.049475  0.287608   over-trained               0  25.497194  0.159560
34       130  Linear  0.028838  256  1024  4.000000   2.083907        2.289677  0.874400     True   12.552862      dense        2.911492  2.318289           1.098743  blocks.7.ffn.net.3          256  208.108224        256            149          0   1  0.088797      12.552862    16.578548  success  3.543002  0.298748                              0  12.552862  0.305507
35       134  Linear  0.043269  256   768  3.000000   1.781673        2.136392  0.819902     True   15.815860      dense        2.898212  2.373583           1.199093        blocks.8.qkv          256  236.364800        256            183          0   1  0.057783      15.815860    14.944796  success  3.976916  0.218800   over-trained               0  15.815860  0.153081
36       135  Linear  0.034222  256   256  1.000000   1.884683        1.860689  0.721719     True    9.711109      dense        2.271374  1.843661           0.987269   blocks.8.out_proj          256   69.768803        256             99          1   1  0.088914       9.711109     7.184432  success  3.116265  0.000072   over-trained               1   9.711109  0.091885
37       142  Linear  0.056886  256  1024  4.000000   3.692506        5.383981  0.852058     True   28.713312      dense        5.406164  2.458205           1.458083  blocks.8.ffn.net.0          256  287.213323        256             24          0   1  0.549606      28.713312    10.002793  success  5.358480  0.304283                              0  28.713312  3.645394
38       145  Linear  0.027402  256  1024  4.000000   2.042304        2.328545  0.858819     True   13.808800      dense        2.994673  2.347517           1.140156  blocks.8.ffn.net.3          256  222.595711        256            161          0   1  0.082145      13.808800    16.119845  success  3.716019  0.303745                              0  13.808800  0.276216
39       149  Linear  0.043200  256   768  3.000000   1.786782        2.081906  0.820513     True   14.627516      dense        2.887116  2.366196           1.165171        blocks.9.qkv          256  232.378296        256            187          0   1  0.057535      14.627516    15.886381  success  3.824594  0.222152   over-trained               0  14.627516  0.147700
40       150  Linear  0.037804  256   256  1.000000   1.897013        1.738445  0.731028     True    8.249202      dense        2.210869  1.823437           0.916412   blocks.9.out_proj          256   66.594295        256            100          0   1  0.089701       8.249202     8.072817  success  2.872142  0.001089   over-trained               0   8.249202  0.090330
41       157  Linear  0.057432  256  1024  4.000000   3.830647        5.818136  0.844318     True   33.024727      dense        5.831195  2.473663           1.518839  blocks.9.ffn.net.0          256  297.620473        256             17          0   1  0.686533      33.024727     9.012049  success  5.746715  0.295629                              0  33.024727  4.446265
42       160  Linear  0.032370  256  1024  4.000000   2.035882        2.433080  0.846811     True   15.671075      dense        3.077161  2.366647           1.195099  blocks.9.ffn.net.3          256  232.620058        256            153          0   1  0.083746      15.671075    14.843912  success  3.958671  0.298743                              0  15.671075  0.289618
43       165  Linear  0.054245  128   256  2.000000   1.678896        1.501563  0.757068     True    7.841068      dense        2.023359  1.758031           0.894375          src_head.0          128   57.283717        128             82          0   1  0.074972       7.841068     7.305602  success  2.800191  0.092821   over-trained               0   7.841068  0.063929
44       167  Linear  0.100056   64   128  2.000000   2.042890       -0.109692  0.850391     True    0.883702      dense        0.548515  0.961761          -0.053694          src_head.2           64    9.157162         64             29          0   1  0.193660       0.883702    10.362277  success  0.940054  0.083032                              0   0.883702  0.081278
45       169  Linear  0.078677  256   256  1.000000   3.369005        3.357426  0.789135     True    9.921181      dense        3.509687  2.046665           0.996563         dest_head.0          256  111.343429        256             16          0   1  0.592251       9.921181    11.222800  success  3.149791  0.000371                              1   9.921181  2.048157
46       171  Linear  0.061914   73   256  3.506849   2.843198        2.034257  0.884900     True    5.193764      dense        2.239349  1.634564           0.715482         dest_head.2           73   43.108574         73             20          0   1  0.412152       5.193764     8.300064  success  2.278983  0.249888                              0   5.193764  0.692435
47       173  Conv2d  0.014900  256   256  1.000000   2.607778        1.468354  1.015922     True    3.656512     conv2d        2.436867  2.469852           0.563067        value_conv.0         2304  295.020038       2304            411          0   9  0.079306       3.656512    80.683459  success  1.912201  0.001351                              7   3.656512  0.193326
48       177  Linear  0.056456  128   256  2.000000   2.167040        1.249378  0.762693     True    3.771697      dense        1.546067  1.340969           0.576537         value_mlp.0          128   21.926506        128             63          0   1  0.147033       3.771697     5.813433  success  1.942086  0.085927                              0   3.771697  0.069342
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 02:33:24 2025      Time elapsed: 85.84894s
Begin: Training epoch 21                       Current time: Sun Oct 26 02:33:24 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:33:44 2025      Time elapsed: 18117.69925     ETA: 689740.81066s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:34:04 2025      Time elapsed: 18137.54040     ETA: 336179.31144s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:34:24 2025      Time elapsed: 18157.50220     ETA: 218313.70156s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:34:44 2025      Time elapsed: 18177.60339     ETA: 159372.13774s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:35:04 2025      Time elapsed: 18197.98025     ETA: 124001.03748s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:35:25 2025      Time elapsed: 18218.54391     ETA: 100414.54125s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:35:45 2025      Time elapsed: 18238.89574     ETA: 83560.19806s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:36:05 2025      Time elapsed: 18259.11412     ETA: 70913.83448s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:36:26 2025      Time elapsed: 18279.39413     ETA: 61073.48684s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:36:46 2025      Time elapsed: 18299.80897     ETA: 53197.54469s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:37:07 2025      Time elapsed: 18320.46683     ETA: 46750.50038s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:37:27 2025      Time elapsed: 18341.02097     ETA: 41374.28649s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:37:48 2025      Time elapsed: 18361.41894     ETA: 36821.70707s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:38:08 2025      Time elapsed: 18381.74314     ETA: 32916.45005s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:38:28 2025      Time elapsed: 18402.02904     ETA: 29529.12261s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:38:49 2025      Time elapsed: 18422.27972     ETA: 26562.62458s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:39:09 2025      Time elapsed: 18442.47362     ETA: 23942.67017s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:39:29 2025      Time elapsed: 18462.74977     ETA: 21611.67431s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:39:50 2025      Time elapsed: 18483.15763     ETA: 19524.05125s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:40:10 2025      Time elapsed: 18503.69984     ETA: 17643.27780s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:40:30 2025      Time elapsed: 18524.08694     ETA: 15939.53577s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:40:51 2025      Time elapsed: 18544.34058     ETA: 14388.72245s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:41:11 2025      Time elapsed: 18564.56940     ETA: 12970.98393s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:41:31 2025      Time elapsed: 18584.85940     ETA: 11669.74297s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:41:52 2025      Time elapsed: 18605.23985     ETA: 10471.02899s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:42:12 2025      Time elapsed: 18625.57533     ETA: 9362.93345s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:42:32 2025      Time elapsed: 18645.87926     ETA: 8335.39862s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:42:53 2025      Time elapsed: 18666.34858     ETA: 7379.87424s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:43:13 2025      Time elapsed: 18686.87400     ETA: 6488.85591s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:43:34 2025      Time elapsed: 18707.20433     ETA: 5655.81144s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:43:54 2025      Time elapsed: 18727.53886     ETA: 4875.20125s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:44:14 2025      Time elapsed: 18747.89350     ETA: 4142.11272s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:44:35 2025      Time elapsed: 18768.24698     ETA: 3452.21998s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:44:55 2025      Time elapsed: 18788.62814     ETA: 2801.71602s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:45:15 2025      Time elapsed: 18808.96140     ETA: 2187.21351s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:45:36 2025      Time elapsed: 18829.47494     ETA: 1605.73578s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:45:57 2025      Time elapsed: 18850.19388     ETA: 1054.59193s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:46:17 2025      Time elapsed: 18870.87851     ETA: 531.36421s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:46:38 2025      Time elapsed: 18891.51114     ETA: 33.90784s
Epoch 21: Avg Policy Loss=2.6470, Avg Value Loss=0.4463
  End: Training epoch 21                       Current time: Sun Oct 26 02:46:39 2025      Time elapsed: 794.95965s
Begin: Validating epoch 21                     Current time: Sun Oct 26 02:46:39 2025      
Validation: Policy Loss=2.6462, Value Loss=0.4499, Top-1 Acc=0.2310, Top-5 Acc=0.5566
  End: Validating epoch 21                     Current time: Sun Oct 26 02:47:03 2025      Time elapsed: 24.10840s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_21.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 02:47:03 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.063562   19    32  1.684211   3.349399        0.125340  0.917090     True    1.089988     conv2d        0.551227  1.391451           0.037422     conv_stem.net.0          171   24.629232        171             37          0   9  0.386239       1.089988    22.595877  success  1.044025  0.120304                              0   1.089988  0.224828
1          6  Conv2d  0.124813   32    64  2.000000   5.028298       -1.491308  0.967711     True    0.505146     conv2d       -0.432077  1.645166          -0.296583     conv_stem.net.3          288   44.173907        288             58          0   9  0.528941       0.505146    87.447797  success  0.710736  0.138892                              0   0.505146  0.258919
2          9  Conv2d  0.154362   64   256  4.000000   4.835929        3.362497  0.973176     True    4.958103     conv2d        4.310045  2.200921           0.695316                proj           64  158.825894         64             24          0   1  0.783006       4.958103    32.033603  success  2.226680  0.308587                              0   4.958103  2.874729
3         14  Linear  0.047756  256   768  3.000000   1.749707        2.254519  0.804299     True   19.431751      dense        2.941875  2.394464           1.288512        blocks.0.qkv          256  248.006793        256            191          0   1  0.054247      19.431751    12.762967  success  4.408146  0.217353   over-trained               0  19.431751  0.131624
4         15  Linear  0.038854  256   256  1.000000   1.894711        1.639837  0.754566     True    7.336377      dense        2.081992  1.787067           0.865482   blocks.0.out_proj          256   61.244513        256             96          0   1  0.091316       7.336377     8.348060  success  2.708575  0.000630   over-trained               1   7.336377  0.095331
5         22  Linear  0.059861  256  1024  4.000000   1.829042        2.168580  0.866362     True   15.333346      dense        2.796277  2.358040           1.185637  blocks.0.ffn.net.0          256  228.055166        256            209          0   1  0.057346      15.333346    14.873150  success  3.915782  0.285677   over-trained               0  15.333346  0.163104
6         25  Linear  0.035686  256  1024  4.000000   2.219737        2.240146  0.903833     True   10.213958      dense        2.722155  2.230521           1.009194  blocks.0.ffn.net.3          256  170.028123        256            130          0   1  0.106978      10.213958    16.646644  success  3.195928  0.303038                              0  10.213958  0.345226
7         29  Linear  0.050915  256   768  3.000000   1.740118        2.283620  0.807461     True   20.527494      dense        2.943433  2.405065           1.312336        blocks.1.qkv          256  254.135469        256            192          0   1  0.053413      20.527494    12.380248  success  4.530728  0.208494   over-trained               0  20.527494  0.132393
8         30  Linear  0.040030  256   256  1.000000   1.813290        1.531275  0.756541     True    6.989940      dense        2.118160  1.848614           0.844473   blocks.1.out_proj          256   70.568959        256            107          0   1  0.078624       6.989940    10.095789  success  2.643849  0.001018   over-trained               0   6.989940  0.085404
9         37  Linear  0.059009  256  1024  4.000000   3.776826        4.729500  0.864805     True   17.874821      dense        4.798557  2.372625           1.252242  blocks.1.ffn.net.0          256  235.844295        256             14          0   1  0.742138      17.874821    13.194219  success  4.227862  0.283197                              0  17.874821  3.808998
10        40  Linear  0.030521  256  1024  4.000000   2.183499        2.046431  0.905422     True    8.654174      dense        2.681460  2.238696           0.937226  blocks.1.ffn.net.3          256  173.259016        256            138          0   1  0.100746       8.654174    20.020284  success  2.941798  0.303097                              0   8.654174  0.327613
11        44  Linear  0.045272  256   768  3.000000   1.753032        2.172176  0.809145     True   17.341898      dense        2.923283  2.390853           1.239097        blocks.2.qkv          256  245.953541        256            192          0   1  0.054345      17.341898    14.182620  success  4.164361  0.215076   over-trained               0  17.341898  0.132915
12        45  Linear  0.034065  256   256  1.000000   1.877091        1.673273  0.744448     True    7.787860      dense        2.163166  1.824150           0.891418   blocks.2.out_proj          256   66.703660        256             97          0   1  0.089055       7.787860     8.565082  success  2.790674  0.000808   over-trained               1   7.787860  0.096492
13        52  Linear  0.055598  256  1024  4.000000   4.036049        5.276697  0.861287     True   20.295130      dense        5.311732  2.399524           1.307392  blocks.2.ffn.net.0          256  250.913620        256             16          0   1  0.759012      20.295130    12.363243  success  4.505012  0.288237                              0  20.295130  3.940977
14        55  Linear  0.037451  256  1024  4.000000   2.154544        1.987227  0.904274     True    8.362615      dense        2.696961  2.261793           0.922342  blocks.2.ffn.net.3          256  182.722810        256            127          0   1  0.102449       8.362615    21.849962  success  2.891819  0.305621                              0   8.362615  0.362685
15        59  Linear  0.047388  256   768  3.000000   1.747346        2.066248  0.812251     True   15.223231      dense        2.891628  2.379099           1.182507        blocks.3.qkv          256  239.385954        256            194          0   1  0.053656      15.223231    15.725042  success  3.901696  0.215199   over-trained               0  15.223231  0.128173
16        60  Linear  0.036036  256   256  1.000000   1.877632        1.607840  0.743256     True    7.183111      dense        2.161995  1.824980           0.856313   blocks.3.out_proj          256   66.831374        256             95          0   1  0.090043       7.183111     9.303960  success  2.680133  0.000949   over-trained               1   7.183111  0.098078
17        67  Linear  0.064672  256  1024  4.000000   1.770045        2.298749  0.861578     True   19.892771      dense        2.848012  2.401840           1.298695  blocks.3.ffn.net.0          256  252.255141        256            218          0   1  0.052154      19.892771    12.680744  success  4.460131  0.284785   over-trained               0  19.892771  0.150682
18        70  Linear  0.037128  256  1024  4.000000   2.125468        1.885301  0.905132     True    7.709124      dense        2.668885  2.261260           0.887005  blocks.3.ffn.net.3          256  182.498833        256            144          0   1  0.093789       7.709124    23.673096  success  2.776531  0.302556                              0   7.709124  0.317159
19        74  Linear  0.048849  256   768  3.000000   1.750625        2.111419  0.810980     True   16.072897      dense        2.923340  2.394947           1.206094        blocks.4.qkv          256  248.282774        256            190          0   1  0.054456      16.072897    15.447295  success  4.009102  0.215456   over-trained               0  16.072897  0.136390
20        75  Linear  0.038204  256   256  1.000000   1.841504        1.531282  0.746248     True    6.784828      dense        2.156252  1.844366           0.831539   blocks.4.out_proj          256   69.882105        256            103          0   1  0.082916       6.784828    10.299761  success  2.604770  0.000868   over-trained               1   6.784828  0.089361
21        82  Linear  0.068747  256  1024  4.000000   1.752261        2.356712  0.859849     True   22.128662      dense        2.873904  2.419990           1.344955  blocks.4.ffn.net.0          256  263.020608        256            219          0   1  0.050833      22.128662    11.885970  success  4.704111  0.291375   over-trained               0  22.128662  0.149650
22        85  Linear  0.034888  256  1024  4.000000   2.101674        2.093192  0.898224     True    9.907496      dense        2.733679  2.278438           0.995964  blocks.4.ffn.net.3          256  189.861897        256            149          0   1  0.090253       9.907496    19.163458  success  3.147618  0.294609                              0   9.907496  0.307865
23        89  Linear  0.044923  256   768  3.000000   1.775569        2.124225  0.812022     True   15.716764      dense        2.914115  2.375768           1.196363        blocks.5.qkv          256  237.556897        256            182          0   1  0.057489      15.716764    15.114873  success  3.964437  0.214939   over-trained               0  15.716764  0.147135
24        90  Linear  0.035083  256   256  1.000000   1.880066        1.560152  0.739752     True    6.758320      dense        2.151311  1.816589           0.829839   blocks.5.out_proj          256   65.552525        256             95          0   1  0.090293       6.758320     9.699530  success  2.599677  0.002581   over-trained               0   6.758320  0.095084
25        97  Linear  0.069135  256  1024  4.000000   1.742200        2.424100  0.856488     True   24.626478      dense        2.912346  2.440118           1.391402  blocks.5.ffn.net.0          256  275.497870        256            220          0   1  0.050039      24.626478    11.187059  success  4.962507  0.296281   over-trained               0  24.626478  0.150334
26       100  Linear  0.030341  256  1024  4.000000   2.060307        2.070542  0.886628     True   10.115046      dense        2.809334  2.308464           1.004968  blocks.5.ffn.net.3          256  203.452738        256            145          0   1  0.088054      10.115046    20.113873  success  3.180416  0.303784                              0  10.115046  0.313347
27       104  Linear  0.043407  256   768  3.000000   1.776752        2.189913  0.812735     True   17.081944      dense        2.907884  2.368008           1.232537        blocks.6.qkv          256  233.350002        256            183          0   1  0.057419      17.081944    13.660624  success  4.133031  0.216452   over-trained               0  17.081944  0.145903
28       105  Linear  0.035775  256   256  1.000000   1.895206        1.764490  0.731128     True    8.531548      dense        2.191990  1.808452           0.931028   blocks.6.out_proj          256   64.335765        256            104          0   1  0.087782       8.531548     7.540926  success  2.920881  0.000100   over-trained               1   8.531548  0.084031
29       112  Linear  0.053254  256  1024  4.000000   3.866616        5.414441  0.856285     True   25.136513      dense        5.439583  2.445413           1.400305  blocks.6.ffn.net.0          256  278.877101        256             19          0   1  0.657647      25.136513    11.094502  success  5.013633  0.283841                              0  25.136513  3.935012
30       115  Linear  0.031031  256  1024  4.000000   2.046179        2.158415  0.880923     True   11.346233      dense        2.841409  2.315641           1.054852  blocks.6.ffn.net.3          256  206.842931        256            152          0   1  0.084856      11.346233    18.230097  success  3.368417  0.299835                              0  11.346233  0.295464
31       119  Linear  0.042779  256   768  3.000000   1.780662        2.089094  0.815810     True   14.900871      dense        2.901346  2.371997           1.173212        blocks.7.qkv          256  235.503294        256            180          0   1  0.058187      14.900871    15.804666  success  3.860165  0.217286   over-trained               0  14.900871  0.151657
32       120  Linear  0.043304  256   256  1.000000   1.871469        1.563367  0.729085     True    6.844933      dense        2.227474  1.852034           0.835369   blocks.7.out_proj          256   71.126974        256             92          0   1  0.090857       6.844933    10.391187  success  2.616282  0.000256   over-trained               1   6.844933  0.100461
33       127  Linear  0.066056  256  1024  4.000000   1.738480        2.502081  0.853437     True   27.493809      dense        2.951363  2.455720           1.439235  blocks.7.ffn.net.0          256  285.575144        256            221          0   1  0.049676      27.493809    10.386889  success  5.243454  0.287525   over-trained               0  27.493809  0.152544
34       130  Linear  0.028864  256  1024  4.000000   2.042702        2.249769  0.872427     True   12.629007      dense        2.901830  2.329497           1.101369  blocks.7.ffn.net.3          256  213.548779        256            152          0   1  0.084574      12.629007    16.909387  success  3.553731  0.296548                              0  12.629007  0.294481
35       134  Linear  0.046006  256   768  3.000000   1.758185        2.101629  0.819784     True   15.679799      dense        2.891458  2.383806           1.195340        blocks.8.qkv          256  241.995019        256            185          0   1  0.055743      15.679799    15.433554  success  3.959773  0.217044   over-trained               0  15.679799  0.146463
36       135  Linear  0.033594  256   256  1.000000   1.864915        1.820028  0.724658     True    9.460868      dense        2.248186  1.846544           0.975931   blocks.8.out_proj          256   70.233494        256            101          0   1  0.086062       9.460868     7.423578  success  3.075852  0.000144   over-trained               1   9.460868  0.088447
37       142  Linear  0.066223  256  1024  4.000000   3.686900        5.482110  0.848396     True   30.684256      dense        5.502235  2.475892           1.486916  blocks.8.ffn.net.0          256  299.151778        256             24          0   1  0.548461      30.684256     9.749358  success  5.539337  0.299389                              0  30.684256  3.791053
38       145  Linear  0.027384  256  1024  4.000000   2.006872        2.296996  0.856147     True   13.949706      dense        2.991205  2.360029           1.144565  blocks.8.ffn.net.3          256  229.102111        256            165          0   1  0.078385      13.949706    16.423436  success  3.734931  0.303924                              0  13.949706  0.264764
39       149  Linear  0.045877  256   768  3.000000   1.761086        2.058698  0.820189     True   14.756843      dense        2.879958  2.376586           1.168993        blocks.9.qkv          256  238.005016        256            190          0   1  0.055215      14.756843    16.128451  success  3.841464  0.219446   over-trained               0  14.756843  0.139862
40       150  Linear  0.034860  256   256  1.000000   1.872951        1.688113  0.733604     True    7.967309      dense        2.184076  1.825341           0.901312   blocks.9.out_proj          256   66.886928        256            105          0   1  0.085191       7.967309     8.395171  success  2.822642  0.001712   over-trained               0   7.967309  0.083489
41       157  Linear  0.052700  256  1024  4.000000   3.875560        5.966127  0.841839     True   34.627655      dense        5.977422  2.489892           1.539423  blocks.9.ffn.net.0          256  308.952536        256             18          0   1  0.677776      34.627655     8.922133  success  5.884527  0.292891                              0  34.627655  4.514857
42       160  Linear  0.030058  256  1024  4.000000   2.005545        2.406587  0.843966     True   15.847729      dense        3.072218  2.377423           1.199967  blocks.9.ffn.net.3          256  238.464043        256            157          0   1  0.080251      15.847729    15.047206  success  3.980921  0.295531                              0  15.847729  0.277353
43       165  Linear  0.059326  128   256  2.000000   1.650766        1.501358  0.758203     True    8.118798      dense        2.042374  1.782172           0.909492          src_head.0          128   60.558115        128             83          0   1  0.071431       8.118798     7.459000  success  2.849350  0.093756   over-trained               0   8.118798  0.061806
44       167  Linear  0.099540   64   128  2.000000   2.156523       -0.090165  0.852586     True    0.908217      dense        0.558518  0.984323          -0.041811          src_head.2           64    9.645470         64             26          0   1  0.226813       0.908217    10.620231  success  0.953004  0.085074                              0   0.908217  0.105071
45       169  Linear  0.078302  256   256  1.000000   3.435695        3.462747  0.789575     True   10.182950      dense        3.608511  2.061636           1.007874         dest_head.0          256  115.248655        256             16          0   1  0.608924      10.182950    11.317806  success  3.191073  0.000153                              1  10.182950  2.130760
46       171  Linear  0.056674   73   256  3.506849   2.747631        2.023758  0.886832     True    5.451883      dense        2.246396  1.659352           0.736547         dest_head.2           73   45.640661         73             25          0   1  0.349526       5.451883     8.371540  success  2.334927  0.261864                              0   5.451883  0.619417
47       173  Conv2d  0.014645  256   256  1.000000   2.548904        1.510845  1.012021     True    3.915102     conv2d        2.475005  2.472644           0.592743        value_conv.0         2304  296.923315       2304            416          1   9  0.075941       3.915102    75.840515  success  1.978662  0.002346                              8   3.915102  0.188752
48       177  Linear  0.050436  128   256  2.000000   2.138902        1.286585  0.746056     True    3.994997      dense        1.621311  1.366866           0.601516         value_mlp.0          128   23.273734        128             62          0   1  0.144641       3.994997     5.825720  success  1.998749  0.083938                              0   3.994997  0.069395
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 02:48:28 2025      Time elapsed: 84.37776s
Begin: Training epoch 22                       Current time: Sun Oct 26 02:48:28 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:48:47 2025      Time elapsed: 19021.11569     ETA: 724133.87467s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:49:07 2025      Time elapsed: 19041.04401     ETA: 352925.75081s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:49:28 2025      Time elapsed: 19061.16068     ETA: 229178.68866s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:49:48 2025      Time elapsed: 19081.35505     ETA: 167295.78046s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:50:08 2025      Time elapsed: 19101.68421     ETA: 130158.87624s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:50:28 2025      Time elapsed: 19122.09786     ETA: 105394.62938s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:50:49 2025      Time elapsed: 19142.41563     ETA: 87699.60991s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:51:09 2025      Time elapsed: 19162.75987     ETA: 74423.36869s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:51:30 2025      Time elapsed: 19183.23378     ETA: 64093.31556s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:51:50 2025      Time elapsed: 19203.75152     ETA: 55825.30569s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:52:11 2025      Time elapsed: 19224.41694     ETA: 49057.21670s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:52:31 2025      Time elapsed: 19245.08829     ETA: 43413.71173s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:52:52 2025      Time elapsed: 19265.76249     ETA: 38635.26372s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:53:13 2025      Time elapsed: 19286.41125     ETA: 34536.45215s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:53:33 2025      Time elapsed: 19307.07880     ETA: 30981.42579s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:53:54 2025      Time elapsed: 19327.72746     ETA: 27868.16704s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:54:15 2025      Time elapsed: 19348.40322     ETA: 25118.77995s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:54:35 2025      Time elapsed: 19369.08720     ETA: 22672.59264s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:54:56 2025      Time elapsed: 19389.79549     ETA: 20481.74714s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:55:17 2025      Time elapsed: 19410.49615     ETA: 18507.90808s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:55:38 2025      Time elapsed: 19431.19572     ETA: 16720.08128s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:55:58 2025      Time elapsed: 19451.90895     ETA: 15092.91299s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:56:19 2025      Time elapsed: 19472.63763     ETA: 13605.44725s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:56:40 2025      Time elapsed: 19493.32852     ETA: 12240.18587s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:57:00 2025      Time elapsed: 19514.03218     ETA: 10982.49732s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:57:21 2025      Time elapsed: 19534.73712     ETA: 9819.96209s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:57:42 2025      Time elapsed: 19555.44766     ETA: 8742.00938s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:58:03 2025      Time elapsed: 19576.12688     ETA: 7739.56159s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:58:23 2025      Time elapsed: 19596.79867     ETA: 6804.81940s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:58:44 2025      Time elapsed: 19617.46969     ETA: 5931.01501s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:59:05 2025      Time elapsed: 19638.14512     ETA: 5112.25262s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:59:25 2025      Time elapsed: 19658.81740     ETA: 4343.36997s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 02:59:46 2025      Time elapsed: 19679.48459     ETA: 3619.83247s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:00:07 2025      Time elapsed: 19700.16209     ETA: 2937.64182s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:00:27 2025      Time elapsed: 19720.82775     ETA: 2293.25054s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:00:48 2025      Time elapsed: 19741.48176     ETA: 1683.50969s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:01:09 2025      Time elapsed: 19762.14051     ETA: 1105.61164s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:01:29 2025      Time elapsed: 19782.79063     ETA: 557.04174s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:01:50 2025      Time elapsed: 19803.42486     ETA: 35.54461s
Epoch 22: Avg Policy Loss=2.6356, Avg Value Loss=0.4437
  End: Training epoch 22                       Current time: Sun Oct 26 03:01:51 2025      Time elapsed: 803.35741s
Begin: Validating epoch 22                     Current time: Sun Oct 26 03:01:51 2025      
Validation: Policy Loss=2.6316, Value Loss=0.4469, Top-1 Acc=0.2348, Top-5 Acc=0.5611
  End: Validating epoch 22                     Current time: Sun Oct 26 03:02:15 2025      Time elapsed: 23.97477s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_22.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 03:02:15 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.063535   19    32  1.684211   3.317772        0.091916  0.916310     True    1.065869     conv2d        0.525137  1.379332           0.027704     conv_stem.net.0          171   23.951453        171             37          0   9  0.381039       1.065869    22.471282  success  1.032410  0.119927                              0   1.065869  0.217867
1          6  Conv2d  0.105909   32    64  2.000000  13.989548       -4.333688  0.967617     True    0.490027     conv2d       -3.890472  1.632275          -0.309780     conv_stem.net.3          288   42.881987        288             13          0   9  3.602652       0.490027    87.509521  success  0.700019  0.134255  under-trained               0   0.490027  0.386983
2          9  Conv2d  0.147893   64   256  4.000000   4.393560        2.979203  0.973339     True    4.765234     conv2d        3.958834  2.182657           0.678084                proj           64  152.284988         64             28          0   1  0.641322       4.765234    31.957508  success  2.182941  0.297623                              0   4.765234  2.537988
3         14  Linear  0.049729  256   768  3.000000   1.731995        2.229246  0.802865     True   19.368553      dense        2.944935  2.407248           1.287097        blocks.0.qkv          256  255.416063        256            194          0   1  0.052554      19.368553    13.187152  success  4.400972  0.213771   over-trained               0  19.368553  0.125165
4         15  Linear  0.040445  256   256  1.000000   1.857238        1.596123  0.756487     True    7.234468      dense        2.068437  1.798259           0.859407   blocks.0.out_proj          256   62.843264        256             98          0   1  0.086594       7.234468     8.686647  success  2.689697  0.000083   over-trained               1   7.234468  0.091382
5         22  Linear  0.062825  256  1024  4.000000   1.791938        2.211098  0.860215     True   17.136189      dense        2.817330  2.375891           1.233914  blocks.0.ffn.net.0          256  237.624551        256            211          0   1  0.054519      17.136189    13.866826  success  4.139588  0.279985   over-trained               0  17.136189  0.152976
6         25  Linear  0.037674  256  1024  4.000000   2.178022        2.190710  0.902976     True   10.135036      dense        2.711487  2.241869           1.005825  blocks.0.ffn.net.3          256  174.529397        256            129          0   1  0.103719      10.135036    17.220401  success  3.183557  0.300114                              0  10.135036  0.347795
7         29  Linear  0.053678  256   768  3.000000   1.713755        2.237282  0.806673     True   20.206238      dense        2.933653  2.415691           1.305485        blocks.1.qkv          256  260.430151        256            199          0   1  0.050597      20.206238    12.888602  success  4.495135  0.203450   over-trained               0  20.206238  0.120048
8         30  Linear  0.042333  256   256  1.000000   1.776234        1.486599  0.759077     True    6.869711      dense        2.102556  1.856653           0.836938   blocks.1.out_proj          256   71.887449        256            111          0   1  0.073677       6.869711    10.464406  success  2.621013  0.000294   over-trained               1   6.869711  0.078742
9         37  Linear  0.055382  256  1024  4.000000   3.767239        4.909065  0.858258     True   20.095264      dense        4.962561  2.392588           1.303094  blocks.1.ffn.net.0          256  246.937776        256             22          0   1  0.589977      20.095264    12.288357  success  4.482774  0.279457                              0  20.095264  3.364818
10        40  Linear  0.034930  256  1024  4.000000   2.127437        1.978300  0.904258     True    8.509389      dense        2.670285  2.251728           0.929898  blocks.1.ffn.net.3          256  178.537051        256            144          0   1  0.093953       8.509389    20.981184  success  2.917086  0.301012                              0   8.509389  0.311983
11        44  Linear  0.048359  256   768  3.000000   1.728089        2.134920  0.807970     True   17.195793      dense        2.919986  2.403115           1.235422        blocks.2.qkv          256  252.996575        256            193          0   1  0.052409      17.195793    14.712702  success  4.146781  0.212984   over-trained               0  17.195793  0.126830
12        45  Linear  0.035722  256   256  1.000000   1.849468        1.637868  0.747369     True    7.684024      dense        2.148768  1.833555           0.885589   blocks.2.out_proj          256   68.164059        256             97          1   1  0.086250       7.684024     8.870881  success  2.772007  0.000005   over-trained               1   7.684024  0.095753
13        52  Linear  0.068015  256  1024  4.000000   1.747344        2.366411  0.855107     True   22.609472      dense        2.880675  2.419918           1.354290  blocks.2.ffn.net.0          256  262.977024        256            222          0   1  0.050158      22.609472    11.631277  success  4.754942  0.284330   over-trained               0  22.609472  0.142046
14        55  Linear  0.039108  256  1024  4.000000   2.086098        1.909789  0.903356     True    8.231597      dense        2.680743  2.275355           0.915484  blocks.2.ffn.net.3          256  188.519132        256            146          0   1  0.089886       8.231597    22.901890  success  2.869076  0.306157                              0   8.231597  0.313015
15        59  Linear  0.051179  256   768  3.000000   1.718745        2.043558  0.810462     True   15.451923      dense        2.887384  2.391452           1.188983        blocks.3.qkv          256  246.293076        256            198          0   1  0.051079      15.451923    15.939315  success  3.930893  0.211057   over-trained               0  15.451923  0.118572
16        60  Linear  0.037692  256   256  1.000000   1.831520        1.559105  0.745093     True    7.100071      dense        2.140781  1.834372           0.851263   blocks.3.out_proj          256   68.292357        256            104          0   1  0.081537       7.100071     9.618546  success  2.664596  0.000163   over-trained               1   7.100071  0.084781
17        67  Linear  0.067608  256  1024  4.000000   1.739236        2.335981  0.855772     True   22.034712      dense        2.875925  2.423844           1.343107  blocks.3.ffn.net.0          256  265.365046        256            223          0   1  0.049503      22.034712    12.043046  success  4.694115  0.280379   over-trained               0  22.034712  0.140086
18        70  Linear  0.038196  256  1024  4.000000   2.076853        1.841955  0.903468     True    7.707211      dense        2.671019  2.275640           0.886897  blocks.3.ffn.net.3          256  188.642743        256            152          0   1  0.087344       7.707211    24.476134  success  2.776186  0.301814                              0   7.707211  0.299051
19        74  Linear  0.048798  256   768  3.000000   1.721967        2.076110  0.809732     True   16.056919      dense        2.917670  2.407590           1.205662        blocks.4.qkv          256  255.616899        256            196          0   1  0.051569      16.056919    15.919424  success  4.007109  0.213456   over-trained               0  16.056919  0.124768
20        75  Linear  0.036631  256   256  1.000000   1.812743        1.523956  0.747315     True    6.929317      dense        2.148303  1.852470           0.840690   blocks.4.out_proj          256   71.198314        256            108          0   1  0.078206       6.929317    10.274940  success  2.632360  0.001932   over-trained               0   6.929317  0.082537
21        82  Linear  0.070428  256  1024  4.000000   1.726392        2.395279  0.854467     True   24.403257      dense        2.902863  2.441513           1.387448  blocks.4.ffn.net.0          256  276.384008        256            225          0   1  0.048426      24.403257    11.325701  success  4.939965  0.286811   over-trained               0  24.403257  0.139297
22        85  Linear  0.038414  256  1024  4.000000   2.050799        2.034935  0.896928     True    9.823459      dense        2.726961  2.293090           0.992264  blocks.4.ffn.net.3          256  196.376523        256            152          0   1  0.085231       9.823459    19.990568  success  3.134240  0.299618                              0   9.823459  0.298133
23        89  Linear  0.048728  256   768  3.000000   1.743707        2.100942  0.810902     True   16.027676      dense        2.908986  2.390424           1.204871        blocks.5.qkv          256  245.710381        256            188          0   1  0.054240      16.027676    15.330381  success  4.003458  0.212700   over-trained               0  16.027676  0.135034
24        90  Linear  0.036026  256   256  1.000000   1.837377        1.521832  0.740499     True    6.733850      dense        2.138576  1.827237           0.828263   blocks.5.out_proj          256   67.179539        256            101          0   1  0.083322       6.733850     9.976394  success  2.594966  0.001849   over-trained               0   6.733850  0.085428
25        97  Linear  0.071513  256  1024  4.000000   1.712742        2.441991  0.852015     True   26.654989      dense        2.932841  2.461149           1.425779  blocks.5.ffn.net.0          256  289.166880        256            226          0   1  0.047411      26.654989    10.848509  success  5.162847  0.292254   over-trained               0  26.654989  0.139020
26       100  Linear  0.034789  256  1024  4.000000   2.012825        2.005002  0.885800     True    9.910901      dense        2.800413  2.322886           0.996113  blocks.5.ffn.net.3          256  210.322800        256            153          0   1  0.081882       9.910901    21.221360  success  3.148158  0.302292                              0   9.910901  0.293764
27       104  Linear  0.046367  256   768  3.000000   1.748379        2.156818  0.811470     True   17.124193      dense        2.905336  2.382679           1.233610        blocks.6.qkv          256  241.367581        256            190          0   1  0.054293      17.124193    14.095121  success  4.138139  0.214272   over-trained               0  17.124193  0.133858
28       105  Linear  0.034504  256   256  1.000000   1.866544        1.716431  0.732139     True    8.309537      dense        2.177810  1.817541           0.919577   blocks.6.out_proj          256   65.696289        256            104          0   1  0.084972       8.309537     7.906131  success  2.882627  0.000148   over-trained               1   8.309537  0.082325
29       112  Linear  0.051536  256  1024  4.000000   3.980566        5.703904  0.852212     True   27.098030      dense        5.722798  2.465907           1.432938  blocks.6.ffn.net.0          256  292.352470        256             18          0   1  0.702526      27.098030    10.788698  success  5.205577  0.286513                              0  27.098030  4.257226
30       115  Linear  0.033758  256  1024  4.000000   2.006007        2.101127  0.879744     True   11.153662      dense        2.835902  2.330051           1.047417  blocks.6.ffn.net.3          256  213.821072        256            155          0   1  0.080804      11.153662    19.170482  success  3.339710  0.300154                              0  11.153662  0.286929
31       119  Linear  0.045195  256   768  3.000000   1.751734        2.060431  0.814877     True   15.004574      dense        2.897129  2.385029           1.176224        blocks.7.qkv          256  242.676973        256            184          0   1  0.055419      15.004574    16.173533  success  3.873574  0.216276   over-trained               0  15.004574  0.142097
32       120  Linear  0.038950  256   256  1.000000   1.828630        1.507177  0.729840     True    6.671310      dense        2.207806  1.859813           0.824211   blocks.7.out_proj          256   72.412387        256             97          0   1  0.084135       6.671310    10.854298  success  2.582888  0.000915   over-trained               1   6.671310  0.090438
33       127  Linear  0.069331  256  1024  4.000000   1.708124        2.510946  0.850038     True   29.512253      dense        2.965690  2.475846           1.470002  blocks.7.ffn.net.0          256  299.120694        256            226          0   1  0.047104      29.512253    10.135475  success  5.432518  0.285685   over-trained               0  29.512253  0.142079
34       130  Linear  0.029819  256  1024  4.000000   2.000995        2.202923  0.870341     True   12.615771      dense        2.898947  2.344525           1.100914  blocks.7.ffn.net.3          256  221.067467        256            155          0   1  0.080402      12.615771    17.523104  success  3.551869  0.296588                              0  12.615771  0.284916
35       134  Linear  0.047851  256   768  3.000000   1.727689        2.070775  0.819265     True   15.797234      dense        2.885612  2.397240           1.198581        blocks.8.qkv          256  249.597341        256            194          0   1  0.052245      15.797234    15.800067  success  3.974573  0.215092   over-trained               0  15.797234  0.131762
36       135  Linear  0.033839  256   256  1.000000   1.825629        1.773565  0.725420     True    9.364440      dense        2.229485  1.855917           0.971482   blocks.8.out_proj          256   71.765742        256            106          0   1  0.080192       9.364440     7.663645  success  3.060137  0.000619   over-trained               1   9.364440  0.080297
37       142  Linear  0.064537  256  1024  4.000000   4.005352        6.078236  0.845216     True   32.925213      dense        6.088576  2.494747           1.517529  blocks.8.ffn.net.0          256  312.425667        256             20          0   1  0.672017      32.925213     9.488949  success  5.738050  0.298265                              0  32.925213  4.388012
38       145  Linear  0.028646  256  1024  4.000000   1.975767        2.264889  0.853672     True   14.006635      dense        2.994219  2.374331           1.146334  blocks.8.ffn.net.3          256  236.772287        256            164          0   1  0.076195      14.006635    16.904295  success  3.742544  0.302226   over-trained               0  14.006635  0.263436
39       149  Linear  0.049199  256   768  3.000000   1.734807        2.033255  0.819671     True   14.860553      dense        2.877885  2.389741           1.172035        blocks.9.qkv          256  245.324807        256            195          0   1  0.052621      14.860553    16.508458  success  3.854939  0.217316   over-trained               0  14.860553  0.130642
40       150  Linear  0.033556  256   256  1.000000   1.844886        1.663673  0.733372     True    7.975824      dense        2.178225  1.834758           0.901776   blocks.9.out_proj          256   68.353080        256            105          0   1  0.082452       7.975824     8.570034  success  2.824150  0.001852   over-trained               0   7.975824  0.081558
41       157  Linear  0.052454  256  1024  4.000000   3.834436        5.998494  0.839446     True   36.675377      dense        6.009378  2.507962           1.564375  blocks.9.ffn.net.0          256  322.078930        256             19          0   1  0.650264      36.675377     8.781885  success  6.056020  0.291494                              0  36.675377  4.561892
42       160  Linear  0.028308  256  1024  4.000000   1.961950        2.375465  0.840456     True   16.246782      dense        3.066530  2.392667           1.210767  blocks.9.ffn.net.3          256  246.983011        256            164          0   1  0.075116      16.246782    15.201965  success  4.030730  0.293474   over-trained               0  16.246782  0.258138
43       165  Linear  0.059178  128   256  2.000000   1.614576        1.480975  0.759908     True    8.265193      dense        2.055767  1.806620           0.917253          src_head.0          128   64.064938        128             91          0   1  0.064425       8.265193     7.751173  success  2.874925  0.095928   over-trained               0   8.265193  0.051243
44       167  Linear  0.113343   64   128  2.000000   2.260261       -0.064978  0.855065     True    0.935948      dense        0.578319  1.008393          -0.028748          src_head.2           64   10.195131         64             24          0   1  0.257250       0.935948    10.892833  success  0.967444  0.089660                              0   0.935948  0.129105
45       169  Linear  0.081110  256   256  1.000000   3.410114        3.479988  0.789933     True   10.483115      dense        3.631662  2.078066           1.020490         dest_head.0          256  119.692284        256             16          0   1  0.602528      10.483115    11.417626  success  3.237764  0.000746                              1  10.483115  2.191107
46       171  Linear  0.055798   73   256  3.506849   2.858306        2.174903  0.888405     True    5.766419      dense        2.379676  1.685518           0.760906         dest_head.2           73   48.475008         73             20          0   1  0.415530       5.766419     8.406432  success  2.401337  0.274615                              0   5.766419  0.773405
47       173  Conv2d  0.015167  256   256  1.000000   2.487657        1.541670  1.007866     True    4.166080     conv2d        2.512510  2.479256           0.619728        value_conv.0         2304  301.477996       2304            425          0   9  0.072162       4.166080    72.364900  success  2.041098  0.002428                              8   4.166080  0.184393
48       177  Linear  0.050131  128   256  2.000000   2.054196        1.320509  0.730941     True    4.393746      dense        1.673572  1.396130           0.642835         value_mlp.0          128   24.896018        128             64          0   1  0.131774       4.393746     5.666239  success  2.096127  0.082407                              0   4.393746  0.063966
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 03:03:41 2025      Time elapsed: 85.39151s
Begin: Training epoch 23                       Current time: Sun Oct 26 03:03:41 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:04:01 2025      Time elapsed: 19934.75235     ETA: 758916.02208s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:04:22 2025      Time elapsed: 19955.83537     ETA: 369881.40868s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:04:43 2025      Time elapsed: 19976.64681     ETA: 240185.88352s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:05:04 2025      Time elapsed: 19997.18279     ETA: 175325.30020s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:05:24 2025      Time elapsed: 20017.82073     ETA: 136401.43051s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:05:45 2025      Time elapsed: 20038.58055     ETA: 110445.97648s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:06:06 2025      Time elapsed: 20059.25143     ETA: 91900.02765s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:06:26 2025      Time elapsed: 20079.92008     ETA: 77985.38963s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:06:47 2025      Time elapsed: 20100.60681     ETA: 67158.36079s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:07:08 2025      Time elapsed: 20121.32615     ETA: 58492.69515s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:07:28 2025      Time elapsed: 20142.05959     ETA: 51398.87391s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:07:49 2025      Time elapsed: 20162.80144     ETA: 45483.91960s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:08:10 2025      Time elapsed: 20183.56208     ETA: 40475.80489s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:08:31 2025      Time elapsed: 20204.31278     ETA: 36180.15154s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:08:51 2025      Time elapsed: 20225.01278     ETA: 32454.40385s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:09:12 2025      Time elapsed: 20245.69448     ETA: 29191.76074s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:09:33 2025      Time elapsed: 20266.40626     ETA: 26310.56390s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:09:53 2025      Time elapsed: 20287.08099     ETA: 23747.15536s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:10:14 2025      Time elapsed: 20307.73456     ETA: 21451.38067s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:10:35 2025      Time elapsed: 20328.37477     ETA: 19383.10534s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:10:55 2025      Time elapsed: 20349.03422     ETA: 17509.85945s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:11:16 2025      Time elapsed: 20369.71721     ETA: 15805.04877s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:11:37 2025      Time elapsed: 20390.39556     ETA: 14246.68073s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:11:57 2025      Time elapsed: 20411.08163     ETA: 12816.45834s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:12:18 2025      Time elapsed: 20431.75386     ETA: 11498.99107s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:12:39 2025      Time elapsed: 20452.43185     ETA: 10281.28017s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:12:59 2025      Time elapsed: 20473.12132     ETA: 9152.24350s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:13:20 2025      Time elapsed: 20493.79611     ETA: 8102.36868s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:13:41 2025      Time elapsed: 20514.48692     ETA: 7123.47873s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:14:02 2025      Time elapsed: 20535.16401     ETA: 6208.46459s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:14:22 2025      Time elapsed: 20555.84342     ETA: 5351.15021s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:14:43 2025      Time elapsed: 20576.51936     ETA: 4546.12475s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:15:04 2025      Time elapsed: 20597.20484     ETA: 3788.63738s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:15:24 2025      Time elapsed: 20617.87992     ETA: 3074.48974s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:15:45 2025      Time elapsed: 20638.54458     ETA: 2399.96790s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:16:06 2025      Time elapsed: 20659.21893     ETA: 1761.77228s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:16:26 2025      Time elapsed: 20679.90023     ETA: 1156.95658s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:16:47 2025      Time elapsed: 20700.56578     ETA: 582.88435s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:17:08 2025      Time elapsed: 20721.22692     ETA: 37.19195s
Epoch 23: Avg Policy Loss=2.6204, Avg Value Loss=0.4387
  End: Training epoch 23                       Current time: Sun Oct 26 03:17:09 2025      Time elapsed: 808.37715s
Begin: Validating epoch 23                     Current time: Sun Oct 26 03:17:09 2025      
Validation: Policy Loss=2.6189, Value Loss=0.4427, Top-1 Acc=0.2379, Top-5 Acc=0.5665
  End: Validating epoch 23                     Current time: Sun Oct 26 03:17:33 2025      Time elapsed: 24.00979s
Checkpoint saved to /teamspace/studios/this_studio/chess_bot/results/checkpoints/_test_run/model_epoch_23.pt
Begin: Generating ww analysis                  Current time: Sun Oct 26 03:17:33 2025      
    layer_id    name         D    M     N         Q      alpha  alpha_weighted   entropy  has_esd  lambda_max layer_type  log_alpha_norm  log_norm  log_spectral_norm            longname  matrix_rank        norm  num_evals  num_pl_spikes  rank_loss  rf     sigma  spectral_norm  stable_rank   status    sv_max    sv_min        warning  weak_rank_loss       xmax      xmin
0          3  Conv2d  0.069531   19    32  1.684211   3.319269        0.058251  0.915637     True    1.041236     conv2d        0.490939  1.367117           0.017549     conv_stem.net.0          171   23.287209        171             35          0   9  0.392028       1.041236    22.364964  success  1.020410  0.117671                              0   1.041236  0.217552
1          6  Conv2d  0.114166   32    64  2.000000   4.823472       -1.565823  0.967565     True    0.473559     conv2d       -0.464397  1.619726          -0.324626     conv_stem.net.3          288   41.660682        288             63          0   9  0.481712       0.473559    87.973550  success  0.688156  0.133249                              0   0.473559  0.235740
2          9  Conv2d  0.149806   64   256  4.000000   4.347711        2.871096  0.973494     True    4.574772     conv2d        3.849620  2.164330           0.660369                proj           64  145.992270         64             28          0   1  0.632658       4.574772    31.912470  success  2.138872  0.284950                              0   4.574772  2.419435
3         14  Linear  0.051675  256   768  3.000000   1.706647        2.199434  0.801342     True   19.442225      dense        2.939428  2.418228           1.288746        blocks.0.qkv          256  261.955618        256            202          0   1  0.049719      19.442225    13.473541  success  4.409334  0.212895   over-trained               0  19.442225  0.112549
4         15  Linear  0.038295  256   256  1.000000   1.823444        1.550925  0.759056     True    7.088379      dense        2.055823  1.808830           0.850547   blocks.0.out_proj          256   64.391679        256            101          0   1  0.081936       7.088379     9.084119  success  2.662401  0.000385   over-trained               1   7.088379  0.086699
5         22  Linear  0.063114  256  1024  4.000000   1.769732        2.264496  0.854358     True   19.035744      dense        2.845674  2.393099           1.279570  blocks.0.ffn.net.0          256  247.229024        256            215          0   1  0.052495      19.035744    12.987621  success  4.362997  0.278248   over-trained               0  19.035744  0.144435
6         25  Linear  0.039223  256  1024  4.000000   2.133676        2.131472  0.902496     True    9.976236      dense        2.698826  2.253269           0.998967  blocks.0.ffn.net.3          256  179.171728        256            137          0   1  0.096857       9.976236    17.959852  success  3.158518  0.302182                              0   9.976236  0.329113
7         29  Linear  0.054337  256   768  3.000000   1.695120        2.200763  0.805820     True   19.874395      dense        2.930318  2.425284           1.298294        blocks.1.qkv          256  266.246675        256            204          0   1  0.048668      19.874395    13.396467  success  4.458071  0.202696   over-trained               0  19.874395  0.111538
8         30  Linear  0.044251  256   256  1.000000   1.757581        1.454029  0.761783     True    6.718775      dense        2.095875  1.864494           0.827290   blocks.1.out_proj          256   73.197086        256            112          0   1  0.071585       6.718775    10.894409  success  2.592060  0.000271   over-trained               1   6.718775  0.077197
9         37  Linear  0.040210  256  1024  4.000000   3.878781        5.228905  0.852315     True   22.288437      dense        5.265668  2.412612           1.348080  blocks.1.ffn.net.0          256  258.590272        256             22          0   1  0.613758      22.288437    11.601992  success  4.721063  0.277252                              0  22.288437  3.597248
10        40  Linear  0.039495  256  1024  4.000000   2.072284        1.914241  0.903348     True    8.389480      dense        2.660851  2.265447           0.923735  blocks.1.ffn.net.3          256  184.266773        256            155          0   1  0.086128       8.389480    21.964029  success  2.896460  0.294670                              0   8.389480  0.287536
11        44  Linear  0.048797  256   768  3.000000   1.699098        2.092374  0.807262     True   17.039701      dense        2.910832  2.414243           1.231462        blocks.2.qkv          256  259.563223        256            202          0   1  0.049188      17.039701    15.232850  success  4.127917  0.210526   over-trained               0  17.039701  0.112938
12        45  Linear  0.036948  256   256  1.000000   1.812113        1.585501  0.749685     True    7.498017      dense        2.132836  1.843756           0.874946   blocks.2.out_proj          256   69.784096        256            103          0   1  0.080020       7.498017     9.307007  success  2.738251  0.000185   over-trained               1   7.498017  0.086795
13        52  Linear  0.061719  256  1024  4.000000   4.099324        5.716516  0.849897     True   24.802879      dense        5.736823  2.440156           1.394502  blocks.2.ffn.net.0          256  275.521789        256             15          0   1  0.800242      24.802879    11.108460  success  4.980249  0.280903                              0  24.802879  4.473119
14        55  Linear  0.042903  256  1024  4.000000   2.050692        1.861976  0.902609     True    8.090487      dense        2.684474  2.289563           0.907975  blocks.2.ffn.net.3          256  194.788311        256            146          0   1  0.086956       8.090487    24.076214  success  2.844378  0.303247                              0   8.090487  0.314090
15        59  Linear  0.052217  256   768  3.000000   1.702305        2.018873  0.809519     True   15.344916      dense        2.890247  2.403009           1.185965        blocks.3.qkv          256  252.934923        256            202          0   1  0.049414      15.344916    16.483304  success  3.917259  0.209945   over-trained               0  15.344916  0.112043
16        60  Linear  0.040406  256   256  1.000000   1.799143        1.513585  0.746885     True    6.938745      dense        2.126704  1.842394           0.841281   blocks.3.out_proj          256   69.565536        256            106          0   1  0.077620       6.938745    10.025665  success  2.634150  0.000603   over-trained               1   6.938745  0.080484
17        67  Linear  0.069178  256  1024  4.000000   1.708798        2.365319  0.850712     True   24.221460      dense        2.898104  2.444561           1.384200  blocks.3.ffn.net.0          256  278.330655        256            228          0   1  0.046941      24.221460    11.491077  success  4.921530  0.277985   over-trained               0  24.221460  0.129560
18        70  Linear  0.038457  256  1024  4.000000   2.032784        1.797467  0.902303     True    7.660176      dense        2.673691  2.289957           0.884239  blocks.3.ffn.net.3          256  194.965342        256            155          0   1  0.082955       7.660176    25.451809  success  2.767702  0.300026                              0   7.660176  0.290944
19        74  Linear  0.049229  256   768  3.000000   1.702368        2.055068  0.808587     True   16.113199      dense        2.918921  2.419330           1.207182        blocks.4.qkv          256  262.621558        256            202          0   1  0.049418      16.113199    16.298536  success  4.014125  0.210683   over-trained               0  16.113199  0.115627
20        75  Linear  0.043706  256   256  1.000000   1.802706        1.512664  0.749741     True    6.904104      dense        2.144347  1.859326           0.839107   blocks.4.out_proj          256   72.331195        256            106          0   1  0.077966       6.904104    10.476551  success  2.627566  0.001249   over-trained               0   6.904104  0.084986
21        82  Linear  0.072548  256  1024  4.000000   3.711959        5.287025  0.850001     True   26.565729      dense        5.316883  2.462466           1.424322  blocks.4.ffn.net.0          256  290.045647        256             24          0   1  0.553576      26.565729    10.918038  success  5.154195  0.281497                              0  26.565729  3.722647
22        85  Linear  0.040218  256  1024  4.000000   2.005250        1.990568  0.895813     True    9.832824      dense        2.725316  2.308067           0.992678  blocks.4.ffn.net.3          256  203.266891        256            159          0   1  0.079721       9.832824    20.672281  success  3.135733  0.301365                              0   9.832824  0.281981
23        89  Linear  0.049676  256   768  3.000000   1.717404        2.067595  0.810142     True   15.992156      dense        2.906681  2.404240           1.203907        blocks.5.qkv          256  253.653008        256            194          0   1  0.051507      15.992156    15.861089  success  3.999019  0.211353   over-trained               0  15.992156  0.124584
24        90  Linear  0.037580  256   256  1.000000   1.802777        1.491508  0.741229     True    6.719534      dense        2.131598  1.838314           0.827339   blocks.5.out_proj          256   68.915040        256            106          0   1  0.077973       6.719534    10.255925  success  2.592206  0.000665   over-trained               1   6.719534  0.078217
25        97  Linear  0.070653  256  1024  4.000000   3.989665        5.819974  0.848102     True   28.758259      dense        5.835932  2.480331           1.458763  blocks.5.ffn.net.0          256  302.225602        256             20          0   1  0.668509      28.758259    10.509176  success  5.362673  0.288553                              0  28.758259  4.255398
26       100  Linear  0.037185  256  1024  4.000000   1.972401        1.965115  0.884969     True    9.915301      dense        2.797168  2.336991           0.996306  blocks.5.ffn.net.3          256  217.265367        256            169          0   1  0.074800       9.915301    21.912130  success  3.148857  0.302041   over-trained               0   9.915301  0.262236
27       104  Linear  0.050552  256   768  3.000000   1.725701        2.130620  0.810948     True   17.164858      dense        2.903286  2.395295           1.234640        blocks.6.qkv          256  248.482313        256            191          0   1  0.052510      17.164858    14.476223  success  4.143049  0.214100   over-trained               0  17.164858  0.128842
28       105  Linear  0.033494  256   256  1.000000   1.838183        1.671467  0.733539     True    8.115291      dense        2.163227  1.825604           0.909304   blocks.6.out_proj          256   66.927434        256            104          0   1  0.082191       8.115291     8.247078  success  2.848735  0.000360   over-trained               1   8.115291  0.080543
29       112  Linear  0.052320  256  1024  4.000000   4.060303        5.946673  0.848542     True   29.146633      dense        5.961114  2.484876           1.464588  blocks.6.ffn.net.0          256  305.404730        256             18          0   1  0.721320      29.146633    10.478216  success  5.398762  0.285103                              0  29.146633  4.476435
30       115  Linear  0.036239  256  1024  4.000000   1.972069        2.074424  0.878810     True   11.269437      dense        2.836001  2.343829           1.051902  blocks.6.ffn.net.3          256  220.713423        256            157          0   1  0.077580      11.269437    19.585133  success  3.356998  0.298096   over-trained               0  11.269437  0.281344
31       119  Linear  0.046858  256   768  3.000000   1.724835        2.028307  0.813796     True   14.994885      dense        2.894906  2.398018           1.175943        blocks.7.qkv          256  250.044898        256            192          0   1  0.052310      14.994885    16.675346  success  3.872323  0.211229   over-trained               0  14.994885  0.129087
32       120  Linear  0.038718  256   256  1.000000   1.810278        1.484487  0.730880     True    6.607434      dense        2.203374  1.867829           0.820033   blocks.7.out_proj          256   73.761436        256             98          0   1  0.081850       6.607434    11.163401  success  2.570493  0.001166   over-trained               0   6.607434  0.088504
33       127  Linear  0.069989  256  1024  4.000000   1.681385        2.518496  0.847154     True   31.468067      dense        2.979046  2.494889           1.497870  blocks.7.ffn.net.0          256  312.527781        256            229          0   1  0.045027      31.468067     9.931585  success  5.609641  0.285508   over-trained               0  31.468067  0.134263
34       130  Linear  0.031960  256  1024  4.000000   1.964036        2.178604  0.868612     True   12.860225      dense        2.898550  2.358883           1.109249  blocks.7.ffn.net.3          256  228.498242        256            160          0   1  0.076214      12.860225    17.767827  success  3.586116  0.295360   over-trained               0  12.860225  0.272251
35       134  Linear  0.051663  256   768  3.000000   1.706094        2.051390  0.819055     True   15.936388      dense        2.885091  2.409361           1.202390        blocks.8.qkv          256  256.661862        256            197          0   1  0.050307      15.936388    16.105397  success  3.992041  0.214970   over-trained               0  15.936388  0.125228
36       135  Linear  0.038669  256   256  1.000000   1.803969        1.743117  0.726687     True    9.252691      dense        2.220694  1.863904           0.966268   blocks.8.out_proj          256   73.097666        256            107          0   1  0.077723       9.252691     7.900152  success  3.041824  0.000265   over-trained               1   9.252691  0.077971
37       142  Linear  0.059143  256  1024  4.000000   4.037799        6.224961  0.842737     True   34.807434      dense        6.234018  2.512529           1.541672  blocks.8.ffn.net.0          256  325.483785        256             21          0   1  0.662902      34.807434     9.350985  success  5.899783  0.291589                              0  34.807434  4.487352
38       145  Linear  0.030182  256  1024  4.000000   1.943060        2.240045  0.851883     True   14.218182      dense        2.992468  2.387966           1.152844  blocks.8.ffn.net.3          256  244.324084        256            169          0   1  0.072543      14.218182    17.183919  success  3.770700  0.302190   over-trained               0  14.218182  0.251421
39       149  Linear  0.052893  256   768  3.000000   1.701148        2.008611  0.819091     True   15.161365      dense        2.871515  2.403557           1.180738        blocks.9.qkv          256  253.254242        256            201          0   1  0.049455      15.161365    16.703921  success  3.893760  0.215036   over-trained               0  15.161365  0.119046
40       150  Linear  0.036046  256   256  1.000000   1.816262        1.634685  0.733222     True    7.943773      dense        2.175108  1.846099           0.900027   blocks.9.out_proj          256   70.161573        256            106          0   1  0.079282       7.943773     8.832273  success  2.818470  0.000484   over-trained               2   7.943773  0.078711
41       157  Linear  0.051243  256  1024  4.000000   3.902582        6.178933  0.837883     True   38.308357      dense        6.188194  2.524826           1.583294  blocks.9.ffn.net.0          256  334.831372        256             19          0   1  0.665898      38.308357     8.740426  success  6.189374  0.290921                              0  38.308357  4.759655
42       160  Linear  0.029120  256  1024  4.000000   1.933963        2.350414  0.837631     True   16.418570      dense        3.070236  2.406733           1.215335  blocks.9.ffn.net.3          256  255.113073        256            172          0   1  0.071214      16.418570    15.538082  success  4.051983  0.292720   over-trained               0  16.418570  0.241862
43       165  Linear  0.061503  128   256  2.000000   1.598142        1.479975  0.761619     True    8.434508      dense        2.079142  1.830347           0.926060          src_head.0          128   67.662264        128             92          0   1  0.062361       8.434508     8.022076  success  2.904222  0.098489   over-trained               0   8.434508  0.050453
44       167  Linear  0.118861   64   128  2.000000   2.292420       -0.021734  0.857719     True    0.978406      dense        0.615204  1.031708          -0.009481          src_head.2           64   10.757417         64             24          0   1  0.263814       0.978406    10.994834  success  0.989144  0.095275                              0   0.978406  0.139524
45       169  Linear  0.074084  256   256  1.000000   3.360304        3.473216  0.790363     True   10.804428      dense        3.633135  2.094113           1.033602         dest_head.0          256  124.197436        256             16          1   1  0.590076      10.804428    11.495049  success  3.287009  0.000066                              1  10.804428  2.241519
46       171  Linear  0.059989   73   256  3.506849   2.761127        2.155974  0.889994     True    6.037142      dense        2.378347  1.709007           0.780831         dest_head.2           73   51.169027         73             25          0   1  0.352225       6.037142     8.475704  success  2.457060  0.284123                              0   6.037142  0.691269
47       173  Conv2d  0.019148  256   256  1.000000   2.434093        1.564728  1.004150     True    4.393778     conv2d        2.540966  2.485912           0.642838        value_conv.0         2304  306.134446       2304            444          0   9  0.068059       4.393778    69.674531  success  2.096134  0.001687                              5   4.393778  0.177658
48       177  Linear  0.046008  128   256  2.000000   2.008897        1.376796  0.717332     True    4.845618      dense        1.737329  1.426804           0.685349         value_mlp.0          128   26.718004        128             70          0   1  0.120586       4.845618     5.513848  success  2.201277  0.080932                              0   4.845618  0.057366
49       181  Linear  0.136463  128   256  2.000000  13.147252       -6.655368  0.954682     True    0.311733      dense       -6.414893  1.113448          -0.506217      outcome_head.0          128   12.985173        128              8          0   1  4.294702       0.311733    41.654810  success  0.558330  0.100728  under-trained               0   0.311733  0.241617
  End: Generating ww analysis                  Current time: Sun Oct 26 03:18:59 2025      Time elapsed: 85.51217s
Begin: Training epoch 24                       Current time: Sun Oct 26 03:18:59 2025      
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:19:19 2025      Time elapsed: 20852.73562     ETA: 793863.64532s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:19:40 2025      Time elapsed: 20873.86145     ETA: 386897.02203s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:20:01 2025      Time elapsed: 20894.65974     ETA: 251223.45896s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:20:22 2025      Time elapsed: 20915.19563     ETA: 183373.97779s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:20:42 2025      Time elapsed: 20935.84790     ETA: 142656.86762s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:21:03 2025      Time elapsed: 20956.62276     ETA: 115505.91913s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:21:24 2025      Time elapsed: 20977.32158     ETA: 96106.10047s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:21:44 2025      Time elapsed: 20997.97551     ETA: 81550.88742s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:22:05 2025      Time elapsed: 21018.65274     ETA: 70225.65422s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:22:26 2025      Time elapsed: 21039.34939     ETA: 61161.38870s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:22:46 2025      Time elapsed: 21060.04890     ETA: 53741.41570s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:23:07 2025      Time elapsed: 21080.74797     ETA: 47554.65398s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:23:28 2025      Time elapsed: 21101.43826     ETA: 42316.49965s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:23:48 2025      Time elapsed: 21122.12427     ETA: 37823.68968s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:24:09 2025      Time elapsed: 21142.77194     ETA: 33927.10139s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:24:30 2025      Time elapsed: 21163.42817     ETA: 30515.01800s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:24:50 2025      Time elapsed: 21184.08326     ETA: 27501.92457s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:25:11 2025      Time elapsed: 21204.70754     ETA: 24821.28822s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:25:32 2025      Time elapsed: 21225.32208     ETA: 22420.64286s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:25:52 2025      Time elapsed: 21245.94416     ETA: 20258.00776s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:26:13 2025      Time elapsed: 21266.56480     ETA: 18299.37267s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:26:34 2025      Time elapsed: 21287.20256     ETA: 16516.93399s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:26:54 2025      Time elapsed: 21307.85335     ETA: 14887.70449s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:27:15 2025      Time elapsed: 21328.50840     ETA: 13392.52590s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:27:36 2025      Time elapsed: 21349.17758     ETA: 12015.31714s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:27:56 2025      Time elapsed: 21369.84113     ETA: 10742.45476s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:28:17 2025      Time elapsed: 21390.49794     ETA: 9562.34482s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:28:38 2025      Time elapsed: 21411.17182     ETA: 8465.05972s
  Lap: Training for 3907 batches               Current time: Sun Oct 26 03:28:58 2025      Time elapsed: 21431.84467     ETA: 7442.02331s
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/chess_bot/src/train_test.py", line 219, in <module>
    train_pipeline(
  File "/teamspace/studios/this_studio/chess_bot/src/train_test.py", line 101, in train_pipeline
    scaler.step(optimizer)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py", line 461, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py", line 355, in _maybe_opt_step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py", line 355, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt
